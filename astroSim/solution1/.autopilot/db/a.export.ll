; ModuleID = '/home/linsun/XilinxLab/astro/astroSim/solution1/.autopilot/db/a.o.2.bc'
target datalayout = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@scale_vel = constant double 1.000000e-16, align 8
@scale_pos = constant double 1.000000e-16, align 8
@p_z_8 = global double 0xBFDEA187B634DB1A
@p_z_7 = global double 0xBFC961E0BE157C12
@p_z_6 = global double 0x3FC7E5989FEBDF52
@p_z_5 = global double 0x3FBD2FDCD0179FA4
@p_z_4 = global double 0x3FA8D9956609AAD1
@p_z_3 = global double 0xBF2465D41C124A40
@p_z_2 = global double 0x3FA5B5322CF8CE05
@p_z_1 = global double 0xBF964698DBEFCB0B
@p_z_0 = global double 0xBF20E99E2D034213
@p_z = global [9 x double] [double 0xBF20E99E2D034213, double 0xBF964698DBEFCB0B, double 0x3FA5B5322CF8CE05, double 0xBF2465D41C124A40, double 0x3FA8D9956609AAD1, double 0x3FBD2FDCD0179FA4, double 0x3FC7E5989FEBDF52, double 0xBFC961E0BE157C12, double 0xBFDEA187B634DB1A]
@p_y_8 = global double 0xC0219502573C37FA
@p_y_7 = global double 0x4021AFCF747ADCA3
@p_y_6 = global double 0xC0241A39E25E85F4
@p_y_5 = global double 0xC007D955EEEAB803
@p_y_4 = global double 0x3FDCD9A6C1889FBB
@p_y_3 = global double 0x3FE1C3FE1FA86D35
@p_y_2 = global double 0x3FC0B46DAED4F4AD
@p_y_1 = global double 0xBFDBB5B2C08236D6
@p_y_0 = global double 0x3F77B17E896D4129
@p_y = global [9 x double] [double 0x3F77B17E896D4129, double 0xBFDBB5B2C08236D6, double 0x3FC0B46DAED4F4AD, double 0x3FE1C3FE1FA86D35, double 0x3FDCD9A6C1889FBB, double 0xC007D955EEEAB803, double 0xC0241A39E25E85F4, double 0x4021AFCF747ADCA3, double 0xC0219502573C37FA]
@p_x_8 = global double 0x403C9F7653CCEE75
@p_x_7 = global double 0x4031D783AF637DB7
@p_x_6 = global double 0xBFD3307121192C06
@p_x_5 = global double 0xC0122D8A2D8E41D1
@p_x_4 = global double 0xBFF99CB9F9E42F76
@p_x_3 = global double 0x3FEA9286B17974A3
@p_x_2 = global double 0xBFE6907EC81DDB80
@p_x_1 = global double 0xBFC3927878C2E34A
@p_x_0 = global double 0x3F61C8E693683811
@p_x = global [9 x double] [double 0x3F61C8E693683811, double 0xBFC3927878C2E34A, double 0xBFE6907EC81DDB80, double 0x3FEA9286B17974A3, double 0xBFF99CB9F9E42F76, double 0xC0122D8A2D8E41D1, double 0xBFD3307121192C06, double 0x4031D783AF637DB7, double 0x403C9F7653CCEE75]
@p_vz_8 = global double 0xBF73BF9E2E3C5383
@p_vz_7 = global double 0x3F60DCF854CE4C7C
@p_vz_6 = global double 0xBF88973D44583149
@p_vz_5 = global double 0xBF6F613A0D086259
@p_vz_4 = global double 0xBF853C4453159B2B
@p_vz_3 = global double 0xBEFA43F02C76C8AB
@p_vz_2 = global double 0xBF6F2F613DADF176
@p_vz_1 = global double 0xBFC319BD79AF55DD
@p_vz_0 = global double 0x3EDE8F5A3EB9DCFC
@p_vz = global [9 x double] [double 0x3EDE8F5A3EB9DCFC, double 0xBFC319BD79AF55DD, double 0xBF6F2F613DADF176, double 0xBEFA43F02C76C8AB, double 0xBF853C4453159B2B, double 0xBF6F613A0D086259, double 0xBF88973D44583149, double 0x3F60DCF854CE4C7C, double 0xBF73BF9E2E3C5383]
@p_vy_8 = global double 0x3FC677B23A587859
@p_vy_7 = global double 0x3FC8DB85A5B42410
@p_vy_6 = global double 0xBF85F0F79C6BDB23
@p_vy_5 = global double 0xBFD6241DECB5C325
@p_vy_4 = global double 0xBFE6D947030952B4
@p_vy_3 = global double 0x3FEA8FA78A436C92
@p_vy_2 = global double 0xBFF29B21E53B95B9
@p_vy_1 = global double 0xBFDDACB633B56C17
@p_vy_0 = global double 0x3F34BDC20AA5CC77
@p_vy = global [9 x double] [double 0x3F34BDC20AA5CC77, double 0xBFDDACB633B56C17, double 0xBFF29B21E53B95B9, double 0x3FEA8FA78A436C92, double 0xBFE6D947030952B4, double 0xBFD6241DECB5C325, double 0xBF85F0F79C6BDB23, double 0x3FC8DB85A5B42410, double 0x3FC677B23A587859]
@p_vx_8 = global double 0x3FAACF601FAEFFED
@p_vx_7 = global double 0xBFBA6C2D89FC4D33
@p_vx_6 = global double 0x3FD39B66EF2B2F4F
@p_vx_5 = global double 0x3FCE23C71B55DC83
@p_vx_4 = global double 0xBFC7FEE458000E0D
@p_vx_3 = global double 0xBFE238DAECF98D5A
@p_vx_2 = global double 0xBFCAF89B7302DA8D
@p_vx_1 = global double 0x3FF368D039E12295
@p_vx_0 = global double 0xBF34379C52A2C552
@p_vx = global [9 x double] [double 0xBF34379C52A2C552, double 0x3FF368D039E12295, double 0xBFCAF89B7302DA8D, double 0xBFE238DAECF98D5A, double 0xBFC7FEE458000E0D, double 0x3FCE23C71B55DC83, double 0x3FD39B66EF2B2F4F, double 0xBFBA6C2D89FC4D33, double 0x3FAACF601FAEFFED]
@p_m_8 = global double 0x3F0B0211FC924B60
@p_m_7 = global double 0x3F06E445EC9476B8
@p_m_6 = global double 0x3F32BC5D9D5F6437
@p_m_5 = global double 0x3F4F49600670CC2E
@p_m_4 = global double 0x3E95A8363C414D00
@p_m_3 = global double 0x3EC9814786649F85
@p_m_2 = global double 0x3EC488B1548664FE
@p_m_1 = global double 0x3E86481BDA0ACB48
@p_m_0 = global double 1.000000e+00
@p_m = global [9 x double] [double 1.000000e+00, double 0x3E86481BDA0ACB48, double 0x3EC488B1548664FE, double 0x3EC9814786649F85, double 0x3E95A8363C414D00, double 0x3F4F49600670CC2E, double 0x3F32BC5D9D5F6437, double 0x3F06E445EC9476B8, double 0x3F0B0211FC924B60]
@p_az_8 = global double 0.000000e+00
@p_az_7 = global double 0.000000e+00
@p_az_6 = global double 0.000000e+00
@p_az_5 = global double 0.000000e+00
@p_az_4 = global double 0.000000e+00
@p_az_3 = global double 0.000000e+00
@p_az_2 = global double 0.000000e+00
@p_az_1 = global double 0.000000e+00
@p_az_0 = global double 0.000000e+00
@p_az = global [9 x double] zeroinitializer
@p_ay_8 = global double 0.000000e+00
@p_ay_7 = global double 0.000000e+00
@p_ay_6 = global double 0.000000e+00
@p_ay_5 = global double 0.000000e+00
@p_ay_4 = global double 0.000000e+00
@p_ay_3 = global double 0.000000e+00
@p_ay_2 = global double 0.000000e+00
@p_ay_1 = global double 0.000000e+00
@p_ay_0 = global double 0.000000e+00
@p_ay = global [9 x double] zeroinitializer
@p_ax_8 = global double 0.000000e+00
@p_ax_7 = global double 0.000000e+00
@p_ax_6 = global double 0.000000e+00
@p_ax_5 = global double 0.000000e+00
@p_ax_4 = global double 0.000000e+00
@p_ax_3 = global double 0.000000e+00
@p_ax_2 = global double 0.000000e+00
@p_ax_1 = global double 0.000000e+00
@p_ax_0 = global double 0.000000e+00
@p_ax = global [9 x double] zeroinitializer
@memcpy_OC_result_OC_s = internal unnamed_addr constant [17 x i8] c"memcpy.result.m.\00"
@llvm_global_ctors_1 = appending global [1 x void ()*] [void ()* @_GLOBAL__I_a]
@llvm_global_ctors_0 = appending global [1 x i32] [i32 65535]
@inv_scale_vel = constant double 1.000000e+16, align 8
@inv_scale_pos = constant double 1.000000e+16, align 8
@burstwrite_OC_region = internal unnamed_addr constant [18 x i8] c"burstwrite.region\00"
@astroSim_str = internal unnamed_addr constant [9 x i8] c"astroSim\00"
@N = constant i32 9, align 4
@p_str7 = private unnamed_addr constant [12 x i8] c"hls_label_3\00", align 1
@p_str5 = private unnamed_addr constant [7 x i8] c"LOOP_X\00", align 1
@p_str3 = private unnamed_addr constant [9 x i8] c"AXILiteS\00", align 1
@p_str2 = private unnamed_addr constant [10 x i8] c"s_axilite\00", align 1
@p_str11 = private unnamed_addr constant [12 x i8] c"hls_label_2\00", align 1
@p_str10 = private unnamed_addr constant [12 x i8] c"hls_label_1\00", align 1
@p_str1 = private unnamed_addr constant [6 x i8] c"m_axi\00", align 1
@p_str = private unnamed_addr constant [1 x i8] zeroinitializer, align 1

define internal fastcc void @to_double(i64 %p_int_0_x_read, i64 %p_int_1_x_read, i64 %p_int_2_x_read, i64 %p_int_3_x_read, i64 %p_int_4_x_read, i64 %p_int_5_x_read, i64 %p_int_6_x_read, i64 %p_int_7_x_read, i64 %p_int_8_x_read, i64 %p_int_0_y_read, i64 %p_int_1_y_read, i64 %p_int_2_y_read, i64 %p_int_3_y_read, i64 %p_int_4_y_read, i64 %p_int_5_y_read, i64 %p_int_6_y_read, i64 %p_int_7_y_read, i64 %p_int_8_y_read, i64 %p_int_0_z_read, i64 %p_int_1_z_read, i64 %p_int_2_z_read, i64 %p_int_3_z_read, i64 %p_int_4_z_read, i64 %p_int_5_z_read, i64 %p_int_6_z_read, i64 %p_int_7_z_read, i64 %p_int_8_z_read, i64 %p_int_0_vx_read, i64 %p_int_1_vx_read, i64 %p_int_2_vx_read, i64 %p_int_3_vx_read, i64 %p_int_4_vx_read, i64 %p_int_5_vx_read, i64 %p_int_6_vx_read, i64 %p_int_7_vx_read, i64 %p_int_8_vx_read, i64 %p_int_0_vy_read, i64 %p_int_1_vy_read, i64 %p_int_2_vy_read, i64 %p_int_3_vy_read, i64 %p_int_4_vy_read, i64 %p_int_5_vy_read, i64 %p_int_6_vy_read, i64 %p_int_7_vy_read, i64 %p_int_8_vy_read, i64 %p_int_0_vz_read, i64 %p_int_1_vz_read, i64 %p_int_2_vz_read, i64 %p_int_3_vz_read, i64 %p_int_4_vz_read, i64 %p_int_5_vz_read, i64 %p_int_6_vz_read, i64 %p_int_7_vz_read, i64 %p_int_8_vz_read) {
  %p_int_8_vz_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_vz_read)
  %p_int_7_vz_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_vz_read)
  %p_int_6_vz_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_vz_read)
  %p_int_5_vz_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_vz_read)
  %p_int_4_vz_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_vz_read)
  %p_int_3_vz_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_vz_read)
  %p_int_2_vz_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_vz_read)
  %p_int_1_vz_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_vz_read)
  %p_int_0_vz_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_vz_read)
  %p_int_8_vy_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_vy_read)
  %p_int_7_vy_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_vy_read)
  %p_int_6_vy_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_vy_read)
  %p_int_5_vy_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_vy_read)
  %p_int_4_vy_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_vy_read)
  %p_int_3_vy_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_vy_read)
  %p_int_2_vy_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_vy_read)
  %p_int_1_vy_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_vy_read)
  %p_int_0_vy_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_vy_read)
  %p_int_8_vx_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_vx_read)
  %p_int_7_vx_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_vx_read)
  %p_int_6_vx_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_vx_read)
  %p_int_5_vx_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_vx_read)
  %p_int_4_vx_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_vx_read)
  %p_int_3_vx_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_vx_read)
  %p_int_2_vx_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_vx_read)
  %p_int_1_vx_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_vx_read)
  %p_int_0_vx_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_vx_read)
  %p_int_8_z_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_z_read)
  %p_int_7_z_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_z_read)
  %p_int_6_z_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_z_read)
  %p_int_5_z_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_z_read)
  %p_int_4_z_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_z_read)
  %p_int_3_z_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_z_read)
  %p_int_2_z_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_z_read)
  %p_int_1_z_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_z_read)
  %p_int_0_z_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_z_read)
  %p_int_8_y_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_y_read)
  %p_int_7_y_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_y_read)
  %p_int_6_y_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_y_read)
  %p_int_5_y_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_y_read)
  %p_int_4_y_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_y_read)
  %p_int_3_y_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_y_read)
  %p_int_2_y_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_y_read)
  %p_int_1_y_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_y_read)
  %p_int_0_y_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_y_read)
  %p_int_8_x_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_x_read)
  %p_int_7_x_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_x_read)
  %p_int_6_x_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_x_read)
  %p_int_5_x_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_x_read)
  %p_int_4_x_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_x_read)
  %p_int_3_x_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_x_read)
  %p_int_2_x_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_x_read)
  %p_int_1_x_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_x_read)
  %p_int_0_x_read_1 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_x_read)
  br label %1

; <label>:1                                       ; preds = %2, %0
  %i = phi i4 [ 0, %0 ], [ %i_1_2, %2 ]
  %tmp = icmp eq i4 %i, -7
  br i1 %tmp, label %3, label %_ifconv

_ifconv:                                          ; preds = %1
  %empty = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_1 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str10)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %sel_tmp = icmp eq i4 %i, 3
  %sel_tmp1 = select i1 %sel_tmp, i64 %p_int_3_x_read_1, i64 %p_int_6_x_read_1
  %sel_tmp2 = icmp eq i4 %i, 0
  %p_int_x_load_0_phi = select i1 %sel_tmp2, i64 %p_int_0_x_read_1, i64 %sel_tmp1
  %tmp_2 = sitofp i64 %p_int_x_load_0_phi to double
  %tmp_3 = fmul double %tmp_2, 1.000000e-16
  %p_int_y_load_0_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_0_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_3_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i64 %p_int_6_y_read_1, i4 %i)
  %tmp_4 = sitofp i64 %p_int_y_load_0_phi to double
  %tmp_5 = fmul double %tmp_4, 1.000000e-16
  %p_int_z_load_0_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_0_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_3_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i64 %p_int_6_z_read_1, i4 %i)
  %tmp_6 = sitofp i64 %p_int_z_load_0_phi to double
  %tmp_7 = fmul double %tmp_6, 1.000000e-16
  %p_int_vx_load_0_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_0_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_3_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i64 %p_int_6_vx_read_1, i4 %i)
  %tmp_8 = sitofp i64 %p_int_vx_load_0_phi to double
  %tmp_9 = fmul double %tmp_8, 1.000000e-16
  %p_int_vy_load_0_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_0_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_3_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i64 %p_int_6_vy_read_1, i4 %i)
  %tmp_s = sitofp i64 %p_int_vy_load_0_phi to double
  %tmp_10 = fmul double %tmp_s, 1.000000e-16
  %p_int_vz_load_0_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_0_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_3_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i64 %p_int_6_vz_read_1, i4 %i)
  %tmp_11 = sitofp i64 %p_int_vz_load_0_phi to double
  %tmp_12 = fmul double %tmp_11, 1.000000e-16
  %empty_6 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str10, i32 %tmp_1)
  %i_1_0_t = add i4 %i, 1
  %p_int_x_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_7_x_read_1, i64 %p_int_1_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_4_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_7_x_read_1, i64 %p_int_7_x_read_1, i4 %i_1_0_t)
  %tmp_2_1 = sitofp i64 %p_int_x_load_1_phi to double
  %tmp_3_1 = fmul double %tmp_2_1, 1.000000e-16
  %p_int_y_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_7_y_read_1, i64 %p_int_1_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_4_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_7_y_read_1, i64 %p_int_7_y_read_1, i4 %i_1_0_t)
  %tmp_4_1 = sitofp i64 %p_int_y_load_1_phi to double
  %tmp_5_1 = fmul double %tmp_4_1, 1.000000e-16
  %p_int_z_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_7_z_read_1, i64 %p_int_1_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_4_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_7_z_read_1, i64 %p_int_7_z_read_1, i4 %i_1_0_t)
  %tmp_6_1 = sitofp i64 %p_int_z_load_1_phi to double
  %tmp_7_1 = fmul double %tmp_6_1, 1.000000e-16
  %p_int_vx_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_7_vx_read_1, i64 %p_int_1_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_4_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_7_vx_read_1, i64 %p_int_7_vx_read_1, i4 %i_1_0_t)
  %tmp_8_1 = sitofp i64 %p_int_vx_load_1_phi to double
  %tmp_9_1 = fmul double %tmp_8_1, 1.000000e-16
  %p_int_vy_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_7_vy_read_1, i64 %p_int_1_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_4_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_7_vy_read_1, i64 %p_int_7_vy_read_1, i4 %i_1_0_t)
  %tmp_1_7 = sitofp i64 %p_int_vy_load_1_phi to double
  %tmp_10_1 = fmul double %tmp_1_7, 1.000000e-16
  %p_int_vz_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_7_vz_read_1, i64 %p_int_1_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_4_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_7_vz_read_1, i64 %p_int_7_vz_read_1, i4 %i_1_0_t)
  %tmp_11_1 = sitofp i64 %p_int_vz_load_1_phi to double
  %tmp_12_1 = fmul double %tmp_11_1, 1.000000e-16
  %i_1_1_t = add i4 %i, 2
  %p_int_x_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_8_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_2_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_5_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_8_x_read_1, i64 %p_int_8_x_read_1, i4 %i_1_1_t)
  %tmp_2_2 = sitofp i64 %p_int_x_load_2_phi to double
  %tmp_3_2 = fmul double %tmp_2_2, 1.000000e-16
  %p_int_y_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_8_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_2_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_5_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_8_y_read_1, i64 %p_int_8_y_read_1, i4 %i_1_1_t)
  %tmp_4_2 = sitofp i64 %p_int_y_load_2_phi to double
  %tmp_5_2 = fmul double %tmp_4_2, 1.000000e-16
  %p_int_z_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_8_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_2_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_5_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_8_z_read_1, i64 %p_int_8_z_read_1, i4 %i_1_1_t)
  %tmp_6_2 = sitofp i64 %p_int_z_load_2_phi to double
  %tmp_7_2 = fmul double %tmp_6_2, 1.000000e-16
  %p_int_vx_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_8_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_2_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_5_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_8_vx_read_1, i64 %p_int_8_vx_read_1, i4 %i_1_1_t)
  %tmp_8_2 = sitofp i64 %p_int_vx_load_2_phi to double
  %tmp_9_2 = fmul double %tmp_8_2, 1.000000e-16
  %p_int_vy_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_8_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_2_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_5_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_8_vy_read_1, i64 %p_int_8_vy_read_1, i4 %i_1_1_t)
  %tmp_2_8 = sitofp i64 %p_int_vy_load_2_phi to double
  %tmp_10_2 = fmul double %tmp_2_8, 1.000000e-16
  %p_int_vz_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_8_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_2_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_5_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_8_vz_read_1, i64 %p_int_8_vz_read_1, i4 %i_1_1_t)
  %tmp_11_2 = sitofp i64 %p_int_vz_load_2_phi to double
  %tmp_12_2 = fmul double %tmp_11_2, 1.000000e-16
  switch i4 %i, label %branch24 [
    i4 0, label %branch18
    i4 3, label %branch21
  ]

; <label>:2                                       ; preds = %branch24, %branch21, %branch18
  %i_1_2 = add i4 %i, 3
  br label %1

; <label>:3                                       ; preds = %1
  ret void

branch18:                                         ; preds = %_ifconv
  store double %tmp_3, double* @p_x_0, align 16
  store double %tmp_5, double* @p_y_0, align 8
  store double %tmp_7, double* @p_z_0, align 16
  store double %tmp_9, double* @p_vx_0, align 8
  store double %tmp_10, double* @p_vy_0, align 16
  store double %tmp_12, double* @p_vz_0, align 8
  store double %tmp_3_1, double* @p_x_1, align 16
  store double %tmp_5_1, double* @p_y_1, align 8
  store double %tmp_7_1, double* @p_z_1, align 16
  store double %tmp_9_1, double* @p_vx_1, align 8
  store double %tmp_10_1, double* @p_vy_1, align 16
  store double %tmp_12_1, double* @p_vz_1, align 8
  store double %tmp_3_2, double* @p_x_2, align 16
  store double %tmp_5_2, double* @p_y_2, align 8
  store double %tmp_7_2, double* @p_z_2, align 16
  store double %tmp_9_2, double* @p_vx_2, align 8
  store double %tmp_10_2, double* @p_vy_2, align 16
  store double %tmp_12_2, double* @p_vz_2, align 8
  br label %2

branch21:                                         ; preds = %_ifconv
  store double %tmp_3, double* @p_x_3, align 16
  store double %tmp_5, double* @p_y_3, align 8
  store double %tmp_7, double* @p_z_3, align 16
  store double %tmp_9, double* @p_vx_3, align 8
  store double %tmp_10, double* @p_vy_3, align 16
  store double %tmp_12, double* @p_vz_3, align 8
  store double %tmp_3_1, double* @p_x_4, align 16
  store double %tmp_5_1, double* @p_y_4, align 8
  store double %tmp_7_1, double* @p_z_4, align 16
  store double %tmp_9_1, double* @p_vx_4, align 8
  store double %tmp_10_1, double* @p_vy_4, align 16
  store double %tmp_12_1, double* @p_vz_4, align 8
  store double %tmp_3_2, double* @p_x_5, align 16
  store double %tmp_5_2, double* @p_y_5, align 8
  store double %tmp_7_2, double* @p_z_5, align 16
  store double %tmp_9_2, double* @p_vx_5, align 8
  store double %tmp_10_2, double* @p_vy_5, align 16
  store double %tmp_12_2, double* @p_vz_5, align 8
  br label %2

branch24:                                         ; preds = %_ifconv
  store double %tmp_3, double* @p_x_6, align 16
  store double %tmp_5, double* @p_y_6, align 8
  store double %tmp_7, double* @p_z_6, align 16
  store double %tmp_9, double* @p_vx_6, align 8
  store double %tmp_10, double* @p_vy_6, align 16
  store double %tmp_12, double* @p_vz_6, align 8
  store double %tmp_3_1, double* @p_x_7, align 16
  store double %tmp_5_1, double* @p_y_7, align 8
  store double %tmp_7_1, double* @p_z_7, align 16
  store double %tmp_9_1, double* @p_vx_7, align 8
  store double %tmp_10_1, double* @p_vy_7, align 16
  store double %tmp_12_1, double* @p_vz_7, align 8
  store double %tmp_3_2, double* @p_x_8, align 16
  store double %tmp_5_2, double* @p_y_8, align 8
  store double %tmp_7_2, double* @p_z_8, align 16
  store double %tmp_9_2, double* @p_vx_8, align 8
  store double %tmp_10_2, double* @p_vy_8, align 16
  store double %tmp_12_2, double* @p_vz_8, align 8
  br label %2
}

declare double @llvm.sqrt.f64(double) nounwind readonly

declare i64 @llvm.part.select.i64(i64, i32, i32) nounwind readnone

declare i169 @llvm.part.select.i169(i169, i32, i32) nounwind readnone

declare void @llvm.dbg.value(metadata, i64, metadata) nounwind readnone

define internal fastcc void @gravity() nounwind uwtable {
._crit_edge.0.0:
  %p_x_0_load = load double* @p_x_0, align 16
  %p_x_1_load = load double* @p_x_1, align 16
  %dx_0_1 = fsub double %p_x_0_load, %p_x_1_load
  %p_y_0_load = load double* @p_y_0, align 16
  %p_y_1_load = load double* @p_y_1, align 8
  %dy_0_1 = fsub double %p_y_0_load, %p_y_1_load
  %p_z_0_load = load double* @p_z_0, align 16
  %p_z_1_load = load double* @p_z_1, align 16
  %dz_0_1 = fsub double %p_z_0_load, %p_z_1_load
  %tmp_35_0_1 = fmul double %dx_0_1, %dx_0_1
  %tmp_36_0_1 = fmul double %dy_0_1, %dy_0_1
  %tmp_37_0_1 = fadd double %tmp_35_0_1, %tmp_36_0_1
  %tmp_38_0_1 = fmul double %dz_0_1, %dz_0_1
  %pre_sqrt_0_1 = fadd double %tmp_37_0_1, %tmp_38_0_1
  %p_r_0_1 = call double @llvm.sqrt.f64(double %pre_sqrt_0_1)
  %tmp_39_0_1 = fmul double %pre_sqrt_0_1, %p_r_0_1
  %tmp_40_0_1 = fdiv double -1.000000e+00, %tmp_39_0_1
  %p_m_1_load = load double* @p_m_1, align 8
  %prefact_0_1 = fmul double %tmp_40_0_1, %p_m_1_load
  %tmp_41_0_1 = fmul double %prefact_0_1, %dx_0_1
  %tmp_42_0_1 = fadd double %tmp_41_0_1, 0.000000e+00
  %tmp_43_0_1 = fmul double %prefact_0_1, %dy_0_1
  %tmp_44_0_1 = fadd double %tmp_43_0_1, 0.000000e+00
  %tmp_45_0_1 = fmul double %prefact_0_1, %dz_0_1
  %tmp_46_0_1 = fadd double %tmp_45_0_1, 0.000000e+00
  %p_x_2_load = load double* @p_x_2, align 16
  %dx_0_2 = fsub double %p_x_0_load, %p_x_2_load
  %p_y_2_load = load double* @p_y_2, align 16
  %dy_0_2 = fsub double %p_y_0_load, %p_y_2_load
  %p_z_2_load = load double* @p_z_2, align 16
  %dz_0_2 = fsub double %p_z_0_load, %p_z_2_load
  %tmp_35_0_2 = fmul double %dx_0_2, %dx_0_2
  %tmp_36_0_2 = fmul double %dy_0_2, %dy_0_2
  %tmp_37_0_2 = fadd double %tmp_35_0_2, %tmp_36_0_2
  %tmp_38_0_2 = fmul double %dz_0_2, %dz_0_2
  %pre_sqrt_0_2 = fadd double %tmp_37_0_2, %tmp_38_0_2
  %p_r_0_2 = call double @llvm.sqrt.f64(double %pre_sqrt_0_2)
  %tmp_39_0_2 = fmul double %pre_sqrt_0_2, %p_r_0_2
  %tmp_40_0_2 = fdiv double -1.000000e+00, %tmp_39_0_2
  %p_m_2_load = load double* @p_m_2, align 16
  %prefact_0_2 = fmul double %tmp_40_0_2, %p_m_2_load
  %tmp_41_0_2 = fmul double %prefact_0_2, %dx_0_2
  %tmp_42_0_2 = fadd double %tmp_42_0_1, %tmp_41_0_2
  %tmp_43_0_2 = fmul double %prefact_0_2, %dy_0_2
  %tmp_44_0_2 = fadd double %tmp_44_0_1, %tmp_43_0_2
  %tmp_45_0_2 = fmul double %prefact_0_2, %dz_0_2
  %tmp_46_0_2 = fadd double %tmp_46_0_1, %tmp_45_0_2
  %p_x_3_load = load double* @p_x_3, align 16
  %dx_0_3 = fsub double %p_x_0_load, %p_x_3_load
  %p_y_3_load = load double* @p_y_3, align 8
  %dy_0_3 = fsub double %p_y_0_load, %p_y_3_load
  %p_z_3_load = load double* @p_z_3, align 16
  %dz_0_3 = fsub double %p_z_0_load, %p_z_3_load
  %tmp_35_0_3 = fmul double %dx_0_3, %dx_0_3
  %tmp_36_0_3 = fmul double %dy_0_3, %dy_0_3
  %tmp_37_0_3 = fadd double %tmp_35_0_3, %tmp_36_0_3
  %tmp_38_0_3 = fmul double %dz_0_3, %dz_0_3
  %pre_sqrt_0_3 = fadd double %tmp_37_0_3, %tmp_38_0_3
  %p_r_0_3 = call double @llvm.sqrt.f64(double %pre_sqrt_0_3)
  %tmp_39_0_3 = fmul double %pre_sqrt_0_3, %p_r_0_3
  %tmp_40_0_3 = fdiv double -1.000000e+00, %tmp_39_0_3
  %p_m_3_load = load double* @p_m_3, align 8
  %prefact_0_3 = fmul double %tmp_40_0_3, %p_m_3_load
  %tmp_41_0_3 = fmul double %prefact_0_3, %dx_0_3
  %tmp_42_0_3 = fadd double %tmp_42_0_2, %tmp_41_0_3
  %tmp_43_0_3 = fmul double %prefact_0_3, %dy_0_3
  %tmp_44_0_3 = fadd double %tmp_44_0_2, %tmp_43_0_3
  %tmp_45_0_3 = fmul double %prefact_0_3, %dz_0_3
  %tmp_46_0_3 = fadd double %tmp_46_0_2, %tmp_45_0_3
  %p_x_4_load = load double* @p_x_4, align 16
  %dx_0_4 = fsub double %p_x_0_load, %p_x_4_load
  %p_y_4_load = load double* @p_y_4, align 16
  %dy_0_4 = fsub double %p_y_0_load, %p_y_4_load
  %p_z_4_load = load double* @p_z_4, align 16
  %dz_0_4 = fsub double %p_z_0_load, %p_z_4_load
  %tmp_35_0_4 = fmul double %dx_0_4, %dx_0_4
  %tmp_36_0_4 = fmul double %dy_0_4, %dy_0_4
  %tmp_37_0_4 = fadd double %tmp_35_0_4, %tmp_36_0_4
  %tmp_38_0_4 = fmul double %dz_0_4, %dz_0_4
  %pre_sqrt_0_4 = fadd double %tmp_37_0_4, %tmp_38_0_4
  %p_r_0_4 = call double @llvm.sqrt.f64(double %pre_sqrt_0_4)
  %tmp_39_0_4 = fmul double %pre_sqrt_0_4, %p_r_0_4
  %tmp_40_0_4 = fdiv double -1.000000e+00, %tmp_39_0_4
  %p_m_4_load = load double* @p_m_4, align 16
  %prefact_0_4 = fmul double %tmp_40_0_4, %p_m_4_load
  %tmp_41_0_4 = fmul double %prefact_0_4, %dx_0_4
  %tmp_42_0_4 = fadd double %tmp_42_0_3, %tmp_41_0_4
  %tmp_43_0_4 = fmul double %prefact_0_4, %dy_0_4
  %tmp_44_0_4 = fadd double %tmp_44_0_3, %tmp_43_0_4
  %tmp_45_0_4 = fmul double %prefact_0_4, %dz_0_4
  %tmp_46_0_4 = fadd double %tmp_46_0_3, %tmp_45_0_4
  %p_x_5_load = load double* @p_x_5, align 16
  %dx_0_5 = fsub double %p_x_0_load, %p_x_5_load
  %p_y_5_load = load double* @p_y_5, align 8
  %dy_0_5 = fsub double %p_y_0_load, %p_y_5_load
  %p_z_5_load = load double* @p_z_5, align 16
  %dz_0_5 = fsub double %p_z_0_load, %p_z_5_load
  %tmp_35_0_5 = fmul double %dx_0_5, %dx_0_5
  %tmp_36_0_5 = fmul double %dy_0_5, %dy_0_5
  %tmp_37_0_5 = fadd double %tmp_35_0_5, %tmp_36_0_5
  %tmp_38_0_5 = fmul double %dz_0_5, %dz_0_5
  %pre_sqrt_0_5 = fadd double %tmp_37_0_5, %tmp_38_0_5
  %p_r_0_5 = call double @llvm.sqrt.f64(double %pre_sqrt_0_5)
  %tmp_39_0_5 = fmul double %pre_sqrt_0_5, %p_r_0_5
  %tmp_40_0_5 = fdiv double -1.000000e+00, %tmp_39_0_5
  %p_m_5_load = load double* @p_m_5, align 8
  %prefact_0_5 = fmul double %tmp_40_0_5, %p_m_5_load
  %tmp_41_0_5 = fmul double %prefact_0_5, %dx_0_5
  %tmp_42_0_5 = fadd double %tmp_42_0_4, %tmp_41_0_5
  %tmp_43_0_5 = fmul double %prefact_0_5, %dy_0_5
  %tmp_44_0_5 = fadd double %tmp_44_0_4, %tmp_43_0_5
  %tmp_45_0_5 = fmul double %prefact_0_5, %dz_0_5
  %tmp_46_0_5 = fadd double %tmp_46_0_4, %tmp_45_0_5
  %p_x_6_load = load double* @p_x_6, align 16
  %dx_0_6 = fsub double %p_x_0_load, %p_x_6_load
  %p_y_6_load = load double* @p_y_6, align 16
  %dy_0_6 = fsub double %p_y_0_load, %p_y_6_load
  %p_z_6_load = load double* @p_z_6, align 16
  %dz_0_6 = fsub double %p_z_0_load, %p_z_6_load
  %tmp_35_0_6 = fmul double %dx_0_6, %dx_0_6
  %tmp_36_0_6 = fmul double %dy_0_6, %dy_0_6
  %tmp_37_0_6 = fadd double %tmp_35_0_6, %tmp_36_0_6
  %tmp_38_0_6 = fmul double %dz_0_6, %dz_0_6
  %pre_sqrt_0_6 = fadd double %tmp_37_0_6, %tmp_38_0_6
  %p_r_0_6 = call double @llvm.sqrt.f64(double %pre_sqrt_0_6)
  %tmp_39_0_6 = fmul double %pre_sqrt_0_6, %p_r_0_6
  %tmp_40_0_6 = fdiv double -1.000000e+00, %tmp_39_0_6
  %p_m_6_load = load double* @p_m_6, align 16
  %prefact_0_6 = fmul double %tmp_40_0_6, %p_m_6_load
  %tmp_41_0_6 = fmul double %prefact_0_6, %dx_0_6
  %tmp_42_0_6 = fadd double %tmp_42_0_5, %tmp_41_0_6
  %tmp_43_0_6 = fmul double %prefact_0_6, %dy_0_6
  %tmp_44_0_6 = fadd double %tmp_44_0_5, %tmp_43_0_6
  %tmp_45_0_6 = fmul double %prefact_0_6, %dz_0_6
  %tmp_46_0_6 = fadd double %tmp_46_0_5, %tmp_45_0_6
  %p_x_7_load = load double* @p_x_7, align 16
  %dx_0_7 = fsub double %p_x_0_load, %p_x_7_load
  %p_y_7_load = load double* @p_y_7, align 8
  %dy_0_7 = fsub double %p_y_0_load, %p_y_7_load
  %p_z_7_load = load double* @p_z_7, align 16
  %dz_0_7 = fsub double %p_z_0_load, %p_z_7_load
  %tmp_35_0_7 = fmul double %dx_0_7, %dx_0_7
  %tmp_36_0_7 = fmul double %dy_0_7, %dy_0_7
  %tmp_37_0_7 = fadd double %tmp_35_0_7, %tmp_36_0_7
  %tmp_38_0_7 = fmul double %dz_0_7, %dz_0_7
  %pre_sqrt_0_7 = fadd double %tmp_37_0_7, %tmp_38_0_7
  %p_r_0_7 = call double @llvm.sqrt.f64(double %pre_sqrt_0_7)
  %tmp_39_0_7 = fmul double %pre_sqrt_0_7, %p_r_0_7
  %tmp_40_0_7 = fdiv double -1.000000e+00, %tmp_39_0_7
  %p_m_7_load = load double* @p_m_7, align 8
  %prefact_0_7 = fmul double %tmp_40_0_7, %p_m_7_load
  %tmp_41_0_7 = fmul double %prefact_0_7, %dx_0_7
  %tmp_42_0_7 = fadd double %tmp_42_0_6, %tmp_41_0_7
  %tmp_43_0_7 = fmul double %prefact_0_7, %dy_0_7
  %tmp_44_0_7 = fadd double %tmp_44_0_6, %tmp_43_0_7
  %tmp_45_0_7 = fmul double %prefact_0_7, %dz_0_7
  %tmp_46_0_7 = fadd double %tmp_46_0_6, %tmp_45_0_7
  %p_x_8_load = load double* @p_x_8, align 16
  %dx_0_8 = fsub double %p_x_0_load, %p_x_8_load
  %p_y_8_load = load double* @p_y_8, align 16
  %dy_0_8 = fsub double %p_y_0_load, %p_y_8_load
  %p_z_8_load = load double* @p_z_8, align 16
  %dz_0_8 = fsub double %p_z_0_load, %p_z_8_load
  %tmp_35_0_8 = fmul double %dx_0_8, %dx_0_8
  %tmp_36_0_8 = fmul double %dy_0_8, %dy_0_8
  %tmp_37_0_8 = fadd double %tmp_35_0_8, %tmp_36_0_8
  %tmp_38_0_8 = fmul double %dz_0_8, %dz_0_8
  %pre_sqrt_0_8 = fadd double %tmp_37_0_8, %tmp_38_0_8
  %p_r_0_8 = call double @llvm.sqrt.f64(double %pre_sqrt_0_8)
  %tmp_39_0_8 = fmul double %pre_sqrt_0_8, %p_r_0_8
  %tmp_40_0_8 = fdiv double -1.000000e+00, %tmp_39_0_8
  %p_m_8_load = load double* @p_m_8, align 16
  %prefact_0_8 = fmul double %tmp_40_0_8, %p_m_8_load
  %tmp_41_0_8 = fmul double %prefact_0_8, %dx_0_8
  %tmp_42_0_8 = fadd double %tmp_42_0_7, %tmp_41_0_8
  store double %tmp_42_0_8, double* @p_ax_0, align 16
  %tmp_43_0_8 = fmul double %prefact_0_8, %dy_0_8
  %tmp_44_0_8 = fadd double %tmp_44_0_7, %tmp_43_0_8
  store double %tmp_44_0_8, double* @p_ay_0, align 16
  %tmp_45_0_8 = fmul double %prefact_0_8, %dz_0_8
  %tmp_46_0_8 = fadd double %tmp_46_0_7, %tmp_45_0_8
  store double %tmp_46_0_8, double* @p_az_0, align 16
  %dx_1 = fsub double %p_x_1_load, %p_x_0_load
  %dy_1 = fsub double %p_y_1_load, %p_y_0_load
  %dz_1 = fsub double %p_z_1_load, %p_z_0_load
  %tmp_35_1 = fmul double %dx_1, %dx_1
  %tmp_36_1 = fmul double %dy_1, %dy_1
  %tmp_37_1 = fadd double %tmp_35_1, %tmp_36_1
  %tmp_38_1 = fmul double %dz_1, %dz_1
  %pre_sqrt_1 = fadd double %tmp_37_1, %tmp_38_1
  %p_r_1 = call double @llvm.sqrt.f64(double %pre_sqrt_1)
  %tmp_39_1 = fmul double %pre_sqrt_1, %p_r_1
  %tmp_40_1 = fdiv double -1.000000e+00, %tmp_39_1
  %p_m_0_load = load double* @p_m_0, align 16
  %prefact_1 = fmul double %tmp_40_1, %p_m_0_load
  %tmp_41_1 = fmul double %prefact_1, %dx_1
  %tmp_42_1 = fadd double %tmp_41_1, 0.000000e+00
  %tmp_43_1 = fmul double %prefact_1, %dy_1
  %tmp_44_1 = fadd double %tmp_43_1, 0.000000e+00
  %tmp_45_1 = fmul double %prefact_1, %dz_1
  %tmp_46_1 = fadd double %tmp_45_1, 0.000000e+00
  %dx_1_2 = fsub double %p_x_1_load, %p_x_2_load
  %dy_1_2 = fsub double %p_y_1_load, %p_y_2_load
  %dz_1_2 = fsub double %p_z_1_load, %p_z_2_load
  %tmp_35_1_2 = fmul double %dx_1_2, %dx_1_2
  %tmp_36_1_2 = fmul double %dy_1_2, %dy_1_2
  %tmp_37_1_2 = fadd double %tmp_35_1_2, %tmp_36_1_2
  %tmp_38_1_2 = fmul double %dz_1_2, %dz_1_2
  %pre_sqrt_1_2 = fadd double %tmp_37_1_2, %tmp_38_1_2
  %p_r_1_2 = call double @llvm.sqrt.f64(double %pre_sqrt_1_2)
  %tmp_39_1_2 = fmul double %pre_sqrt_1_2, %p_r_1_2
  %tmp_40_1_2 = fdiv double -1.000000e+00, %tmp_39_1_2
  %prefact_1_2 = fmul double %tmp_40_1_2, %p_m_2_load
  %tmp_41_1_2 = fmul double %prefact_1_2, %dx_1_2
  %tmp_42_1_2 = fadd double %tmp_42_1, %tmp_41_1_2
  %tmp_43_1_2 = fmul double %prefact_1_2, %dy_1_2
  %tmp_44_1_2 = fadd double %tmp_44_1, %tmp_43_1_2
  %tmp_45_1_2 = fmul double %prefact_1_2, %dz_1_2
  %tmp_46_1_2 = fadd double %tmp_46_1, %tmp_45_1_2
  %dx_1_3 = fsub double %p_x_1_load, %p_x_3_load
  %dy_1_3 = fsub double %p_y_1_load, %p_y_3_load
  %dz_1_3 = fsub double %p_z_1_load, %p_z_3_load
  %tmp_35_1_3 = fmul double %dx_1_3, %dx_1_3
  %tmp_36_1_3 = fmul double %dy_1_3, %dy_1_3
  %tmp_37_1_3 = fadd double %tmp_35_1_3, %tmp_36_1_3
  %tmp_38_1_3 = fmul double %dz_1_3, %dz_1_3
  %pre_sqrt_1_3 = fadd double %tmp_37_1_3, %tmp_38_1_3
  %p_r_1_3 = call double @llvm.sqrt.f64(double %pre_sqrt_1_3)
  %tmp_39_1_3 = fmul double %pre_sqrt_1_3, %p_r_1_3
  %tmp_40_1_3 = fdiv double -1.000000e+00, %tmp_39_1_3
  %prefact_1_3 = fmul double %tmp_40_1_3, %p_m_3_load
  %tmp_41_1_3 = fmul double %prefact_1_3, %dx_1_3
  %tmp_42_1_3 = fadd double %tmp_42_1_2, %tmp_41_1_3
  %tmp_43_1_3 = fmul double %prefact_1_3, %dy_1_3
  %tmp_44_1_3 = fadd double %tmp_44_1_2, %tmp_43_1_3
  %tmp_45_1_3 = fmul double %prefact_1_3, %dz_1_3
  %tmp_46_1_3 = fadd double %tmp_46_1_2, %tmp_45_1_3
  %dx_1_4 = fsub double %p_x_1_load, %p_x_4_load
  %dy_1_4 = fsub double %p_y_1_load, %p_y_4_load
  %dz_1_4 = fsub double %p_z_1_load, %p_z_4_load
  %tmp_35_1_4 = fmul double %dx_1_4, %dx_1_4
  %tmp_36_1_4 = fmul double %dy_1_4, %dy_1_4
  %tmp_37_1_4 = fadd double %tmp_35_1_4, %tmp_36_1_4
  %tmp_38_1_4 = fmul double %dz_1_4, %dz_1_4
  %pre_sqrt_1_4 = fadd double %tmp_37_1_4, %tmp_38_1_4
  %p_r_1_4 = call double @llvm.sqrt.f64(double %pre_sqrt_1_4)
  %tmp_39_1_4 = fmul double %pre_sqrt_1_4, %p_r_1_4
  %tmp_40_1_4 = fdiv double -1.000000e+00, %tmp_39_1_4
  %prefact_1_4 = fmul double %tmp_40_1_4, %p_m_4_load
  %tmp_41_1_4 = fmul double %prefact_1_4, %dx_1_4
  %tmp_42_1_4 = fadd double %tmp_42_1_3, %tmp_41_1_4
  %tmp_43_1_4 = fmul double %prefact_1_4, %dy_1_4
  %tmp_44_1_4 = fadd double %tmp_44_1_3, %tmp_43_1_4
  %tmp_45_1_4 = fmul double %prefact_1_4, %dz_1_4
  %tmp_46_1_4 = fadd double %tmp_46_1_3, %tmp_45_1_4
  %dx_1_5 = fsub double %p_x_1_load, %p_x_5_load
  %dy_1_5 = fsub double %p_y_1_load, %p_y_5_load
  %dz_1_5 = fsub double %p_z_1_load, %p_z_5_load
  %tmp_35_1_5 = fmul double %dx_1_5, %dx_1_5
  %tmp_36_1_5 = fmul double %dy_1_5, %dy_1_5
  %tmp_37_1_5 = fadd double %tmp_35_1_5, %tmp_36_1_5
  %tmp_38_1_5 = fmul double %dz_1_5, %dz_1_5
  %pre_sqrt_1_5 = fadd double %tmp_37_1_5, %tmp_38_1_5
  %p_r_1_5 = call double @llvm.sqrt.f64(double %pre_sqrt_1_5)
  %tmp_39_1_5 = fmul double %pre_sqrt_1_5, %p_r_1_5
  %tmp_40_1_5 = fdiv double -1.000000e+00, %tmp_39_1_5
  %prefact_1_5 = fmul double %tmp_40_1_5, %p_m_5_load
  %tmp_41_1_5 = fmul double %prefact_1_5, %dx_1_5
  %tmp_42_1_5 = fadd double %tmp_42_1_4, %tmp_41_1_5
  %tmp_43_1_5 = fmul double %prefact_1_5, %dy_1_5
  %tmp_44_1_5 = fadd double %tmp_44_1_4, %tmp_43_1_5
  %tmp_45_1_5 = fmul double %prefact_1_5, %dz_1_5
  %tmp_46_1_5 = fadd double %tmp_46_1_4, %tmp_45_1_5
  %dx_1_6 = fsub double %p_x_1_load, %p_x_6_load
  %dy_1_6 = fsub double %p_y_1_load, %p_y_6_load
  %dz_1_6 = fsub double %p_z_1_load, %p_z_6_load
  %tmp_35_1_6 = fmul double %dx_1_6, %dx_1_6
  %tmp_36_1_6 = fmul double %dy_1_6, %dy_1_6
  %tmp_37_1_6 = fadd double %tmp_35_1_6, %tmp_36_1_6
  %tmp_38_1_6 = fmul double %dz_1_6, %dz_1_6
  %pre_sqrt_1_6 = fadd double %tmp_37_1_6, %tmp_38_1_6
  %p_r_1_6 = call double @llvm.sqrt.f64(double %pre_sqrt_1_6)
  %tmp_39_1_6 = fmul double %pre_sqrt_1_6, %p_r_1_6
  %tmp_40_1_6 = fdiv double -1.000000e+00, %tmp_39_1_6
  %prefact_1_6 = fmul double %tmp_40_1_6, %p_m_6_load
  %tmp_41_1_6 = fmul double %prefact_1_6, %dx_1_6
  %tmp_42_1_6 = fadd double %tmp_42_1_5, %tmp_41_1_6
  %tmp_43_1_6 = fmul double %prefact_1_6, %dy_1_6
  %tmp_44_1_6 = fadd double %tmp_44_1_5, %tmp_43_1_6
  %tmp_45_1_6 = fmul double %prefact_1_6, %dz_1_6
  %tmp_46_1_6 = fadd double %tmp_46_1_5, %tmp_45_1_6
  %dx_1_7 = fsub double %p_x_1_load, %p_x_7_load
  %dy_1_7 = fsub double %p_y_1_load, %p_y_7_load
  %dz_1_7 = fsub double %p_z_1_load, %p_z_7_load
  %tmp_35_1_7 = fmul double %dx_1_7, %dx_1_7
  %tmp_36_1_7 = fmul double %dy_1_7, %dy_1_7
  %tmp_37_1_7 = fadd double %tmp_35_1_7, %tmp_36_1_7
  %tmp_38_1_7 = fmul double %dz_1_7, %dz_1_7
  %pre_sqrt_1_7 = fadd double %tmp_37_1_7, %tmp_38_1_7
  %p_r_1_7 = call double @llvm.sqrt.f64(double %pre_sqrt_1_7)
  %tmp_39_1_7 = fmul double %pre_sqrt_1_7, %p_r_1_7
  %tmp_40_1_7 = fdiv double -1.000000e+00, %tmp_39_1_7
  %prefact_1_7 = fmul double %tmp_40_1_7, %p_m_7_load
  %tmp_41_1_7 = fmul double %prefact_1_7, %dx_1_7
  %tmp_42_1_7 = fadd double %tmp_42_1_6, %tmp_41_1_7
  %tmp_43_1_7 = fmul double %prefact_1_7, %dy_1_7
  %tmp_44_1_7 = fadd double %tmp_44_1_6, %tmp_43_1_7
  %tmp_45_1_7 = fmul double %prefact_1_7, %dz_1_7
  %tmp_46_1_7 = fadd double %tmp_46_1_6, %tmp_45_1_7
  %dx_1_8 = fsub double %p_x_1_load, %p_x_8_load
  %dy_1_8 = fsub double %p_y_1_load, %p_y_8_load
  %dz_1_8 = fsub double %p_z_1_load, %p_z_8_load
  %tmp_35_1_8 = fmul double %dx_1_8, %dx_1_8
  %tmp_36_1_8 = fmul double %dy_1_8, %dy_1_8
  %tmp_37_1_8 = fadd double %tmp_35_1_8, %tmp_36_1_8
  %tmp_38_1_8 = fmul double %dz_1_8, %dz_1_8
  %pre_sqrt_1_8 = fadd double %tmp_37_1_8, %tmp_38_1_8
  %p_r_1_8 = call double @llvm.sqrt.f64(double %pre_sqrt_1_8)
  %tmp_39_1_8 = fmul double %pre_sqrt_1_8, %p_r_1_8
  %tmp_40_1_8 = fdiv double -1.000000e+00, %tmp_39_1_8
  %prefact_1_8 = fmul double %tmp_40_1_8, %p_m_8_load
  %tmp_41_1_8 = fmul double %prefact_1_8, %dx_1_8
  %tmp_42_1_8 = fadd double %tmp_42_1_7, %tmp_41_1_8
  store double %tmp_42_1_8, double* @p_ax_1, align 16
  %tmp_43_1_8 = fmul double %prefact_1_8, %dy_1_8
  %tmp_44_1_8 = fadd double %tmp_44_1_7, %tmp_43_1_8
  store double %tmp_44_1_8, double* @p_ay_1, align 8
  %tmp_45_1_8 = fmul double %prefact_1_8, %dz_1_8
  %tmp_46_1_8 = fadd double %tmp_46_1_7, %tmp_45_1_8
  store double %tmp_46_1_8, double* @p_az_1, align 16
  %dx_2 = fsub double %p_x_2_load, %p_x_0_load
  %dy_2 = fsub double %p_y_2_load, %p_y_0_load
  %dz_2 = fsub double %p_z_2_load, %p_z_0_load
  %tmp_35_2 = fmul double %dx_2, %dx_2
  %tmp_36_2 = fmul double %dy_2, %dy_2
  %tmp_37_2 = fadd double %tmp_35_2, %tmp_36_2
  %tmp_38_2 = fmul double %dz_2, %dz_2
  %pre_sqrt_2 = fadd double %tmp_37_2, %tmp_38_2
  %p_r_2 = call double @llvm.sqrt.f64(double %pre_sqrt_2)
  %tmp_39_2 = fmul double %pre_sqrt_2, %p_r_2
  %tmp_40_2 = fdiv double -1.000000e+00, %tmp_39_2
  %prefact_2 = fmul double %tmp_40_2, %p_m_0_load
  %tmp_41_2 = fmul double %prefact_2, %dx_2
  %tmp_42_2 = fadd double %tmp_41_2, 0.000000e+00
  %tmp_43_2 = fmul double %prefact_2, %dy_2
  %tmp_44_2 = fadd double %tmp_43_2, 0.000000e+00
  %tmp_45_2 = fmul double %prefact_2, %dz_2
  %tmp_46_2 = fadd double %tmp_45_2, 0.000000e+00
  %dx_2_1 = fsub double %p_x_2_load, %p_x_1_load
  %dy_2_1 = fsub double %p_y_2_load, %p_y_1_load
  %dz_2_1 = fsub double %p_z_2_load, %p_z_1_load
  %tmp_35_2_1 = fmul double %dx_2_1, %dx_2_1
  %tmp_36_2_1 = fmul double %dy_2_1, %dy_2_1
  %tmp_37_2_1 = fadd double %tmp_35_2_1, %tmp_36_2_1
  %tmp_38_2_1 = fmul double %dz_2_1, %dz_2_1
  %pre_sqrt_2_1 = fadd double %tmp_37_2_1, %tmp_38_2_1
  %p_r_2_1 = call double @llvm.sqrt.f64(double %pre_sqrt_2_1)
  %tmp_39_2_1 = fmul double %pre_sqrt_2_1, %p_r_2_1
  %tmp_40_2_1 = fdiv double -1.000000e+00, %tmp_39_2_1
  %prefact_2_1 = fmul double %tmp_40_2_1, %p_m_1_load
  %tmp_41_2_1 = fmul double %prefact_2_1, %dx_2_1
  %tmp_42_2_1 = fadd double %tmp_42_2, %tmp_41_2_1
  %tmp_43_2_1 = fmul double %prefact_2_1, %dy_2_1
  %tmp_44_2_1 = fadd double %tmp_44_2, %tmp_43_2_1
  %tmp_45_2_1 = fmul double %prefact_2_1, %dz_2_1
  %tmp_46_2_1 = fadd double %tmp_46_2, %tmp_45_2_1
  %dx_2_3 = fsub double %p_x_2_load, %p_x_3_load
  %dy_2_3 = fsub double %p_y_2_load, %p_y_3_load
  %dz_2_3 = fsub double %p_z_2_load, %p_z_3_load
  %tmp_35_2_3 = fmul double %dx_2_3, %dx_2_3
  %tmp_36_2_3 = fmul double %dy_2_3, %dy_2_3
  %tmp_37_2_3 = fadd double %tmp_35_2_3, %tmp_36_2_3
  %tmp_38_2_3 = fmul double %dz_2_3, %dz_2_3
  %pre_sqrt_2_3 = fadd double %tmp_37_2_3, %tmp_38_2_3
  %p_r_2_3 = call double @llvm.sqrt.f64(double %pre_sqrt_2_3)
  %tmp_39_2_3 = fmul double %pre_sqrt_2_3, %p_r_2_3
  %tmp_40_2_3 = fdiv double -1.000000e+00, %tmp_39_2_3
  %prefact_2_3 = fmul double %tmp_40_2_3, %p_m_3_load
  %tmp_41_2_3 = fmul double %prefact_2_3, %dx_2_3
  %tmp_42_2_3 = fadd double %tmp_42_2_1, %tmp_41_2_3
  %tmp_43_2_3 = fmul double %prefact_2_3, %dy_2_3
  %tmp_44_2_3 = fadd double %tmp_44_2_1, %tmp_43_2_3
  %tmp_45_2_3 = fmul double %prefact_2_3, %dz_2_3
  %tmp_46_2_3 = fadd double %tmp_46_2_1, %tmp_45_2_3
  %dx_2_4 = fsub double %p_x_2_load, %p_x_4_load
  %dy_2_4 = fsub double %p_y_2_load, %p_y_4_load
  %dz_2_4 = fsub double %p_z_2_load, %p_z_4_load
  %tmp_35_2_4 = fmul double %dx_2_4, %dx_2_4
  %tmp_36_2_4 = fmul double %dy_2_4, %dy_2_4
  %tmp_37_2_4 = fadd double %tmp_35_2_4, %tmp_36_2_4
  %tmp_38_2_4 = fmul double %dz_2_4, %dz_2_4
  %pre_sqrt_2_4 = fadd double %tmp_37_2_4, %tmp_38_2_4
  %p_r_2_4 = call double @llvm.sqrt.f64(double %pre_sqrt_2_4)
  %tmp_39_2_4 = fmul double %pre_sqrt_2_4, %p_r_2_4
  %tmp_40_2_4 = fdiv double -1.000000e+00, %tmp_39_2_4
  %prefact_2_4 = fmul double %tmp_40_2_4, %p_m_4_load
  %tmp_41_2_4 = fmul double %prefact_2_4, %dx_2_4
  %tmp_42_2_4 = fadd double %tmp_42_2_3, %tmp_41_2_4
  %tmp_43_2_4 = fmul double %prefact_2_4, %dy_2_4
  %tmp_44_2_4 = fadd double %tmp_44_2_3, %tmp_43_2_4
  %tmp_45_2_4 = fmul double %prefact_2_4, %dz_2_4
  %tmp_46_2_4 = fadd double %tmp_46_2_3, %tmp_45_2_4
  %dx_2_5 = fsub double %p_x_2_load, %p_x_5_load
  %dy_2_5 = fsub double %p_y_2_load, %p_y_5_load
  %dz_2_5 = fsub double %p_z_2_load, %p_z_5_load
  %tmp_35_2_5 = fmul double %dx_2_5, %dx_2_5
  %tmp_36_2_5 = fmul double %dy_2_5, %dy_2_5
  %tmp_37_2_5 = fadd double %tmp_35_2_5, %tmp_36_2_5
  %tmp_38_2_5 = fmul double %dz_2_5, %dz_2_5
  %pre_sqrt_2_5 = fadd double %tmp_37_2_5, %tmp_38_2_5
  %p_r_2_5 = call double @llvm.sqrt.f64(double %pre_sqrt_2_5)
  %tmp_39_2_5 = fmul double %pre_sqrt_2_5, %p_r_2_5
  %tmp_40_2_5 = fdiv double -1.000000e+00, %tmp_39_2_5
  %prefact_2_5 = fmul double %tmp_40_2_5, %p_m_5_load
  %tmp_41_2_5 = fmul double %prefact_2_5, %dx_2_5
  %tmp_42_2_5 = fadd double %tmp_42_2_4, %tmp_41_2_5
  %tmp_43_2_5 = fmul double %prefact_2_5, %dy_2_5
  %tmp_44_2_5 = fadd double %tmp_44_2_4, %tmp_43_2_5
  %tmp_45_2_5 = fmul double %prefact_2_5, %dz_2_5
  %tmp_46_2_5 = fadd double %tmp_46_2_4, %tmp_45_2_5
  %dx_2_6 = fsub double %p_x_2_load, %p_x_6_load
  %dy_2_6 = fsub double %p_y_2_load, %p_y_6_load
  %dz_2_6 = fsub double %p_z_2_load, %p_z_6_load
  %tmp_35_2_6 = fmul double %dx_2_6, %dx_2_6
  %tmp_36_2_6 = fmul double %dy_2_6, %dy_2_6
  %tmp_37_2_6 = fadd double %tmp_35_2_6, %tmp_36_2_6
  %tmp_38_2_6 = fmul double %dz_2_6, %dz_2_6
  %pre_sqrt_2_6 = fadd double %tmp_37_2_6, %tmp_38_2_6
  %p_r_2_6 = call double @llvm.sqrt.f64(double %pre_sqrt_2_6)
  %tmp_39_2_6 = fmul double %pre_sqrt_2_6, %p_r_2_6
  %tmp_40_2_6 = fdiv double -1.000000e+00, %tmp_39_2_6
  %prefact_2_6 = fmul double %tmp_40_2_6, %p_m_6_load
  %tmp_41_2_6 = fmul double %prefact_2_6, %dx_2_6
  %tmp_42_2_6 = fadd double %tmp_42_2_5, %tmp_41_2_6
  %tmp_43_2_6 = fmul double %prefact_2_6, %dy_2_6
  %tmp_44_2_6 = fadd double %tmp_44_2_5, %tmp_43_2_6
  %tmp_45_2_6 = fmul double %prefact_2_6, %dz_2_6
  %tmp_46_2_6 = fadd double %tmp_46_2_5, %tmp_45_2_6
  %dx_2_7 = fsub double %p_x_2_load, %p_x_7_load
  %dy_2_7 = fsub double %p_y_2_load, %p_y_7_load
  %dz_2_7 = fsub double %p_z_2_load, %p_z_7_load
  %tmp_35_2_7 = fmul double %dx_2_7, %dx_2_7
  %tmp_36_2_7 = fmul double %dy_2_7, %dy_2_7
  %tmp_37_2_7 = fadd double %tmp_35_2_7, %tmp_36_2_7
  %tmp_38_2_7 = fmul double %dz_2_7, %dz_2_7
  %pre_sqrt_2_7 = fadd double %tmp_37_2_7, %tmp_38_2_7
  %p_r_2_7 = call double @llvm.sqrt.f64(double %pre_sqrt_2_7)
  %tmp_39_2_7 = fmul double %pre_sqrt_2_7, %p_r_2_7
  %tmp_40_2_7 = fdiv double -1.000000e+00, %tmp_39_2_7
  %prefact_2_7 = fmul double %tmp_40_2_7, %p_m_7_load
  %tmp_41_2_7 = fmul double %prefact_2_7, %dx_2_7
  %tmp_42_2_7 = fadd double %tmp_42_2_6, %tmp_41_2_7
  %tmp_43_2_7 = fmul double %prefact_2_7, %dy_2_7
  %tmp_44_2_7 = fadd double %tmp_44_2_6, %tmp_43_2_7
  %tmp_45_2_7 = fmul double %prefact_2_7, %dz_2_7
  %tmp_46_2_7 = fadd double %tmp_46_2_6, %tmp_45_2_7
  %dx_2_8 = fsub double %p_x_2_load, %p_x_8_load
  %dy_2_8 = fsub double %p_y_2_load, %p_y_8_load
  %dz_2_8 = fsub double %p_z_2_load, %p_z_8_load
  %tmp_35_2_8 = fmul double %dx_2_8, %dx_2_8
  %tmp_36_2_8 = fmul double %dy_2_8, %dy_2_8
  %tmp_37_2_8 = fadd double %tmp_35_2_8, %tmp_36_2_8
  %tmp_38_2_8 = fmul double %dz_2_8, %dz_2_8
  %pre_sqrt_2_8 = fadd double %tmp_37_2_8, %tmp_38_2_8
  %p_r_2_8 = call double @llvm.sqrt.f64(double %pre_sqrt_2_8)
  %tmp_39_2_8 = fmul double %pre_sqrt_2_8, %p_r_2_8
  %tmp_40_2_8 = fdiv double -1.000000e+00, %tmp_39_2_8
  %prefact_2_8 = fmul double %tmp_40_2_8, %p_m_8_load
  %tmp_41_2_8 = fmul double %prefact_2_8, %dx_2_8
  %tmp_42_2_8 = fadd double %tmp_42_2_7, %tmp_41_2_8
  store double %tmp_42_2_8, double* @p_ax_2, align 16
  %tmp_43_2_8 = fmul double %prefact_2_8, %dy_2_8
  %tmp_44_2_8 = fadd double %tmp_44_2_7, %tmp_43_2_8
  store double %tmp_44_2_8, double* @p_ay_2, align 16
  %tmp_45_2_8 = fmul double %prefact_2_8, %dz_2_8
  %tmp_46_2_8 = fadd double %tmp_46_2_7, %tmp_45_2_8
  store double %tmp_46_2_8, double* @p_az_2, align 16
  %dx_3 = fsub double %p_x_3_load, %p_x_0_load
  %dy_3 = fsub double %p_y_3_load, %p_y_0_load
  %dz_3 = fsub double %p_z_3_load, %p_z_0_load
  %tmp_35_3 = fmul double %dx_3, %dx_3
  %tmp_36_3 = fmul double %dy_3, %dy_3
  %tmp_37_3 = fadd double %tmp_35_3, %tmp_36_3
  %tmp_38_3 = fmul double %dz_3, %dz_3
  %pre_sqrt_3 = fadd double %tmp_37_3, %tmp_38_3
  %p_r_3 = call double @llvm.sqrt.f64(double %pre_sqrt_3)
  %tmp_39_3 = fmul double %pre_sqrt_3, %p_r_3
  %tmp_40_3 = fdiv double -1.000000e+00, %tmp_39_3
  %prefact_3 = fmul double %tmp_40_3, %p_m_0_load
  %tmp_41_3 = fmul double %prefact_3, %dx_3
  %tmp_42_3 = fadd double %tmp_41_3, 0.000000e+00
  %tmp_43_3 = fmul double %prefact_3, %dy_3
  %tmp_44_3 = fadd double %tmp_43_3, 0.000000e+00
  %tmp_45_3 = fmul double %prefact_3, %dz_3
  %tmp_46_3 = fadd double %tmp_45_3, 0.000000e+00
  %dx_3_1 = fsub double %p_x_3_load, %p_x_1_load
  %dy_3_1 = fsub double %p_y_3_load, %p_y_1_load
  %dz_3_1 = fsub double %p_z_3_load, %p_z_1_load
  %tmp_35_3_1 = fmul double %dx_3_1, %dx_3_1
  %tmp_36_3_1 = fmul double %dy_3_1, %dy_3_1
  %tmp_37_3_1 = fadd double %tmp_35_3_1, %tmp_36_3_1
  %tmp_38_3_1 = fmul double %dz_3_1, %dz_3_1
  %pre_sqrt_3_1 = fadd double %tmp_37_3_1, %tmp_38_3_1
  %p_r_3_1 = call double @llvm.sqrt.f64(double %pre_sqrt_3_1)
  %tmp_39_3_1 = fmul double %pre_sqrt_3_1, %p_r_3_1
  %tmp_40_3_1 = fdiv double -1.000000e+00, %tmp_39_3_1
  %prefact_3_1 = fmul double %tmp_40_3_1, %p_m_1_load
  %tmp_41_3_1 = fmul double %prefact_3_1, %dx_3_1
  %tmp_42_3_1 = fadd double %tmp_42_3, %tmp_41_3_1
  %tmp_43_3_1 = fmul double %prefact_3_1, %dy_3_1
  %tmp_44_3_1 = fadd double %tmp_44_3, %tmp_43_3_1
  %tmp_45_3_1 = fmul double %prefact_3_1, %dz_3_1
  %tmp_46_3_1 = fadd double %tmp_46_3, %tmp_45_3_1
  %dx_3_2 = fsub double %p_x_3_load, %p_x_2_load
  %dy_3_2 = fsub double %p_y_3_load, %p_y_2_load
  %dz_3_2 = fsub double %p_z_3_load, %p_z_2_load
  %tmp_35_3_2 = fmul double %dx_3_2, %dx_3_2
  %tmp_36_3_2 = fmul double %dy_3_2, %dy_3_2
  %tmp_37_3_2 = fadd double %tmp_35_3_2, %tmp_36_3_2
  %tmp_38_3_2 = fmul double %dz_3_2, %dz_3_2
  %pre_sqrt_3_2 = fadd double %tmp_37_3_2, %tmp_38_3_2
  %p_r_3_2 = call double @llvm.sqrt.f64(double %pre_sqrt_3_2)
  %tmp_39_3_2 = fmul double %pre_sqrt_3_2, %p_r_3_2
  %tmp_40_3_2 = fdiv double -1.000000e+00, %tmp_39_3_2
  %prefact_3_2 = fmul double %tmp_40_3_2, %p_m_2_load
  %tmp_41_3_2 = fmul double %prefact_3_2, %dx_3_2
  %tmp_42_3_2 = fadd double %tmp_42_3_1, %tmp_41_3_2
  %tmp_43_3_2 = fmul double %prefact_3_2, %dy_3_2
  %tmp_44_3_2 = fadd double %tmp_44_3_1, %tmp_43_3_2
  %tmp_45_3_2 = fmul double %prefact_3_2, %dz_3_2
  %tmp_46_3_2 = fadd double %tmp_46_3_1, %tmp_45_3_2
  %dx_3_4 = fsub double %p_x_3_load, %p_x_4_load
  %dy_3_4 = fsub double %p_y_3_load, %p_y_4_load
  %dz_3_4 = fsub double %p_z_3_load, %p_z_4_load
  %tmp_35_3_4 = fmul double %dx_3_4, %dx_3_4
  %tmp_36_3_4 = fmul double %dy_3_4, %dy_3_4
  %tmp_37_3_4 = fadd double %tmp_35_3_4, %tmp_36_3_4
  %tmp_38_3_4 = fmul double %dz_3_4, %dz_3_4
  %pre_sqrt_3_4 = fadd double %tmp_37_3_4, %tmp_38_3_4
  %p_r_3_4 = call double @llvm.sqrt.f64(double %pre_sqrt_3_4)
  %tmp_39_3_4 = fmul double %pre_sqrt_3_4, %p_r_3_4
  %tmp_40_3_4 = fdiv double -1.000000e+00, %tmp_39_3_4
  %prefact_3_4 = fmul double %tmp_40_3_4, %p_m_4_load
  %tmp_41_3_4 = fmul double %prefact_3_4, %dx_3_4
  %tmp_42_3_4 = fadd double %tmp_42_3_2, %tmp_41_3_4
  %tmp_43_3_4 = fmul double %prefact_3_4, %dy_3_4
  %tmp_44_3_4 = fadd double %tmp_44_3_2, %tmp_43_3_4
  %tmp_45_3_4 = fmul double %prefact_3_4, %dz_3_4
  %tmp_46_3_4 = fadd double %tmp_46_3_2, %tmp_45_3_4
  %dx_3_5 = fsub double %p_x_3_load, %p_x_5_load
  %dy_3_5 = fsub double %p_y_3_load, %p_y_5_load
  %dz_3_5 = fsub double %p_z_3_load, %p_z_5_load
  %tmp_35_3_5 = fmul double %dx_3_5, %dx_3_5
  %tmp_36_3_5 = fmul double %dy_3_5, %dy_3_5
  %tmp_37_3_5 = fadd double %tmp_35_3_5, %tmp_36_3_5
  %tmp_38_3_5 = fmul double %dz_3_5, %dz_3_5
  %pre_sqrt_3_5 = fadd double %tmp_37_3_5, %tmp_38_3_5
  %p_r_3_5 = call double @llvm.sqrt.f64(double %pre_sqrt_3_5)
  %tmp_39_3_5 = fmul double %pre_sqrt_3_5, %p_r_3_5
  %tmp_40_3_5 = fdiv double -1.000000e+00, %tmp_39_3_5
  %prefact_3_5 = fmul double %tmp_40_3_5, %p_m_5_load
  %tmp_41_3_5 = fmul double %prefact_3_5, %dx_3_5
  %tmp_42_3_5 = fadd double %tmp_42_3_4, %tmp_41_3_5
  %tmp_43_3_5 = fmul double %prefact_3_5, %dy_3_5
  %tmp_44_3_5 = fadd double %tmp_44_3_4, %tmp_43_3_5
  %tmp_45_3_5 = fmul double %prefact_3_5, %dz_3_5
  %tmp_46_3_5 = fadd double %tmp_46_3_4, %tmp_45_3_5
  %dx_3_6 = fsub double %p_x_3_load, %p_x_6_load
  %dy_3_6 = fsub double %p_y_3_load, %p_y_6_load
  %dz_3_6 = fsub double %p_z_3_load, %p_z_6_load
  %tmp_35_3_6 = fmul double %dx_3_6, %dx_3_6
  %tmp_36_3_6 = fmul double %dy_3_6, %dy_3_6
  %tmp_37_3_6 = fadd double %tmp_35_3_6, %tmp_36_3_6
  %tmp_38_3_6 = fmul double %dz_3_6, %dz_3_6
  %pre_sqrt_3_6 = fadd double %tmp_37_3_6, %tmp_38_3_6
  %p_r_3_6 = call double @llvm.sqrt.f64(double %pre_sqrt_3_6)
  %tmp_39_3_6 = fmul double %pre_sqrt_3_6, %p_r_3_6
  %tmp_40_3_6 = fdiv double -1.000000e+00, %tmp_39_3_6
  %prefact_3_6 = fmul double %tmp_40_3_6, %p_m_6_load
  %tmp_41_3_6 = fmul double %prefact_3_6, %dx_3_6
  %tmp_42_3_6 = fadd double %tmp_42_3_5, %tmp_41_3_6
  %tmp_43_3_6 = fmul double %prefact_3_6, %dy_3_6
  %tmp_44_3_6 = fadd double %tmp_44_3_5, %tmp_43_3_6
  %tmp_45_3_6 = fmul double %prefact_3_6, %dz_3_6
  %tmp_46_3_6 = fadd double %tmp_46_3_5, %tmp_45_3_6
  %dx_3_7 = fsub double %p_x_3_load, %p_x_7_load
  %dy_3_7 = fsub double %p_y_3_load, %p_y_7_load
  %dz_3_7 = fsub double %p_z_3_load, %p_z_7_load
  %tmp_35_3_7 = fmul double %dx_3_7, %dx_3_7
  %tmp_36_3_7 = fmul double %dy_3_7, %dy_3_7
  %tmp_37_3_7 = fadd double %tmp_35_3_7, %tmp_36_3_7
  %tmp_38_3_7 = fmul double %dz_3_7, %dz_3_7
  %pre_sqrt_3_7 = fadd double %tmp_37_3_7, %tmp_38_3_7
  %p_r_3_7 = call double @llvm.sqrt.f64(double %pre_sqrt_3_7)
  %tmp_39_3_7 = fmul double %pre_sqrt_3_7, %p_r_3_7
  %tmp_40_3_7 = fdiv double -1.000000e+00, %tmp_39_3_7
  %prefact_3_7 = fmul double %tmp_40_3_7, %p_m_7_load
  %tmp_41_3_7 = fmul double %prefact_3_7, %dx_3_7
  %tmp_42_3_7 = fadd double %tmp_42_3_6, %tmp_41_3_7
  %tmp_43_3_7 = fmul double %prefact_3_7, %dy_3_7
  %tmp_44_3_7 = fadd double %tmp_44_3_6, %tmp_43_3_7
  %tmp_45_3_7 = fmul double %prefact_3_7, %dz_3_7
  %tmp_46_3_7 = fadd double %tmp_46_3_6, %tmp_45_3_7
  %dx_3_8 = fsub double %p_x_3_load, %p_x_8_load
  %dy_3_8 = fsub double %p_y_3_load, %p_y_8_load
  %dz_3_8 = fsub double %p_z_3_load, %p_z_8_load
  %tmp_35_3_8 = fmul double %dx_3_8, %dx_3_8
  %tmp_36_3_8 = fmul double %dy_3_8, %dy_3_8
  %tmp_37_3_8 = fadd double %tmp_35_3_8, %tmp_36_3_8
  %tmp_38_3_8 = fmul double %dz_3_8, %dz_3_8
  %pre_sqrt_3_8 = fadd double %tmp_37_3_8, %tmp_38_3_8
  %p_r_3_8 = call double @llvm.sqrt.f64(double %pre_sqrt_3_8)
  %tmp_39_3_8 = fmul double %pre_sqrt_3_8, %p_r_3_8
  %tmp_40_3_8 = fdiv double -1.000000e+00, %tmp_39_3_8
  %prefact_3_8 = fmul double %tmp_40_3_8, %p_m_8_load
  %tmp_41_3_8 = fmul double %prefact_3_8, %dx_3_8
  %tmp_42_3_8 = fadd double %tmp_42_3_7, %tmp_41_3_8
  store double %tmp_42_3_8, double* @p_ax_3, align 16
  %tmp_43_3_8 = fmul double %prefact_3_8, %dy_3_8
  %tmp_44_3_8 = fadd double %tmp_44_3_7, %tmp_43_3_8
  store double %tmp_44_3_8, double* @p_ay_3, align 8
  %tmp_45_3_8 = fmul double %prefact_3_8, %dz_3_8
  %tmp_46_3_8 = fadd double %tmp_46_3_7, %tmp_45_3_8
  store double %tmp_46_3_8, double* @p_az_3, align 16
  %dx_4 = fsub double %p_x_4_load, %p_x_0_load
  %dy_4 = fsub double %p_y_4_load, %p_y_0_load
  %dz_4 = fsub double %p_z_4_load, %p_z_0_load
  %tmp_35_4 = fmul double %dx_4, %dx_4
  %tmp_36_4 = fmul double %dy_4, %dy_4
  %tmp_37_4 = fadd double %tmp_35_4, %tmp_36_4
  %tmp_38_4 = fmul double %dz_4, %dz_4
  %pre_sqrt_4 = fadd double %tmp_37_4, %tmp_38_4
  %p_r_4 = call double @llvm.sqrt.f64(double %pre_sqrt_4)
  %tmp_39_4 = fmul double %pre_sqrt_4, %p_r_4
  %tmp_40_4 = fdiv double -1.000000e+00, %tmp_39_4
  %prefact_4 = fmul double %tmp_40_4, %p_m_0_load
  %tmp_41_4 = fmul double %prefact_4, %dx_4
  %tmp_42_4 = fadd double %tmp_41_4, 0.000000e+00
  %tmp_43_4 = fmul double %prefact_4, %dy_4
  %tmp_44_4 = fadd double %tmp_43_4, 0.000000e+00
  %tmp_45_4 = fmul double %prefact_4, %dz_4
  %tmp_46_4 = fadd double %tmp_45_4, 0.000000e+00
  %dx_4_1 = fsub double %p_x_4_load, %p_x_1_load
  %dy_4_1 = fsub double %p_y_4_load, %p_y_1_load
  %dz_4_1 = fsub double %p_z_4_load, %p_z_1_load
  %tmp_35_4_1 = fmul double %dx_4_1, %dx_4_1
  %tmp_36_4_1 = fmul double %dy_4_1, %dy_4_1
  %tmp_37_4_1 = fadd double %tmp_35_4_1, %tmp_36_4_1
  %tmp_38_4_1 = fmul double %dz_4_1, %dz_4_1
  %pre_sqrt_4_1 = fadd double %tmp_37_4_1, %tmp_38_4_1
  %p_r_4_1 = call double @llvm.sqrt.f64(double %pre_sqrt_4_1)
  %tmp_39_4_1 = fmul double %pre_sqrt_4_1, %p_r_4_1
  %tmp_40_4_1 = fdiv double -1.000000e+00, %tmp_39_4_1
  %prefact_4_1 = fmul double %tmp_40_4_1, %p_m_1_load
  %tmp_41_4_1 = fmul double %prefact_4_1, %dx_4_1
  %tmp_42_4_1 = fadd double %tmp_42_4, %tmp_41_4_1
  %tmp_43_4_1 = fmul double %prefact_4_1, %dy_4_1
  %tmp_44_4_1 = fadd double %tmp_44_4, %tmp_43_4_1
  %tmp_45_4_1 = fmul double %prefact_4_1, %dz_4_1
  %tmp_46_4_1 = fadd double %tmp_46_4, %tmp_45_4_1
  %dx_4_2 = fsub double %p_x_4_load, %p_x_2_load
  %dy_4_2 = fsub double %p_y_4_load, %p_y_2_load
  %dz_4_2 = fsub double %p_z_4_load, %p_z_2_load
  %tmp_35_4_2 = fmul double %dx_4_2, %dx_4_2
  %tmp_36_4_2 = fmul double %dy_4_2, %dy_4_2
  %tmp_37_4_2 = fadd double %tmp_35_4_2, %tmp_36_4_2
  %tmp_38_4_2 = fmul double %dz_4_2, %dz_4_2
  %pre_sqrt_4_2 = fadd double %tmp_37_4_2, %tmp_38_4_2
  %p_r_4_2 = call double @llvm.sqrt.f64(double %pre_sqrt_4_2)
  %tmp_39_4_2 = fmul double %pre_sqrt_4_2, %p_r_4_2
  %tmp_40_4_2 = fdiv double -1.000000e+00, %tmp_39_4_2
  %prefact_4_2 = fmul double %tmp_40_4_2, %p_m_2_load
  %tmp_41_4_2 = fmul double %prefact_4_2, %dx_4_2
  %tmp_42_4_2 = fadd double %tmp_42_4_1, %tmp_41_4_2
  %tmp_43_4_2 = fmul double %prefact_4_2, %dy_4_2
  %tmp_44_4_2 = fadd double %tmp_44_4_1, %tmp_43_4_2
  %tmp_45_4_2 = fmul double %prefact_4_2, %dz_4_2
  %tmp_46_4_2 = fadd double %tmp_46_4_1, %tmp_45_4_2
  %dx_4_3 = fsub double %p_x_4_load, %p_x_3_load
  %dy_4_3 = fsub double %p_y_4_load, %p_y_3_load
  %dz_4_3 = fsub double %p_z_4_load, %p_z_3_load
  %tmp_35_4_3 = fmul double %dx_4_3, %dx_4_3
  %tmp_36_4_3 = fmul double %dy_4_3, %dy_4_3
  %tmp_37_4_3 = fadd double %tmp_35_4_3, %tmp_36_4_3
  %tmp_38_4_3 = fmul double %dz_4_3, %dz_4_3
  %pre_sqrt_4_3 = fadd double %tmp_37_4_3, %tmp_38_4_3
  %p_r_4_3 = call double @llvm.sqrt.f64(double %pre_sqrt_4_3)
  %tmp_39_4_3 = fmul double %pre_sqrt_4_3, %p_r_4_3
  %tmp_40_4_3 = fdiv double -1.000000e+00, %tmp_39_4_3
  %prefact_4_3 = fmul double %tmp_40_4_3, %p_m_3_load
  %tmp_41_4_3 = fmul double %prefact_4_3, %dx_4_3
  %tmp_42_4_3 = fadd double %tmp_42_4_2, %tmp_41_4_3
  %tmp_43_4_3 = fmul double %prefact_4_3, %dy_4_3
  %tmp_44_4_3 = fadd double %tmp_44_4_2, %tmp_43_4_3
  %tmp_45_4_3 = fmul double %prefact_4_3, %dz_4_3
  %tmp_46_4_3 = fadd double %tmp_46_4_2, %tmp_45_4_3
  %dx_4_5 = fsub double %p_x_4_load, %p_x_5_load
  %dy_4_5 = fsub double %p_y_4_load, %p_y_5_load
  %dz_4_5 = fsub double %p_z_4_load, %p_z_5_load
  %tmp_35_4_5 = fmul double %dx_4_5, %dx_4_5
  %tmp_36_4_5 = fmul double %dy_4_5, %dy_4_5
  %tmp_37_4_5 = fadd double %tmp_35_4_5, %tmp_36_4_5
  %tmp_38_4_5 = fmul double %dz_4_5, %dz_4_5
  %pre_sqrt_4_5 = fadd double %tmp_37_4_5, %tmp_38_4_5
  %p_r_4_5 = call double @llvm.sqrt.f64(double %pre_sqrt_4_5)
  %tmp_39_4_5 = fmul double %pre_sqrt_4_5, %p_r_4_5
  %tmp_40_4_5 = fdiv double -1.000000e+00, %tmp_39_4_5
  %prefact_4_5 = fmul double %tmp_40_4_5, %p_m_5_load
  %tmp_41_4_5 = fmul double %prefact_4_5, %dx_4_5
  %tmp_42_4_5 = fadd double %tmp_42_4_3, %tmp_41_4_5
  %tmp_43_4_5 = fmul double %prefact_4_5, %dy_4_5
  %tmp_44_4_5 = fadd double %tmp_44_4_3, %tmp_43_4_5
  %tmp_45_4_5 = fmul double %prefact_4_5, %dz_4_5
  %tmp_46_4_5 = fadd double %tmp_46_4_3, %tmp_45_4_5
  %dx_4_6 = fsub double %p_x_4_load, %p_x_6_load
  %dy_4_6 = fsub double %p_y_4_load, %p_y_6_load
  %dz_4_6 = fsub double %p_z_4_load, %p_z_6_load
  %tmp_35_4_6 = fmul double %dx_4_6, %dx_4_6
  %tmp_36_4_6 = fmul double %dy_4_6, %dy_4_6
  %tmp_37_4_6 = fadd double %tmp_35_4_6, %tmp_36_4_6
  %tmp_38_4_6 = fmul double %dz_4_6, %dz_4_6
  %pre_sqrt_4_6 = fadd double %tmp_37_4_6, %tmp_38_4_6
  %p_r_4_6 = call double @llvm.sqrt.f64(double %pre_sqrt_4_6)
  %tmp_39_4_6 = fmul double %pre_sqrt_4_6, %p_r_4_6
  %tmp_40_4_6 = fdiv double -1.000000e+00, %tmp_39_4_6
  %prefact_4_6 = fmul double %tmp_40_4_6, %p_m_6_load
  %tmp_41_4_6 = fmul double %prefact_4_6, %dx_4_6
  %tmp_42_4_6 = fadd double %tmp_42_4_5, %tmp_41_4_6
  %tmp_43_4_6 = fmul double %prefact_4_6, %dy_4_6
  %tmp_44_4_6 = fadd double %tmp_44_4_5, %tmp_43_4_6
  %tmp_45_4_6 = fmul double %prefact_4_6, %dz_4_6
  %tmp_46_4_6 = fadd double %tmp_46_4_5, %tmp_45_4_6
  %dx_4_7 = fsub double %p_x_4_load, %p_x_7_load
  %dy_4_7 = fsub double %p_y_4_load, %p_y_7_load
  %dz_4_7 = fsub double %p_z_4_load, %p_z_7_load
  %tmp_35_4_7 = fmul double %dx_4_7, %dx_4_7
  %tmp_36_4_7 = fmul double %dy_4_7, %dy_4_7
  %tmp_37_4_7 = fadd double %tmp_35_4_7, %tmp_36_4_7
  %tmp_38_4_7 = fmul double %dz_4_7, %dz_4_7
  %pre_sqrt_4_7 = fadd double %tmp_37_4_7, %tmp_38_4_7
  %p_r_4_7 = call double @llvm.sqrt.f64(double %pre_sqrt_4_7)
  %tmp_39_4_7 = fmul double %pre_sqrt_4_7, %p_r_4_7
  %tmp_40_4_7 = fdiv double -1.000000e+00, %tmp_39_4_7
  %prefact_4_7 = fmul double %tmp_40_4_7, %p_m_7_load
  %tmp_41_4_7 = fmul double %prefact_4_7, %dx_4_7
  %tmp_42_4_7 = fadd double %tmp_42_4_6, %tmp_41_4_7
  %tmp_43_4_7 = fmul double %prefact_4_7, %dy_4_7
  %tmp_44_4_7 = fadd double %tmp_44_4_6, %tmp_43_4_7
  %tmp_45_4_7 = fmul double %prefact_4_7, %dz_4_7
  %tmp_46_4_7 = fadd double %tmp_46_4_6, %tmp_45_4_7
  %dx_4_8 = fsub double %p_x_4_load, %p_x_8_load
  %dy_4_8 = fsub double %p_y_4_load, %p_y_8_load
  %dz_4_8 = fsub double %p_z_4_load, %p_z_8_load
  %tmp_35_4_8 = fmul double %dx_4_8, %dx_4_8
  %tmp_36_4_8 = fmul double %dy_4_8, %dy_4_8
  %tmp_37_4_8 = fadd double %tmp_35_4_8, %tmp_36_4_8
  %tmp_38_4_8 = fmul double %dz_4_8, %dz_4_8
  %pre_sqrt_4_8 = fadd double %tmp_37_4_8, %tmp_38_4_8
  %p_r_4_8 = call double @llvm.sqrt.f64(double %pre_sqrt_4_8)
  %tmp_39_4_8 = fmul double %pre_sqrt_4_8, %p_r_4_8
  %tmp_40_4_8 = fdiv double -1.000000e+00, %tmp_39_4_8
  %prefact_4_8 = fmul double %tmp_40_4_8, %p_m_8_load
  %tmp_41_4_8 = fmul double %prefact_4_8, %dx_4_8
  %tmp_42_4_8 = fadd double %tmp_42_4_7, %tmp_41_4_8
  store double %tmp_42_4_8, double* @p_ax_4, align 16
  %tmp_43_4_8 = fmul double %prefact_4_8, %dy_4_8
  %tmp_44_4_8 = fadd double %tmp_44_4_7, %tmp_43_4_8
  store double %tmp_44_4_8, double* @p_ay_4, align 16
  %tmp_45_4_8 = fmul double %prefact_4_8, %dz_4_8
  %tmp_46_4_8 = fadd double %tmp_46_4_7, %tmp_45_4_8
  store double %tmp_46_4_8, double* @p_az_4, align 16
  %dx_5 = fsub double %p_x_5_load, %p_x_0_load
  %dy_5 = fsub double %p_y_5_load, %p_y_0_load
  %dz_5 = fsub double %p_z_5_load, %p_z_0_load
  %tmp_35_5 = fmul double %dx_5, %dx_5
  %tmp_36_5 = fmul double %dy_5, %dy_5
  %tmp_37_5 = fadd double %tmp_35_5, %tmp_36_5
  %tmp_38_5 = fmul double %dz_5, %dz_5
  %pre_sqrt_5 = fadd double %tmp_37_5, %tmp_38_5
  %p_r_5 = call double @llvm.sqrt.f64(double %pre_sqrt_5)
  %tmp_39_5 = fmul double %pre_sqrt_5, %p_r_5
  %tmp_40_5 = fdiv double -1.000000e+00, %tmp_39_5
  %prefact_5 = fmul double %tmp_40_5, %p_m_0_load
  %tmp_41_5 = fmul double %prefact_5, %dx_5
  %tmp_42_5 = fadd double %tmp_41_5, 0.000000e+00
  %tmp_43_5 = fmul double %prefact_5, %dy_5
  %tmp_44_5 = fadd double %tmp_43_5, 0.000000e+00
  %tmp_45_5 = fmul double %prefact_5, %dz_5
  %tmp_46_5 = fadd double %tmp_45_5, 0.000000e+00
  %dx_5_1 = fsub double %p_x_5_load, %p_x_1_load
  %dy_5_1 = fsub double %p_y_5_load, %p_y_1_load
  %dz_5_1 = fsub double %p_z_5_load, %p_z_1_load
  %tmp_35_5_1 = fmul double %dx_5_1, %dx_5_1
  %tmp_36_5_1 = fmul double %dy_5_1, %dy_5_1
  %tmp_37_5_1 = fadd double %tmp_35_5_1, %tmp_36_5_1
  %tmp_38_5_1 = fmul double %dz_5_1, %dz_5_1
  %pre_sqrt_5_1 = fadd double %tmp_37_5_1, %tmp_38_5_1
  %p_r_5_1 = call double @llvm.sqrt.f64(double %pre_sqrt_5_1)
  %tmp_39_5_1 = fmul double %pre_sqrt_5_1, %p_r_5_1
  %tmp_40_5_1 = fdiv double -1.000000e+00, %tmp_39_5_1
  %prefact_5_1 = fmul double %tmp_40_5_1, %p_m_1_load
  %tmp_41_5_1 = fmul double %prefact_5_1, %dx_5_1
  %tmp_42_5_1 = fadd double %tmp_42_5, %tmp_41_5_1
  %tmp_43_5_1 = fmul double %prefact_5_1, %dy_5_1
  %tmp_44_5_1 = fadd double %tmp_44_5, %tmp_43_5_1
  %tmp_45_5_1 = fmul double %prefact_5_1, %dz_5_1
  %tmp_46_5_1 = fadd double %tmp_46_5, %tmp_45_5_1
  %dx_5_2 = fsub double %p_x_5_load, %p_x_2_load
  %dy_5_2 = fsub double %p_y_5_load, %p_y_2_load
  %dz_5_2 = fsub double %p_z_5_load, %p_z_2_load
  %tmp_35_5_2 = fmul double %dx_5_2, %dx_5_2
  %tmp_36_5_2 = fmul double %dy_5_2, %dy_5_2
  %tmp_37_5_2 = fadd double %tmp_35_5_2, %tmp_36_5_2
  %tmp_38_5_2 = fmul double %dz_5_2, %dz_5_2
  %pre_sqrt_5_2 = fadd double %tmp_37_5_2, %tmp_38_5_2
  %p_r_5_2 = call double @llvm.sqrt.f64(double %pre_sqrt_5_2)
  %tmp_39_5_2 = fmul double %pre_sqrt_5_2, %p_r_5_2
  %tmp_40_5_2 = fdiv double -1.000000e+00, %tmp_39_5_2
  %prefact_5_2 = fmul double %tmp_40_5_2, %p_m_2_load
  %tmp_41_5_2 = fmul double %prefact_5_2, %dx_5_2
  %tmp_42_5_2 = fadd double %tmp_42_5_1, %tmp_41_5_2
  %tmp_43_5_2 = fmul double %prefact_5_2, %dy_5_2
  %tmp_44_5_2 = fadd double %tmp_44_5_1, %tmp_43_5_2
  %tmp_45_5_2 = fmul double %prefact_5_2, %dz_5_2
  %tmp_46_5_2 = fadd double %tmp_46_5_1, %tmp_45_5_2
  %dx_5_3 = fsub double %p_x_5_load, %p_x_3_load
  %dy_5_3 = fsub double %p_y_5_load, %p_y_3_load
  %dz_5_3 = fsub double %p_z_5_load, %p_z_3_load
  %tmp_35_5_3 = fmul double %dx_5_3, %dx_5_3
  %tmp_36_5_3 = fmul double %dy_5_3, %dy_5_3
  %tmp_37_5_3 = fadd double %tmp_35_5_3, %tmp_36_5_3
  %tmp_38_5_3 = fmul double %dz_5_3, %dz_5_3
  %pre_sqrt_5_3 = fadd double %tmp_37_5_3, %tmp_38_5_3
  %p_r_5_3 = call double @llvm.sqrt.f64(double %pre_sqrt_5_3)
  %tmp_39_5_3 = fmul double %pre_sqrt_5_3, %p_r_5_3
  %tmp_40_5_3 = fdiv double -1.000000e+00, %tmp_39_5_3
  %prefact_5_3 = fmul double %tmp_40_5_3, %p_m_3_load
  %tmp_41_5_3 = fmul double %prefact_5_3, %dx_5_3
  %tmp_42_5_3 = fadd double %tmp_42_5_2, %tmp_41_5_3
  %tmp_43_5_3 = fmul double %prefact_5_3, %dy_5_3
  %tmp_44_5_3 = fadd double %tmp_44_5_2, %tmp_43_5_3
  %tmp_45_5_3 = fmul double %prefact_5_3, %dz_5_3
  %tmp_46_5_3 = fadd double %tmp_46_5_2, %tmp_45_5_3
  %dx_5_4 = fsub double %p_x_5_load, %p_x_4_load
  %dy_5_4 = fsub double %p_y_5_load, %p_y_4_load
  %dz_5_4 = fsub double %p_z_5_load, %p_z_4_load
  %tmp_35_5_4 = fmul double %dx_5_4, %dx_5_4
  %tmp_36_5_4 = fmul double %dy_5_4, %dy_5_4
  %tmp_37_5_4 = fadd double %tmp_35_5_4, %tmp_36_5_4
  %tmp_38_5_4 = fmul double %dz_5_4, %dz_5_4
  %pre_sqrt_5_4 = fadd double %tmp_37_5_4, %tmp_38_5_4
  %p_r_5_4 = call double @llvm.sqrt.f64(double %pre_sqrt_5_4)
  %tmp_39_5_4 = fmul double %pre_sqrt_5_4, %p_r_5_4
  %tmp_40_5_4 = fdiv double -1.000000e+00, %tmp_39_5_4
  %prefact_5_4 = fmul double %tmp_40_5_4, %p_m_4_load
  %tmp_41_5_4 = fmul double %prefact_5_4, %dx_5_4
  %tmp_42_5_4 = fadd double %tmp_42_5_3, %tmp_41_5_4
  %tmp_43_5_4 = fmul double %prefact_5_4, %dy_5_4
  %tmp_44_5_4 = fadd double %tmp_44_5_3, %tmp_43_5_4
  %tmp_45_5_4 = fmul double %prefact_5_4, %dz_5_4
  %tmp_46_5_4 = fadd double %tmp_46_5_3, %tmp_45_5_4
  %dx_5_6 = fsub double %p_x_5_load, %p_x_6_load
  %dy_5_6 = fsub double %p_y_5_load, %p_y_6_load
  %dz_5_6 = fsub double %p_z_5_load, %p_z_6_load
  %tmp_35_5_6 = fmul double %dx_5_6, %dx_5_6
  %tmp_36_5_6 = fmul double %dy_5_6, %dy_5_6
  %tmp_37_5_6 = fadd double %tmp_35_5_6, %tmp_36_5_6
  %tmp_38_5_6 = fmul double %dz_5_6, %dz_5_6
  %pre_sqrt_5_6 = fadd double %tmp_37_5_6, %tmp_38_5_6
  %p_r_5_6 = call double @llvm.sqrt.f64(double %pre_sqrt_5_6)
  %tmp_39_5_6 = fmul double %pre_sqrt_5_6, %p_r_5_6
  %tmp_40_5_6 = fdiv double -1.000000e+00, %tmp_39_5_6
  %prefact_5_6 = fmul double %tmp_40_5_6, %p_m_6_load
  %tmp_41_5_6 = fmul double %prefact_5_6, %dx_5_6
  %tmp_42_5_6 = fadd double %tmp_42_5_4, %tmp_41_5_6
  %tmp_43_5_6 = fmul double %prefact_5_6, %dy_5_6
  %tmp_44_5_6 = fadd double %tmp_44_5_4, %tmp_43_5_6
  %tmp_45_5_6 = fmul double %prefact_5_6, %dz_5_6
  %tmp_46_5_6 = fadd double %tmp_46_5_4, %tmp_45_5_6
  %dx_5_7 = fsub double %p_x_5_load, %p_x_7_load
  %dy_5_7 = fsub double %p_y_5_load, %p_y_7_load
  %dz_5_7 = fsub double %p_z_5_load, %p_z_7_load
  %tmp_35_5_7 = fmul double %dx_5_7, %dx_5_7
  %tmp_36_5_7 = fmul double %dy_5_7, %dy_5_7
  %tmp_37_5_7 = fadd double %tmp_35_5_7, %tmp_36_5_7
  %tmp_38_5_7 = fmul double %dz_5_7, %dz_5_7
  %pre_sqrt_5_7 = fadd double %tmp_37_5_7, %tmp_38_5_7
  %p_r_5_7 = call double @llvm.sqrt.f64(double %pre_sqrt_5_7)
  %tmp_39_5_7 = fmul double %pre_sqrt_5_7, %p_r_5_7
  %tmp_40_5_7 = fdiv double -1.000000e+00, %tmp_39_5_7
  %prefact_5_7 = fmul double %tmp_40_5_7, %p_m_7_load
  %tmp_41_5_7 = fmul double %prefact_5_7, %dx_5_7
  %tmp_42_5_7 = fadd double %tmp_42_5_6, %tmp_41_5_7
  %tmp_43_5_7 = fmul double %prefact_5_7, %dy_5_7
  %tmp_44_5_7 = fadd double %tmp_44_5_6, %tmp_43_5_7
  %tmp_45_5_7 = fmul double %prefact_5_7, %dz_5_7
  %tmp_46_5_7 = fadd double %tmp_46_5_6, %tmp_45_5_7
  %dx_5_8 = fsub double %p_x_5_load, %p_x_8_load
  %dy_5_8 = fsub double %p_y_5_load, %p_y_8_load
  %dz_5_8 = fsub double %p_z_5_load, %p_z_8_load
  %tmp_35_5_8 = fmul double %dx_5_8, %dx_5_8
  %tmp_36_5_8 = fmul double %dy_5_8, %dy_5_8
  %tmp_37_5_8 = fadd double %tmp_35_5_8, %tmp_36_5_8
  %tmp_38_5_8 = fmul double %dz_5_8, %dz_5_8
  %pre_sqrt_5_8 = fadd double %tmp_37_5_8, %tmp_38_5_8
  %p_r_5_8 = call double @llvm.sqrt.f64(double %pre_sqrt_5_8)
  %tmp_39_5_8 = fmul double %pre_sqrt_5_8, %p_r_5_8
  %tmp_40_5_8 = fdiv double -1.000000e+00, %tmp_39_5_8
  %prefact_5_8 = fmul double %tmp_40_5_8, %p_m_8_load
  %tmp_41_5_8 = fmul double %prefact_5_8, %dx_5_8
  %tmp_42_5_8 = fadd double %tmp_42_5_7, %tmp_41_5_8
  store double %tmp_42_5_8, double* @p_ax_5, align 16
  %tmp_43_5_8 = fmul double %prefact_5_8, %dy_5_8
  %tmp_44_5_8 = fadd double %tmp_44_5_7, %tmp_43_5_8
  store double %tmp_44_5_8, double* @p_ay_5, align 8
  %tmp_45_5_8 = fmul double %prefact_5_8, %dz_5_8
  %tmp_46_5_8 = fadd double %tmp_46_5_7, %tmp_45_5_8
  store double %tmp_46_5_8, double* @p_az_5, align 16
  %dx_6 = fsub double %p_x_6_load, %p_x_0_load
  %dy_6 = fsub double %p_y_6_load, %p_y_0_load
  %dz_6 = fsub double %p_z_6_load, %p_z_0_load
  %tmp_35_6 = fmul double %dx_6, %dx_6
  %tmp_36_6 = fmul double %dy_6, %dy_6
  %tmp_37_6 = fadd double %tmp_35_6, %tmp_36_6
  %tmp_38_6 = fmul double %dz_6, %dz_6
  %pre_sqrt_6 = fadd double %tmp_37_6, %tmp_38_6
  %p_r_6 = call double @llvm.sqrt.f64(double %pre_sqrt_6)
  %tmp_39_6 = fmul double %pre_sqrt_6, %p_r_6
  %tmp_40_6 = fdiv double -1.000000e+00, %tmp_39_6
  %prefact_6 = fmul double %tmp_40_6, %p_m_0_load
  %tmp_41_6 = fmul double %prefact_6, %dx_6
  %tmp_42_6 = fadd double %tmp_41_6, 0.000000e+00
  %tmp_43_6 = fmul double %prefact_6, %dy_6
  %tmp_44_6 = fadd double %tmp_43_6, 0.000000e+00
  %tmp_45_6 = fmul double %prefact_6, %dz_6
  %tmp_46_6 = fadd double %tmp_45_6, 0.000000e+00
  %dx_6_1 = fsub double %p_x_6_load, %p_x_1_load
  %dy_6_1 = fsub double %p_y_6_load, %p_y_1_load
  %dz_6_1 = fsub double %p_z_6_load, %p_z_1_load
  %tmp_35_6_1 = fmul double %dx_6_1, %dx_6_1
  %tmp_36_6_1 = fmul double %dy_6_1, %dy_6_1
  %tmp_37_6_1 = fadd double %tmp_35_6_1, %tmp_36_6_1
  %tmp_38_6_1 = fmul double %dz_6_1, %dz_6_1
  %pre_sqrt_6_1 = fadd double %tmp_37_6_1, %tmp_38_6_1
  %p_r_6_1 = call double @llvm.sqrt.f64(double %pre_sqrt_6_1)
  %tmp_39_6_1 = fmul double %pre_sqrt_6_1, %p_r_6_1
  %tmp_40_6_1 = fdiv double -1.000000e+00, %tmp_39_6_1
  %prefact_6_1 = fmul double %tmp_40_6_1, %p_m_1_load
  %tmp_41_6_1 = fmul double %prefact_6_1, %dx_6_1
  %tmp_42_6_1 = fadd double %tmp_42_6, %tmp_41_6_1
  %tmp_43_6_1 = fmul double %prefact_6_1, %dy_6_1
  %tmp_44_6_1 = fadd double %tmp_44_6, %tmp_43_6_1
  %tmp_45_6_1 = fmul double %prefact_6_1, %dz_6_1
  %tmp_46_6_1 = fadd double %tmp_46_6, %tmp_45_6_1
  %dx_6_2 = fsub double %p_x_6_load, %p_x_2_load
  %dy_6_2 = fsub double %p_y_6_load, %p_y_2_load
  %dz_6_2 = fsub double %p_z_6_load, %p_z_2_load
  %tmp_35_6_2 = fmul double %dx_6_2, %dx_6_2
  %tmp_36_6_2 = fmul double %dy_6_2, %dy_6_2
  %tmp_37_6_2 = fadd double %tmp_35_6_2, %tmp_36_6_2
  %tmp_38_6_2 = fmul double %dz_6_2, %dz_6_2
  %pre_sqrt_6_2 = fadd double %tmp_37_6_2, %tmp_38_6_2
  %p_r_6_2 = call double @llvm.sqrt.f64(double %pre_sqrt_6_2)
  %tmp_39_6_2 = fmul double %pre_sqrt_6_2, %p_r_6_2
  %tmp_40_6_2 = fdiv double -1.000000e+00, %tmp_39_6_2
  %prefact_6_2 = fmul double %tmp_40_6_2, %p_m_2_load
  %tmp_41_6_2 = fmul double %prefact_6_2, %dx_6_2
  %tmp_42_6_2 = fadd double %tmp_42_6_1, %tmp_41_6_2
  %tmp_43_6_2 = fmul double %prefact_6_2, %dy_6_2
  %tmp_44_6_2 = fadd double %tmp_44_6_1, %tmp_43_6_2
  %tmp_45_6_2 = fmul double %prefact_6_2, %dz_6_2
  %tmp_46_6_2 = fadd double %tmp_46_6_1, %tmp_45_6_2
  %dx_6_3 = fsub double %p_x_6_load, %p_x_3_load
  %dy_6_3 = fsub double %p_y_6_load, %p_y_3_load
  %dz_6_3 = fsub double %p_z_6_load, %p_z_3_load
  %tmp_35_6_3 = fmul double %dx_6_3, %dx_6_3
  %tmp_36_6_3 = fmul double %dy_6_3, %dy_6_3
  %tmp_37_6_3 = fadd double %tmp_35_6_3, %tmp_36_6_3
  %tmp_38_6_3 = fmul double %dz_6_3, %dz_6_3
  %pre_sqrt_6_3 = fadd double %tmp_37_6_3, %tmp_38_6_3
  %p_r_6_3 = call double @llvm.sqrt.f64(double %pre_sqrt_6_3)
  %tmp_39_6_3 = fmul double %pre_sqrt_6_3, %p_r_6_3
  %tmp_40_6_3 = fdiv double -1.000000e+00, %tmp_39_6_3
  %prefact_6_3 = fmul double %tmp_40_6_3, %p_m_3_load
  %tmp_41_6_3 = fmul double %prefact_6_3, %dx_6_3
  %tmp_42_6_3 = fadd double %tmp_42_6_2, %tmp_41_6_3
  %tmp_43_6_3 = fmul double %prefact_6_3, %dy_6_3
  %tmp_44_6_3 = fadd double %tmp_44_6_2, %tmp_43_6_3
  %tmp_45_6_3 = fmul double %prefact_6_3, %dz_6_3
  %tmp_46_6_3 = fadd double %tmp_46_6_2, %tmp_45_6_3
  %dx_6_4 = fsub double %p_x_6_load, %p_x_4_load
  %dy_6_4 = fsub double %p_y_6_load, %p_y_4_load
  %dz_6_4 = fsub double %p_z_6_load, %p_z_4_load
  %tmp_35_6_4 = fmul double %dx_6_4, %dx_6_4
  %tmp_36_6_4 = fmul double %dy_6_4, %dy_6_4
  %tmp_37_6_4 = fadd double %tmp_35_6_4, %tmp_36_6_4
  %tmp_38_6_4 = fmul double %dz_6_4, %dz_6_4
  %pre_sqrt_6_4 = fadd double %tmp_37_6_4, %tmp_38_6_4
  %p_r_6_4 = call double @llvm.sqrt.f64(double %pre_sqrt_6_4)
  %tmp_39_6_4 = fmul double %pre_sqrt_6_4, %p_r_6_4
  %tmp_40_6_4 = fdiv double -1.000000e+00, %tmp_39_6_4
  %prefact_6_4 = fmul double %tmp_40_6_4, %p_m_4_load
  %tmp_41_6_4 = fmul double %prefact_6_4, %dx_6_4
  %tmp_42_6_4 = fadd double %tmp_42_6_3, %tmp_41_6_4
  %tmp_43_6_4 = fmul double %prefact_6_4, %dy_6_4
  %tmp_44_6_4 = fadd double %tmp_44_6_3, %tmp_43_6_4
  %tmp_45_6_4 = fmul double %prefact_6_4, %dz_6_4
  %tmp_46_6_4 = fadd double %tmp_46_6_3, %tmp_45_6_4
  %dx_6_5 = fsub double %p_x_6_load, %p_x_5_load
  %dy_6_5 = fsub double %p_y_6_load, %p_y_5_load
  %dz_6_5 = fsub double %p_z_6_load, %p_z_5_load
  %tmp_35_6_5 = fmul double %dx_6_5, %dx_6_5
  %tmp_36_6_5 = fmul double %dy_6_5, %dy_6_5
  %tmp_37_6_5 = fadd double %tmp_35_6_5, %tmp_36_6_5
  %tmp_38_6_5 = fmul double %dz_6_5, %dz_6_5
  %pre_sqrt_6_5 = fadd double %tmp_37_6_5, %tmp_38_6_5
  %p_r_6_5 = call double @llvm.sqrt.f64(double %pre_sqrt_6_5)
  %tmp_39_6_5 = fmul double %pre_sqrt_6_5, %p_r_6_5
  %tmp_40_6_5 = fdiv double -1.000000e+00, %tmp_39_6_5
  %prefact_6_5 = fmul double %tmp_40_6_5, %p_m_5_load
  %tmp_41_6_5 = fmul double %prefact_6_5, %dx_6_5
  %tmp_42_6_5 = fadd double %tmp_42_6_4, %tmp_41_6_5
  %tmp_43_6_5 = fmul double %prefact_6_5, %dy_6_5
  %tmp_44_6_5 = fadd double %tmp_44_6_4, %tmp_43_6_5
  %tmp_45_6_5 = fmul double %prefact_6_5, %dz_6_5
  %tmp_46_6_5 = fadd double %tmp_46_6_4, %tmp_45_6_5
  %dx_6_7 = fsub double %p_x_6_load, %p_x_7_load
  %dy_6_7 = fsub double %p_y_6_load, %p_y_7_load
  %dz_6_7 = fsub double %p_z_6_load, %p_z_7_load
  %tmp_35_6_7 = fmul double %dx_6_7, %dx_6_7
  %tmp_36_6_7 = fmul double %dy_6_7, %dy_6_7
  %tmp_37_6_7 = fadd double %tmp_35_6_7, %tmp_36_6_7
  %tmp_38_6_7 = fmul double %dz_6_7, %dz_6_7
  %pre_sqrt_6_7 = fadd double %tmp_37_6_7, %tmp_38_6_7
  %p_r_6_7 = call double @llvm.sqrt.f64(double %pre_sqrt_6_7)
  %tmp_39_6_7 = fmul double %pre_sqrt_6_7, %p_r_6_7
  %tmp_40_6_7 = fdiv double -1.000000e+00, %tmp_39_6_7
  %prefact_6_7 = fmul double %tmp_40_6_7, %p_m_7_load
  %tmp_41_6_7 = fmul double %prefact_6_7, %dx_6_7
  %tmp_42_6_7 = fadd double %tmp_42_6_5, %tmp_41_6_7
  %tmp_43_6_7 = fmul double %prefact_6_7, %dy_6_7
  %tmp_44_6_7 = fadd double %tmp_44_6_5, %tmp_43_6_7
  %tmp_45_6_7 = fmul double %prefact_6_7, %dz_6_7
  %tmp_46_6_7 = fadd double %tmp_46_6_5, %tmp_45_6_7
  %dx_6_8 = fsub double %p_x_6_load, %p_x_8_load
  %dy_6_8 = fsub double %p_y_6_load, %p_y_8_load
  %dz_6_8 = fsub double %p_z_6_load, %p_z_8_load
  %tmp_35_6_8 = fmul double %dx_6_8, %dx_6_8
  %tmp_36_6_8 = fmul double %dy_6_8, %dy_6_8
  %tmp_37_6_8 = fadd double %tmp_35_6_8, %tmp_36_6_8
  %tmp_38_6_8 = fmul double %dz_6_8, %dz_6_8
  %pre_sqrt_6_8 = fadd double %tmp_37_6_8, %tmp_38_6_8
  %p_r_6_8 = call double @llvm.sqrt.f64(double %pre_sqrt_6_8)
  %tmp_39_6_8 = fmul double %pre_sqrt_6_8, %p_r_6_8
  %tmp_40_6_8 = fdiv double -1.000000e+00, %tmp_39_6_8
  %prefact_6_8 = fmul double %tmp_40_6_8, %p_m_8_load
  %tmp_41_6_8 = fmul double %prefact_6_8, %dx_6_8
  %tmp_42_6_8 = fadd double %tmp_42_6_7, %tmp_41_6_8
  store double %tmp_42_6_8, double* @p_ax_6, align 16
  %tmp_43_6_8 = fmul double %prefact_6_8, %dy_6_8
  %tmp_44_6_8 = fadd double %tmp_44_6_7, %tmp_43_6_8
  store double %tmp_44_6_8, double* @p_ay_6, align 16
  %tmp_45_6_8 = fmul double %prefact_6_8, %dz_6_8
  %tmp_46_6_8 = fadd double %tmp_46_6_7, %tmp_45_6_8
  store double %tmp_46_6_8, double* @p_az_6, align 16
  %dx_7 = fsub double %p_x_7_load, %p_x_0_load
  %dy_7 = fsub double %p_y_7_load, %p_y_0_load
  %dz_7 = fsub double %p_z_7_load, %p_z_0_load
  %tmp_35_7 = fmul double %dx_7, %dx_7
  %tmp_36_7 = fmul double %dy_7, %dy_7
  %tmp_37_7 = fadd double %tmp_35_7, %tmp_36_7
  %tmp_38_7 = fmul double %dz_7, %dz_7
  %pre_sqrt_7 = fadd double %tmp_37_7, %tmp_38_7
  %p_r_7 = call double @llvm.sqrt.f64(double %pre_sqrt_7)
  %tmp_39_7 = fmul double %pre_sqrt_7, %p_r_7
  %tmp_40_7 = fdiv double -1.000000e+00, %tmp_39_7
  %prefact_7 = fmul double %tmp_40_7, %p_m_0_load
  %tmp_41_7 = fmul double %prefact_7, %dx_7
  %tmp_42_7 = fadd double %tmp_41_7, 0.000000e+00
  %tmp_43_7 = fmul double %prefact_7, %dy_7
  %tmp_44_7 = fadd double %tmp_43_7, 0.000000e+00
  %tmp_45_7 = fmul double %prefact_7, %dz_7
  %tmp_46_7 = fadd double %tmp_45_7, 0.000000e+00
  %dx_7_1 = fsub double %p_x_7_load, %p_x_1_load
  %dy_7_1 = fsub double %p_y_7_load, %p_y_1_load
  %dz_7_1 = fsub double %p_z_7_load, %p_z_1_load
  %tmp_35_7_1 = fmul double %dx_7_1, %dx_7_1
  %tmp_36_7_1 = fmul double %dy_7_1, %dy_7_1
  %tmp_37_7_1 = fadd double %tmp_35_7_1, %tmp_36_7_1
  %tmp_38_7_1 = fmul double %dz_7_1, %dz_7_1
  %pre_sqrt_7_1 = fadd double %tmp_37_7_1, %tmp_38_7_1
  %p_r_7_1 = call double @llvm.sqrt.f64(double %pre_sqrt_7_1)
  %tmp_39_7_1 = fmul double %pre_sqrt_7_1, %p_r_7_1
  %tmp_40_7_1 = fdiv double -1.000000e+00, %tmp_39_7_1
  %prefact_7_1 = fmul double %tmp_40_7_1, %p_m_1_load
  %tmp_41_7_1 = fmul double %prefact_7_1, %dx_7_1
  %tmp_42_7_1 = fadd double %tmp_42_7, %tmp_41_7_1
  %tmp_43_7_1 = fmul double %prefact_7_1, %dy_7_1
  %tmp_44_7_1 = fadd double %tmp_44_7, %tmp_43_7_1
  %tmp_45_7_1 = fmul double %prefact_7_1, %dz_7_1
  %tmp_46_7_1 = fadd double %tmp_46_7, %tmp_45_7_1
  %dx_7_2 = fsub double %p_x_7_load, %p_x_2_load
  %dy_7_2 = fsub double %p_y_7_load, %p_y_2_load
  %dz_7_2 = fsub double %p_z_7_load, %p_z_2_load
  %tmp_35_7_2 = fmul double %dx_7_2, %dx_7_2
  %tmp_36_7_2 = fmul double %dy_7_2, %dy_7_2
  %tmp_37_7_2 = fadd double %tmp_35_7_2, %tmp_36_7_2
  %tmp_38_7_2 = fmul double %dz_7_2, %dz_7_2
  %pre_sqrt_7_2 = fadd double %tmp_37_7_2, %tmp_38_7_2
  %p_r_7_2 = call double @llvm.sqrt.f64(double %pre_sqrt_7_2)
  %tmp_39_7_2 = fmul double %pre_sqrt_7_2, %p_r_7_2
  %tmp_40_7_2 = fdiv double -1.000000e+00, %tmp_39_7_2
  %prefact_7_2 = fmul double %tmp_40_7_2, %p_m_2_load
  %tmp_41_7_2 = fmul double %prefact_7_2, %dx_7_2
  %tmp_42_7_2 = fadd double %tmp_42_7_1, %tmp_41_7_2
  %tmp_43_7_2 = fmul double %prefact_7_2, %dy_7_2
  %tmp_44_7_2 = fadd double %tmp_44_7_1, %tmp_43_7_2
  %tmp_45_7_2 = fmul double %prefact_7_2, %dz_7_2
  %tmp_46_7_2 = fadd double %tmp_46_7_1, %tmp_45_7_2
  %dx_7_3 = fsub double %p_x_7_load, %p_x_3_load
  %dy_7_3 = fsub double %p_y_7_load, %p_y_3_load
  %dz_7_3 = fsub double %p_z_7_load, %p_z_3_load
  %tmp_35_7_3 = fmul double %dx_7_3, %dx_7_3
  %tmp_36_7_3 = fmul double %dy_7_3, %dy_7_3
  %tmp_37_7_3 = fadd double %tmp_35_7_3, %tmp_36_7_3
  %tmp_38_7_3 = fmul double %dz_7_3, %dz_7_3
  %pre_sqrt_7_3 = fadd double %tmp_37_7_3, %tmp_38_7_3
  %p_r_7_3 = call double @llvm.sqrt.f64(double %pre_sqrt_7_3)
  %tmp_39_7_3 = fmul double %pre_sqrt_7_3, %p_r_7_3
  %tmp_40_7_3 = fdiv double -1.000000e+00, %tmp_39_7_3
  %prefact_7_3 = fmul double %tmp_40_7_3, %p_m_3_load
  %tmp_41_7_3 = fmul double %prefact_7_3, %dx_7_3
  %tmp_42_7_3 = fadd double %tmp_42_7_2, %tmp_41_7_3
  %tmp_43_7_3 = fmul double %prefact_7_3, %dy_7_3
  %tmp_44_7_3 = fadd double %tmp_44_7_2, %tmp_43_7_3
  %tmp_45_7_3 = fmul double %prefact_7_3, %dz_7_3
  %tmp_46_7_3 = fadd double %tmp_46_7_2, %tmp_45_7_3
  %dx_7_4 = fsub double %p_x_7_load, %p_x_4_load
  %dy_7_4 = fsub double %p_y_7_load, %p_y_4_load
  %dz_7_4 = fsub double %p_z_7_load, %p_z_4_load
  %tmp_35_7_4 = fmul double %dx_7_4, %dx_7_4
  %tmp_36_7_4 = fmul double %dy_7_4, %dy_7_4
  %tmp_37_7_4 = fadd double %tmp_35_7_4, %tmp_36_7_4
  %tmp_38_7_4 = fmul double %dz_7_4, %dz_7_4
  %pre_sqrt_7_4 = fadd double %tmp_37_7_4, %tmp_38_7_4
  %p_r_7_4 = call double @llvm.sqrt.f64(double %pre_sqrt_7_4)
  %tmp_39_7_4 = fmul double %pre_sqrt_7_4, %p_r_7_4
  %tmp_40_7_4 = fdiv double -1.000000e+00, %tmp_39_7_4
  %prefact_7_4 = fmul double %tmp_40_7_4, %p_m_4_load
  %tmp_41_7_4 = fmul double %prefact_7_4, %dx_7_4
  %tmp_42_7_4 = fadd double %tmp_42_7_3, %tmp_41_7_4
  %tmp_43_7_4 = fmul double %prefact_7_4, %dy_7_4
  %tmp_44_7_4 = fadd double %tmp_44_7_3, %tmp_43_7_4
  %tmp_45_7_4 = fmul double %prefact_7_4, %dz_7_4
  %tmp_46_7_4 = fadd double %tmp_46_7_3, %tmp_45_7_4
  %dx_7_5 = fsub double %p_x_7_load, %p_x_5_load
  %dy_7_5 = fsub double %p_y_7_load, %p_y_5_load
  %dz_7_5 = fsub double %p_z_7_load, %p_z_5_load
  %tmp_35_7_5 = fmul double %dx_7_5, %dx_7_5
  %tmp_36_7_5 = fmul double %dy_7_5, %dy_7_5
  %tmp_37_7_5 = fadd double %tmp_35_7_5, %tmp_36_7_5
  %tmp_38_7_5 = fmul double %dz_7_5, %dz_7_5
  %pre_sqrt_7_5 = fadd double %tmp_37_7_5, %tmp_38_7_5
  %p_r_7_5 = call double @llvm.sqrt.f64(double %pre_sqrt_7_5)
  %tmp_39_7_5 = fmul double %pre_sqrt_7_5, %p_r_7_5
  %tmp_40_7_5 = fdiv double -1.000000e+00, %tmp_39_7_5
  %prefact_7_5 = fmul double %tmp_40_7_5, %p_m_5_load
  %tmp_41_7_5 = fmul double %prefact_7_5, %dx_7_5
  %tmp_42_7_5 = fadd double %tmp_42_7_4, %tmp_41_7_5
  %tmp_43_7_5 = fmul double %prefact_7_5, %dy_7_5
  %tmp_44_7_5 = fadd double %tmp_44_7_4, %tmp_43_7_5
  %tmp_45_7_5 = fmul double %prefact_7_5, %dz_7_5
  %tmp_46_7_5 = fadd double %tmp_46_7_4, %tmp_45_7_5
  %dx_7_6 = fsub double %p_x_7_load, %p_x_6_load
  %dy_7_6 = fsub double %p_y_7_load, %p_y_6_load
  %dz_7_6 = fsub double %p_z_7_load, %p_z_6_load
  %tmp_35_7_6 = fmul double %dx_7_6, %dx_7_6
  %tmp_36_7_6 = fmul double %dy_7_6, %dy_7_6
  %tmp_37_7_6 = fadd double %tmp_35_7_6, %tmp_36_7_6
  %tmp_38_7_6 = fmul double %dz_7_6, %dz_7_6
  %pre_sqrt_7_6 = fadd double %tmp_37_7_6, %tmp_38_7_6
  %p_r_7_6 = call double @llvm.sqrt.f64(double %pre_sqrt_7_6)
  %tmp_39_7_6 = fmul double %pre_sqrt_7_6, %p_r_7_6
  %tmp_40_7_6 = fdiv double -1.000000e+00, %tmp_39_7_6
  %p_m_6_load_1 = load double* @p_m_6, align 16
  %prefact_7_6 = fmul double %tmp_40_7_6, %p_m_6_load_1
  %tmp_41_7_6 = fmul double %prefact_7_6, %dx_7_6
  %tmp_42_7_6 = fadd double %tmp_42_7_5, %tmp_41_7_6
  %tmp_43_7_6 = fmul double %prefact_7_6, %dy_7_6
  %tmp_44_7_6 = fadd double %tmp_44_7_5, %tmp_43_7_6
  %tmp_45_7_6 = fmul double %prefact_7_6, %dz_7_6
  %tmp_46_7_6 = fadd double %tmp_46_7_5, %tmp_45_7_6
  %dx_7_8 = fsub double %p_x_7_load, %p_x_8_load
  %dy_7_8 = fsub double %p_y_7_load, %p_y_8_load
  %dz_7_8 = fsub double %p_z_7_load, %p_z_8_load
  %tmp_35_7_8 = fmul double %dx_7_8, %dx_7_8
  %tmp_36_7_8 = fmul double %dy_7_8, %dy_7_8
  %tmp_37_7_8 = fadd double %tmp_35_7_8, %tmp_36_7_8
  %tmp_38_7_8 = fmul double %dz_7_8, %dz_7_8
  %pre_sqrt_7_8 = fadd double %tmp_37_7_8, %tmp_38_7_8
  %p_r_7_8 = call double @llvm.sqrt.f64(double %pre_sqrt_7_8)
  %tmp_39_7_8 = fmul double %pre_sqrt_7_8, %p_r_7_8
  %tmp_40_7_8 = fdiv double -1.000000e+00, %tmp_39_7_8
  %prefact_7_8 = fmul double %tmp_40_7_8, %p_m_8_load
  %tmp_41_7_8 = fmul double %prefact_7_8, %dx_7_8
  %tmp_42_7_8 = fadd double %tmp_42_7_6, %tmp_41_7_8
  store double %tmp_42_7_8, double* @p_ax_7, align 16
  %tmp_43_7_8 = fmul double %prefact_7_8, %dy_7_8
  %tmp_44_7_8 = fadd double %tmp_44_7_6, %tmp_43_7_8
  store double %tmp_44_7_8, double* @p_ay_7, align 8
  %tmp_45_7_8 = fmul double %prefact_7_8, %dz_7_8
  %tmp_46_7_8 = fadd double %tmp_46_7_6, %tmp_45_7_8
  store double %tmp_46_7_8, double* @p_az_7, align 16
  %dx_8 = fsub double %p_x_8_load, %p_x_0_load
  %dy_8 = fsub double %p_y_8_load, %p_y_0_load
  %dz_8 = fsub double %p_z_8_load, %p_z_0_load
  %tmp_35_8 = fmul double %dx_8, %dx_8
  %tmp_36_8 = fmul double %dy_8, %dy_8
  %tmp_37_8 = fadd double %tmp_35_8, %tmp_36_8
  %tmp_38_8 = fmul double %dz_8, %dz_8
  %pre_sqrt_8 = fadd double %tmp_37_8, %tmp_38_8
  %p_r_8 = call double @llvm.sqrt.f64(double %pre_sqrt_8)
  %tmp_39_8 = fmul double %pre_sqrt_8, %p_r_8
  %tmp_40_8 = fdiv double -1.000000e+00, %tmp_39_8
  %prefact_8 = fmul double %tmp_40_8, %p_m_0_load
  %tmp_41_8 = fmul double %prefact_8, %dx_8
  %tmp_42_8 = fadd double %tmp_41_8, 0.000000e+00
  %tmp_43_8 = fmul double %prefact_8, %dy_8
  %tmp_44_8 = fadd double %tmp_43_8, 0.000000e+00
  %tmp_45_8 = fmul double %prefact_8, %dz_8
  %tmp_46_8 = fadd double %tmp_45_8, 0.000000e+00
  %dx_8_1 = fsub double %p_x_8_load, %p_x_1_load
  %dy_8_1 = fsub double %p_y_8_load, %p_y_1_load
  %dz_8_1 = fsub double %p_z_8_load, %p_z_1_load
  %tmp_35_8_1 = fmul double %dx_8_1, %dx_8_1
  %tmp_36_8_1 = fmul double %dy_8_1, %dy_8_1
  %tmp_37_8_1 = fadd double %tmp_35_8_1, %tmp_36_8_1
  %tmp_38_8_1 = fmul double %dz_8_1, %dz_8_1
  %pre_sqrt_8_1 = fadd double %tmp_37_8_1, %tmp_38_8_1
  %p_r_8_1 = call double @llvm.sqrt.f64(double %pre_sqrt_8_1)
  %tmp_39_8_1 = fmul double %pre_sqrt_8_1, %p_r_8_1
  %tmp_40_8_1 = fdiv double -1.000000e+00, %tmp_39_8_1
  %prefact_8_1 = fmul double %tmp_40_8_1, %p_m_1_load
  %tmp_41_8_1 = fmul double %prefact_8_1, %dx_8_1
  %tmp_42_8_1 = fadd double %tmp_42_8, %tmp_41_8_1
  %tmp_43_8_1 = fmul double %prefact_8_1, %dy_8_1
  %tmp_44_8_1 = fadd double %tmp_44_8, %tmp_43_8_1
  %tmp_45_8_1 = fmul double %prefact_8_1, %dz_8_1
  %tmp_46_8_1 = fadd double %tmp_46_8, %tmp_45_8_1
  %dx_8_2 = fsub double %p_x_8_load, %p_x_2_load
  %dy_8_2 = fsub double %p_y_8_load, %p_y_2_load
  %dz_8_2 = fsub double %p_z_8_load, %p_z_2_load
  %tmp_35_8_2 = fmul double %dx_8_2, %dx_8_2
  %tmp_36_8_2 = fmul double %dy_8_2, %dy_8_2
  %tmp_37_8_2 = fadd double %tmp_35_8_2, %tmp_36_8_2
  %tmp_38_8_2 = fmul double %dz_8_2, %dz_8_2
  %pre_sqrt_8_2 = fadd double %tmp_37_8_2, %tmp_38_8_2
  %p_r_8_2 = call double @llvm.sqrt.f64(double %pre_sqrt_8_2)
  %tmp_39_8_2 = fmul double %pre_sqrt_8_2, %p_r_8_2
  %tmp_40_8_2 = fdiv double -1.000000e+00, %tmp_39_8_2
  %prefact_8_2 = fmul double %tmp_40_8_2, %p_m_2_load
  %tmp_41_8_2 = fmul double %prefact_8_2, %dx_8_2
  %tmp_42_8_2 = fadd double %tmp_42_8_1, %tmp_41_8_2
  %tmp_43_8_2 = fmul double %prefact_8_2, %dy_8_2
  %tmp_44_8_2 = fadd double %tmp_44_8_1, %tmp_43_8_2
  %tmp_45_8_2 = fmul double %prefact_8_2, %dz_8_2
  %tmp_46_8_2 = fadd double %tmp_46_8_1, %tmp_45_8_2
  %dx_8_3 = fsub double %p_x_8_load, %p_x_3_load
  %dy_8_3 = fsub double %p_y_8_load, %p_y_3_load
  %dz_8_3 = fsub double %p_z_8_load, %p_z_3_load
  %tmp_35_8_3 = fmul double %dx_8_3, %dx_8_3
  %tmp_36_8_3 = fmul double %dy_8_3, %dy_8_3
  %tmp_37_8_3 = fadd double %tmp_35_8_3, %tmp_36_8_3
  %tmp_38_8_3 = fmul double %dz_8_3, %dz_8_3
  %pre_sqrt_8_3 = fadd double %tmp_37_8_3, %tmp_38_8_3
  %p_r_8_3 = call double @llvm.sqrt.f64(double %pre_sqrt_8_3)
  %tmp_39_8_3 = fmul double %pre_sqrt_8_3, %p_r_8_3
  %tmp_40_8_3 = fdiv double -1.000000e+00, %tmp_39_8_3
  %prefact_8_3 = fmul double %tmp_40_8_3, %p_m_3_load
  %tmp_41_8_3 = fmul double %prefact_8_3, %dx_8_3
  %tmp_42_8_3 = fadd double %tmp_42_8_2, %tmp_41_8_3
  %tmp_43_8_3 = fmul double %prefact_8_3, %dy_8_3
  %tmp_44_8_3 = fadd double %tmp_44_8_2, %tmp_43_8_3
  %tmp_45_8_3 = fmul double %prefact_8_3, %dz_8_3
  %tmp_46_8_3 = fadd double %tmp_46_8_2, %tmp_45_8_3
  %dx_8_4 = fsub double %p_x_8_load, %p_x_4_load
  %dy_8_4 = fsub double %p_y_8_load, %p_y_4_load
  %dz_8_4 = fsub double %p_z_8_load, %p_z_4_load
  %tmp_35_8_4 = fmul double %dx_8_4, %dx_8_4
  %tmp_36_8_4 = fmul double %dy_8_4, %dy_8_4
  %tmp_37_8_4 = fadd double %tmp_35_8_4, %tmp_36_8_4
  %tmp_38_8_4 = fmul double %dz_8_4, %dz_8_4
  %pre_sqrt_8_4 = fadd double %tmp_37_8_4, %tmp_38_8_4
  %p_r_8_4 = call double @llvm.sqrt.f64(double %pre_sqrt_8_4)
  %tmp_39_8_4 = fmul double %pre_sqrt_8_4, %p_r_8_4
  %tmp_40_8_4 = fdiv double -1.000000e+00, %tmp_39_8_4
  %prefact_8_4 = fmul double %tmp_40_8_4, %p_m_4_load
  %tmp_41_8_4 = fmul double %prefact_8_4, %dx_8_4
  %tmp_42_8_4 = fadd double %tmp_42_8_3, %tmp_41_8_4
  %tmp_43_8_4 = fmul double %prefact_8_4, %dy_8_4
  %tmp_44_8_4 = fadd double %tmp_44_8_3, %tmp_43_8_4
  %tmp_45_8_4 = fmul double %prefact_8_4, %dz_8_4
  %tmp_46_8_4 = fadd double %tmp_46_8_3, %tmp_45_8_4
  %dx_8_5 = fsub double %p_x_8_load, %p_x_5_load
  %dy_8_5 = fsub double %p_y_8_load, %p_y_5_load
  %dz_8_5 = fsub double %p_z_8_load, %p_z_5_load
  %tmp_35_8_5 = fmul double %dx_8_5, %dx_8_5
  %tmp_36_8_5 = fmul double %dy_8_5, %dy_8_5
  %tmp_37_8_5 = fadd double %tmp_35_8_5, %tmp_36_8_5
  %tmp_38_8_5 = fmul double %dz_8_5, %dz_8_5
  %pre_sqrt_8_5 = fadd double %tmp_37_8_5, %tmp_38_8_5
  %p_r_8_5 = call double @llvm.sqrt.f64(double %pre_sqrt_8_5)
  %tmp_39_8_5 = fmul double %pre_sqrt_8_5, %p_r_8_5
  %tmp_40_8_5 = fdiv double -1.000000e+00, %tmp_39_8_5
  %prefact_8_5 = fmul double %tmp_40_8_5, %p_m_5_load
  %tmp_41_8_5 = fmul double %prefact_8_5, %dx_8_5
  %tmp_42_8_5 = fadd double %tmp_42_8_4, %tmp_41_8_5
  %tmp_43_8_5 = fmul double %prefact_8_5, %dy_8_5
  %tmp_44_8_5 = fadd double %tmp_44_8_4, %tmp_43_8_5
  %tmp_45_8_5 = fmul double %prefact_8_5, %dz_8_5
  %tmp_46_8_5 = fadd double %tmp_46_8_4, %tmp_45_8_5
  %dx_8_6 = fsub double %p_x_8_load, %p_x_6_load
  %dy_8_6 = fsub double %p_y_8_load, %p_y_6_load
  %dz_8_6 = fsub double %p_z_8_load, %p_z_6_load
  %tmp_35_8_6 = fmul double %dx_8_6, %dx_8_6
  %tmp_36_8_6 = fmul double %dy_8_6, %dy_8_6
  %tmp_37_8_6 = fadd double %tmp_35_8_6, %tmp_36_8_6
  %tmp_38_8_6 = fmul double %dz_8_6, %dz_8_6
  %pre_sqrt_8_6 = fadd double %tmp_37_8_6, %tmp_38_8_6
  %p_r_8_6 = call double @llvm.sqrt.f64(double %pre_sqrt_8_6)
  %tmp_39_8_6 = fmul double %pre_sqrt_8_6, %p_r_8_6
  %tmp_40_8_6 = fdiv double -1.000000e+00, %tmp_39_8_6
  %prefact_8_6 = fmul double %tmp_40_8_6, %p_m_6_load_1
  %tmp_41_8_6 = fmul double %prefact_8_6, %dx_8_6
  %tmp_42_8_6 = fadd double %tmp_42_8_5, %tmp_41_8_6
  %tmp_43_8_6 = fmul double %prefact_8_6, %dy_8_6
  %tmp_44_8_6 = fadd double %tmp_44_8_5, %tmp_43_8_6
  %tmp_45_8_6 = fmul double %prefact_8_6, %dz_8_6
  %tmp_46_8_6 = fadd double %tmp_46_8_5, %tmp_45_8_6
  %dx_8_7 = fsub double %p_x_8_load, %p_x_7_load
  %dy_8_7 = fsub double %p_y_8_load, %p_y_7_load
  %dz_8_7 = fsub double %p_z_8_load, %p_z_7_load
  %tmp_35_8_7 = fmul double %dx_8_7, %dx_8_7
  %tmp_36_8_7 = fmul double %dy_8_7, %dy_8_7
  %tmp_37_8_7 = fadd double %tmp_35_8_7, %tmp_36_8_7
  %tmp_38_8_7 = fmul double %dz_8_7, %dz_8_7
  %pre_sqrt_8_7 = fadd double %tmp_37_8_7, %tmp_38_8_7
  %p_r_8_7 = call double @llvm.sqrt.f64(double %pre_sqrt_8_7)
  %tmp_39_8_7 = fmul double %pre_sqrt_8_7, %p_r_8_7
  %tmp_40_8_7 = fdiv double -1.000000e+00, %tmp_39_8_7
  %prefact_8_7 = fmul double %tmp_40_8_7, %p_m_7_load
  %tmp_41_8_7 = fmul double %prefact_8_7, %dx_8_7
  %tmp_42_8_7 = fadd double %tmp_42_8_6, %tmp_41_8_7
  store double %tmp_42_8_7, double* @p_ax_8, align 16
  %tmp_43_8_7 = fmul double %prefact_8_7, %dy_8_7
  %tmp_44_8_7 = fadd double %tmp_44_8_6, %tmp_43_8_7
  store double %tmp_44_8_7, double* @p_ay_8, align 16
  %tmp_45_8_7 = fmul double %prefact_8_7, %dz_8_7
  %tmp_46_8_7 = fadd double %tmp_46_8_6, %tmp_45_8_7
  store double %tmp_46_8_7, double* @p_az_8, align 16
  ret void
}

define internal fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_read, i64 %p_int_1_x_read, i64 %p_int_2_x_read, i64 %p_int_3_x_read, i64 %p_int_4_x_read, i64 %p_int_5_x_read, i64 %p_int_6_x_read, i64 %p_int_7_x_read, i64 %p_int_8_x_read, i64 %p_int_0_y_read, i64 %p_int_1_y_read, i64 %p_int_2_y_read, i64 %p_int_3_y_read, i64 %p_int_4_y_read, i64 %p_int_5_y_read, i64 %p_int_6_y_read, i64 %p_int_7_y_read, i64 %p_int_8_y_read, i64 %p_int_0_z_read, i64 %p_int_1_z_read, i64 %p_int_2_z_read, i64 %p_int_3_z_read, i64 %p_int_4_z_read, i64 %p_int_5_z_read, i64 %p_int_6_z_read, i64 %p_int_7_z_read, i64 %p_int_8_z_read, i64 %p_int_0_vx_read, i64 %p_int_1_vx_read, i64 %p_int_2_vx_read, i64 %p_int_3_vx_read, i64 %p_int_4_vx_read, i64 %p_int_5_vx_read, i64 %p_int_6_vx_read, i64 %p_int_7_vx_read, i64 %p_int_8_vx_read, i64 %p_int_0_vy_read, i64 %p_int_1_vy_read, i64 %p_int_2_vy_read, i64 %p_int_3_vy_read, i64 %p_int_4_vy_read, i64 %p_int_5_vy_read, i64 %p_int_6_vy_read, i64 %p_int_7_vy_read, i64 %p_int_8_vy_read, i64 %p_int_0_vz_read, i64 %p_int_1_vz_read, i64 %p_int_2_vz_read, i64 %p_int_3_vz_read, i64 %p_int_4_vz_read, i64 %p_int_5_vz_read, i64 %p_int_6_vz_read, i64 %p_int_7_vz_read, i64 %p_int_8_vz_read) readnone {
  %p_int_8_vz_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_vz_read)
  %p_int_7_vz_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_vz_read)
  %p_int_6_vz_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_vz_read)
  %p_int_5_vz_read51 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_vz_read)
  %p_int_4_vz_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_vz_read)
  %p_int_3_vz_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_vz_read)
  %p_int_2_vz_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_vz_read)
  %p_int_1_vz_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_vz_read)
  %p_int_0_vz_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_vz_read)
  %p_int_8_vy_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_vy_read)
  %p_int_7_vy_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_vy_read)
  %p_int_6_vy_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_vy_read)
  %p_int_5_vy_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_vy_read)
  %p_int_4_vy_read41 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_vy_read)
  %p_int_3_vy_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_vy_read)
  %p_int_2_vy_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_vy_read)
  %p_int_1_vy_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_vy_read)
  %p_int_0_vy_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_vy_read)
  %p_int_8_vx_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_vx_read)
  %p_int_7_vx_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_vx_read)
  %p_int_6_vx_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_vx_read)
  %p_int_5_vx_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_vx_read)
  %p_int_4_vx_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_vx_read)
  %p_int_3_vx_read31 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_vx_read)
  %p_int_2_vx_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_vx_read)
  %p_int_1_vx_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_vx_read)
  %p_int_0_vx_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_vx_read)
  %p_int_8_z_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_z_read)
  %p_int_7_z_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_z_read)
  %p_int_6_z_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_z_read)
  %p_int_5_z_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_z_read)
  %p_int_4_z_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_z_read)
  %p_int_3_z_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_z_read)
  %p_int_2_z_read21 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_z_read)
  %p_int_1_z_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_z_read)
  %p_int_0_z_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_z_read)
  %p_int_8_y_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_y_read)
  %p_int_7_y_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_y_read)
  %p_int_6_y_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_y_read)
  %p_int_5_y_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_y_read)
  %p_int_4_y_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_y_read)
  %p_int_3_y_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_y_read)
  %p_int_2_y_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_y_read)
  %p_int_1_y_read11 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_y_read)
  %p_int_0_y_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_y_read)
  %p_int_8_x_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_8_x_read)
  %p_int_7_x_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_7_x_read)
  %p_int_6_x_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_6_x_read)
  %p_int_5_x_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_5_x_read)
  %p_int_4_x_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_4_x_read)
  %p_int_3_x_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_3_x_read)
  %p_int_2_x_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_2_x_read)
  %p_int_1_x_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_1_x_read)
  %p_int_0_x_read_2 = call i64 @_ssdm_op_Read.ap_auto.i64(i64 %p_int_0_x_read)
  br label %1

; <label>:1                                       ; preds = %_ifconv, %0
  %p_int_x = phi i64 [ %p_int_0_x_read_2, %0 ], [ %p_int_x_1, %_ifconv ]
  %p_int_x1 = phi i64 [ %p_int_1_x_read_2, %0 ], [ %p_int_x12_1, %_ifconv ]
  %p_int_x2 = phi i64 [ %p_int_2_x_read_2, %0 ], [ %p_int_x2_1, %_ifconv ]
  %p_int_x3 = phi i64 [ %p_int_3_x_read_2, %0 ], [ %p_int_x3_1, %_ifconv ]
  %p_int_x4 = phi i64 [ %p_int_4_x_read_2, %0 ], [ %p_int_x4_1, %_ifconv ]
  %p_int_x5 = phi i64 [ %p_int_5_x_read_2, %0 ], [ %p_int_x5_1, %_ifconv ]
  %p_int_x6 = phi i64 [ %p_int_6_x_read_2, %0 ], [ %p_int_x6_1, %_ifconv ]
  %p_int_x7 = phi i64 [ %p_int_7_x_read_2, %0 ], [ %p_int_x7_1, %_ifconv ]
  %p_int_x8 = phi i64 [ %p_int_8_x_read_2, %0 ], [ %p_int_x8_1, %_ifconv ]
  %p_int_y = phi i64 [ %p_int_0_y_read_2, %0 ], [ %p_int_y_1, %_ifconv ]
  %p_int_y9 = phi i64 [ %p_int_1_y_read11, %0 ], [ %p_int_y9_1, %_ifconv ]
  %p_int_y1 = phi i64 [ %p_int_2_y_read_2, %0 ], [ %p_int_y10_1, %_ifconv ]
  %p_int_y2 = phi i64 [ %p_int_3_y_read_2, %0 ], [ %p_int_y1114_1, %_ifconv ]
  %p_int_y3 = phi i64 [ %p_int_4_y_read_2, %0 ], [ %p_int_y12_1, %_ifconv ]
  %p_int_y4 = phi i64 [ %p_int_5_y_read_2, %0 ], [ %p_int_y13_1, %_ifconv ]
  %p_int_y5 = phi i64 [ %p_int_6_y_read_2, %0 ], [ %p_int_y14_1, %_ifconv ]
  %p_int_y6 = phi i64 [ %p_int_7_y_read_2, %0 ], [ %p_int_y15_1, %_ifconv ]
  %p_int_y7 = phi i64 [ %p_int_8_y_read_2, %0 ], [ %p_int_y16_1, %_ifconv ]
  %p_int_z = phi i64 [ %p_int_0_z_read_2, %0 ], [ %p_int_z_1, %_ifconv ]
  %p_int_z1 = phi i64 [ %p_int_1_z_read_2, %0 ], [ %p_int_z17_1, %_ifconv ]
  %p_int_z2 = phi i64 [ %p_int_2_z_read21, %0 ], [ %p_int_z18_1, %_ifconv ]
  %p_int_z3 = phi i64 [ %p_int_3_z_read_2, %0 ], [ %p_int_z19_1, %_ifconv ]
  %p_int_z4 = phi i64 [ %p_int_4_z_read_2, %0 ], [ %p_int_z20_1, %_ifconv ]
  %p_int_z5 = phi i64 [ %p_int_5_z_read_2, %0 ], [ %p_int_z2126_1, %_ifconv ]
  %p_int_z6 = phi i64 [ %p_int_6_z_read_2, %0 ], [ %p_int_z22_1, %_ifconv ]
  %p_int_z7 = phi i64 [ %p_int_7_z_read_2, %0 ], [ %p_int_z23_1, %_ifconv ]
  %p_int_z8 = phi i64 [ %p_int_8_z_read_2, %0 ], [ %p_int_z24_1, %_ifconv ]
  %i = phi i4 [ 0, %0 ], [ %i_3_2, %_ifconv ]
  %tmp = icmp eq i4 %i, -7
  br i1 %tmp, label %2, label %_ifconv

_ifconv:                                          ; preds = %1
  %empty = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_s = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str11)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %sel_tmp = icmp eq i4 %i, 3
  %sel_tmp1 = select i1 %sel_tmp, i64 %p_int_3_vx_read31, i64 %p_int_6_vx_read_2
  %sel_tmp2 = icmp eq i4 %i, 0
  %p_int_vx_load_0_phi = select i1 %sel_tmp2, i64 %p_int_0_vx_read_2, i64 %sel_tmp1
  %tmp_13 = sitofp i64 %p_int_vx_load_0_phi to double
  %tmp_14 = fmul double %tmp_13, 5.000000e-03
  %tmp_15 = call fastcc i64 @__hls_fptosi_double_(double %tmp_14)
  %p_int_x_load_0_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_x, i64 %p_int_x6, i64 %p_int_x6, i64 %p_int_x3, i64 %p_int_x6, i64 %p_int_x6, i64 %p_int_x6, i64 %p_int_x6, i64 %p_int_x6, i64 %p_int_x6, i64 %p_int_x6, i64 %p_int_x6, i64 %p_int_x6, i64 %p_int_x6, i64 %p_int_x6, i64 %p_int_x6, i4 %i)
  %tmp_16 = add nsw i64 %tmp_15, %p_int_x_load_0_phi
  %p_int_x6_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_x6, i64 %tmp_16, i64 %tmp_16, i64 %p_int_x6, i64 %tmp_16, i64 %tmp_16, i64 %tmp_16, i64 %tmp_16, i64 %tmp_16, i64 %tmp_16, i64 %tmp_16, i64 %tmp_16, i64 %tmp_16, i64 %tmp_16, i64 %tmp_16, i64 %tmp_16, i4 %i)
  %p_int_x3_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_x3, i64 %p_int_x3, i64 %p_int_x3, i64 %tmp_16, i64 %p_int_x3, i64 %p_int_x3, i64 %p_int_x3, i64 %p_int_x3, i64 %p_int_x3, i64 %p_int_x3, i64 %p_int_x3, i64 %p_int_x3, i64 %p_int_x3, i64 %p_int_x3, i64 %p_int_x3, i64 %p_int_x3, i4 %i)
  %p_int_x_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %tmp_16, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i64 %p_int_x, i4 %i)
  %p_int_vy_load_0_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_0_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_3_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i64 %p_int_6_vy_read_2, i4 %i)
  %tmp_17 = sitofp i64 %p_int_vy_load_0_phi to double
  %tmp_18 = fmul double %tmp_17, 5.000000e-03
  %tmp_19 = call fastcc i64 @__hls_fptosi_double_(double %tmp_18)
  %p_int_y_load_0_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_y, i64 %p_int_y5, i64 %p_int_y5, i64 %p_int_y2, i64 %p_int_y5, i64 %p_int_y5, i64 %p_int_y5, i64 %p_int_y5, i64 %p_int_y5, i64 %p_int_y5, i64 %p_int_y5, i64 %p_int_y5, i64 %p_int_y5, i64 %p_int_y5, i64 %p_int_y5, i64 %p_int_y5, i4 %i)
  %tmp_20 = add nsw i64 %tmp_19, %p_int_y_load_0_phi
  %p_int_y14_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_y5, i64 %tmp_20, i64 %tmp_20, i64 %p_int_y5, i64 %tmp_20, i64 %tmp_20, i64 %tmp_20, i64 %tmp_20, i64 %tmp_20, i64 %tmp_20, i64 %tmp_20, i64 %tmp_20, i64 %tmp_20, i64 %tmp_20, i64 %tmp_20, i64 %tmp_20, i4 %i)
  %p_int_y1114_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_y2, i64 %p_int_y2, i64 %p_int_y2, i64 %tmp_20, i64 %p_int_y2, i64 %p_int_y2, i64 %p_int_y2, i64 %p_int_y2, i64 %p_int_y2, i64 %p_int_y2, i64 %p_int_y2, i64 %p_int_y2, i64 %p_int_y2, i64 %p_int_y2, i64 %p_int_y2, i64 %p_int_y2, i4 %i)
  %p_int_y_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %tmp_20, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i64 %p_int_y, i4 %i)
  %p_int_vz_load_0_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_0_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_3_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i64 %p_int_6_vz_read_2, i4 %i)
  %tmp_21 = sitofp i64 %p_int_vz_load_0_phi to double
  %tmp_22 = fmul double %tmp_21, 5.000000e-03
  %tmp_23 = call fastcc i64 @__hls_fptosi_double_(double %tmp_22)
  %p_int_z_load_0_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_z, i64 %p_int_z6, i64 %p_int_z6, i64 %p_int_z3, i64 %p_int_z6, i64 %p_int_z6, i64 %p_int_z6, i64 %p_int_z6, i64 %p_int_z6, i64 %p_int_z6, i64 %p_int_z6, i64 %p_int_z6, i64 %p_int_z6, i64 %p_int_z6, i64 %p_int_z6, i64 %p_int_z6, i4 %i)
  %tmp_24 = add nsw i64 %tmp_23, %p_int_z_load_0_phi
  %p_int_z22_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_z6, i64 %tmp_24, i64 %tmp_24, i64 %p_int_z6, i64 %tmp_24, i64 %tmp_24, i64 %tmp_24, i64 %tmp_24, i64 %tmp_24, i64 %tmp_24, i64 %tmp_24, i64 %tmp_24, i64 %tmp_24, i64 %tmp_24, i64 %tmp_24, i64 %tmp_24, i4 %i)
  %p_int_z19_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_z3, i64 %p_int_z3, i64 %p_int_z3, i64 %tmp_24, i64 %p_int_z3, i64 %p_int_z3, i64 %p_int_z3, i64 %p_int_z3, i64 %p_int_z3, i64 %p_int_z3, i64 %p_int_z3, i64 %p_int_z3, i64 %p_int_z3, i64 %p_int_z3, i64 %p_int_z3, i64 %p_int_z3, i4 %i)
  %p_int_z_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %tmp_24, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i64 %p_int_z, i4 %i)
  %empty_9 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str11, i32 %tmp_s)
  %i_3_0_t = add i4 %i, 1
  %p_int_vx_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_7_vx_read_2, i64 %p_int_1_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_4_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_7_vx_read_2, i64 %p_int_7_vx_read_2, i4 %i_3_0_t)
  %tmp_47_1 = sitofp i64 %p_int_vx_load_1_phi to double
  %tmp_48_1 = fmul double %tmp_47_1, 5.000000e-03
  %tmp_49_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_48_1)
  %p_int_x_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_x7, i64 %p_int_x1, i64 %p_int_x7, i64 %p_int_x7, i64 %p_int_x4, i64 %p_int_x7, i64 %p_int_x7, i64 %p_int_x7, i64 %p_int_x7, i64 %p_int_x7, i64 %p_int_x7, i64 %p_int_x7, i64 %p_int_x7, i64 %p_int_x7, i64 %p_int_x7, i64 %p_int_x7, i4 %i_3_0_t)
  %tmp_50_1 = add nsw i64 %tmp_49_1, %p_int_x_load_1_phi
  %p_int_x7_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %tmp_50_1, i64 %p_int_x7, i64 %tmp_50_1, i64 %tmp_50_1, i64 %p_int_x7, i64 %tmp_50_1, i64 %tmp_50_1, i64 %tmp_50_1, i64 %tmp_50_1, i64 %tmp_50_1, i64 %tmp_50_1, i64 %tmp_50_1, i64 %tmp_50_1, i64 %tmp_50_1, i64 %tmp_50_1, i64 %tmp_50_1, i4 %i_3_0_t)
  %p_int_x4_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_x4, i64 %p_int_x4, i64 %p_int_x4, i64 %p_int_x4, i64 %tmp_50_1, i64 %p_int_x4, i64 %p_int_x4, i64 %p_int_x4, i64 %p_int_x4, i64 %p_int_x4, i64 %p_int_x4, i64 %p_int_x4, i64 %p_int_x4, i64 %p_int_x4, i64 %p_int_x4, i64 %p_int_x4, i4 %i_3_0_t)
  %p_int_x12_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_x1, i64 %tmp_50_1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i64 %p_int_x1, i4 %i_3_0_t)
  %p_int_vy_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_7_vy_read_2, i64 %p_int_1_vy_read_2, i64 %p_int_7_vy_read_2, i64 %p_int_7_vy_read_2, i64 %p_int_4_vy_read41, i64 %p_int_7_vy_read_2, i64 %p_int_7_vy_read_2, i64 %p_int_7_vy_read_2, i64 %p_int_7_vy_read_2, i64 %p_int_7_vy_read_2, i64 %p_int_7_vy_read_2, i64 %p_int_7_vy_read_2, i64 %p_int_7_vy_read_2, i64 %p_int_7_vy_read_2, i64 %p_int_7_vy_read_2, i64 %p_int_7_vy_read_2, i4 %i_3_0_t)
  %tmp_51_1 = sitofp i64 %p_int_vy_load_1_phi to double
  %tmp_52_1 = fmul double %tmp_51_1, 5.000000e-03
  %tmp_53_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_52_1)
  %p_int_y_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_y6, i64 %p_int_y9, i64 %p_int_y6, i64 %p_int_y6, i64 %p_int_y3, i64 %p_int_y6, i64 %p_int_y6, i64 %p_int_y6, i64 %p_int_y6, i64 %p_int_y6, i64 %p_int_y6, i64 %p_int_y6, i64 %p_int_y6, i64 %p_int_y6, i64 %p_int_y6, i64 %p_int_y6, i4 %i_3_0_t)
  %tmp_54_1 = add nsw i64 %tmp_53_1, %p_int_y_load_1_phi
  %p_int_y15_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %tmp_54_1, i64 %p_int_y6, i64 %tmp_54_1, i64 %tmp_54_1, i64 %p_int_y6, i64 %tmp_54_1, i64 %tmp_54_1, i64 %tmp_54_1, i64 %tmp_54_1, i64 %tmp_54_1, i64 %tmp_54_1, i64 %tmp_54_1, i64 %tmp_54_1, i64 %tmp_54_1, i64 %tmp_54_1, i64 %tmp_54_1, i4 %i_3_0_t)
  %p_int_y12_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_y3, i64 %p_int_y3, i64 %p_int_y3, i64 %p_int_y3, i64 %tmp_54_1, i64 %p_int_y3, i64 %p_int_y3, i64 %p_int_y3, i64 %p_int_y3, i64 %p_int_y3, i64 %p_int_y3, i64 %p_int_y3, i64 %p_int_y3, i64 %p_int_y3, i64 %p_int_y3, i64 %p_int_y3, i4 %i_3_0_t)
  %p_int_y9_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_y9, i64 %tmp_54_1, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i64 %p_int_y9, i4 %i_3_0_t)
  %p_int_vz_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_7_vz_read_2, i64 %p_int_1_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_4_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_7_vz_read_2, i64 %p_int_7_vz_read_2, i4 %i_3_0_t)
  %tmp_55_1 = sitofp i64 %p_int_vz_load_1_phi to double
  %tmp_56_1 = fmul double %tmp_55_1, 5.000000e-03
  %tmp_57_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_56_1)
  %p_int_z_load_1_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_z7, i64 %p_int_z1, i64 %p_int_z7, i64 %p_int_z7, i64 %p_int_z4, i64 %p_int_z7, i64 %p_int_z7, i64 %p_int_z7, i64 %p_int_z7, i64 %p_int_z7, i64 %p_int_z7, i64 %p_int_z7, i64 %p_int_z7, i64 %p_int_z7, i64 %p_int_z7, i64 %p_int_z7, i4 %i_3_0_t)
  %tmp_58_1 = add nsw i64 %tmp_57_1, %p_int_z_load_1_phi
  %p_int_z23_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %tmp_58_1, i64 %p_int_z7, i64 %tmp_58_1, i64 %tmp_58_1, i64 %p_int_z7, i64 %tmp_58_1, i64 %tmp_58_1, i64 %tmp_58_1, i64 %tmp_58_1, i64 %tmp_58_1, i64 %tmp_58_1, i64 %tmp_58_1, i64 %tmp_58_1, i64 %tmp_58_1, i64 %tmp_58_1, i64 %tmp_58_1, i4 %i_3_0_t)
  %p_int_z20_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_z4, i64 %p_int_z4, i64 %p_int_z4, i64 %p_int_z4, i64 %tmp_58_1, i64 %p_int_z4, i64 %p_int_z4, i64 %p_int_z4, i64 %p_int_z4, i64 %p_int_z4, i64 %p_int_z4, i64 %p_int_z4, i64 %p_int_z4, i64 %p_int_z4, i64 %p_int_z4, i64 %p_int_z4, i4 %i_3_0_t)
  %p_int_z17_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_z1, i64 %tmp_58_1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i64 %p_int_z1, i4 %i_3_0_t)
  %i_3_1_t = add i4 %i, 2
  %p_int_vx_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_8_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_2_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_5_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_8_vx_read_2, i64 %p_int_8_vx_read_2, i4 %i_3_1_t)
  %tmp_47_2 = sitofp i64 %p_int_vx_load_2_phi to double
  %tmp_48_2 = fmul double %tmp_47_2, 5.000000e-03
  %tmp_49_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_48_2)
  %p_int_x_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_x8, i64 %p_int_x8, i64 %p_int_x2, i64 %p_int_x8, i64 %p_int_x8, i64 %p_int_x5, i64 %p_int_x8, i64 %p_int_x8, i64 %p_int_x8, i64 %p_int_x8, i64 %p_int_x8, i64 %p_int_x8, i64 %p_int_x8, i64 %p_int_x8, i64 %p_int_x8, i64 %p_int_x8, i4 %i_3_1_t)
  %tmp_50_2 = add nsw i64 %tmp_49_2, %p_int_x_load_2_phi
  %p_int_x8_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %tmp_50_2, i64 %tmp_50_2, i64 %p_int_x8, i64 %tmp_50_2, i64 %tmp_50_2, i64 %p_int_x8, i64 %tmp_50_2, i64 %tmp_50_2, i64 %tmp_50_2, i64 %tmp_50_2, i64 %tmp_50_2, i64 %tmp_50_2, i64 %tmp_50_2, i64 %tmp_50_2, i64 %tmp_50_2, i64 %tmp_50_2, i4 %i_3_1_t)
  %p_int_x5_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_x5, i64 %p_int_x5, i64 %p_int_x5, i64 %p_int_x5, i64 %p_int_x5, i64 %tmp_50_2, i64 %p_int_x5, i64 %p_int_x5, i64 %p_int_x5, i64 %p_int_x5, i64 %p_int_x5, i64 %p_int_x5, i64 %p_int_x5, i64 %p_int_x5, i64 %p_int_x5, i64 %p_int_x5, i4 %i_3_1_t)
  %p_int_x2_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_x2, i64 %p_int_x2, i64 %tmp_50_2, i64 %p_int_x2, i64 %p_int_x2, i64 %p_int_x2, i64 %p_int_x2, i64 %p_int_x2, i64 %p_int_x2, i64 %p_int_x2, i64 %p_int_x2, i64 %p_int_x2, i64 %p_int_x2, i64 %p_int_x2, i64 %p_int_x2, i64 %p_int_x2, i4 %i_3_1_t)
  %p_int_vy_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_8_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_2_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_5_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_8_vy_read_2, i64 %p_int_8_vy_read_2, i4 %i_3_1_t)
  %tmp_51_2 = sitofp i64 %p_int_vy_load_2_phi to double
  %tmp_52_2 = fmul double %tmp_51_2, 5.000000e-03
  %tmp_53_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_52_2)
  %p_int_y_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_y7, i64 %p_int_y7, i64 %p_int_y1, i64 %p_int_y7, i64 %p_int_y7, i64 %p_int_y4, i64 %p_int_y7, i64 %p_int_y7, i64 %p_int_y7, i64 %p_int_y7, i64 %p_int_y7, i64 %p_int_y7, i64 %p_int_y7, i64 %p_int_y7, i64 %p_int_y7, i64 %p_int_y7, i4 %i_3_1_t)
  %tmp_54_2 = add nsw i64 %tmp_53_2, %p_int_y_load_2_phi
  %p_int_y16_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %tmp_54_2, i64 %tmp_54_2, i64 %p_int_y7, i64 %tmp_54_2, i64 %tmp_54_2, i64 %p_int_y7, i64 %tmp_54_2, i64 %tmp_54_2, i64 %tmp_54_2, i64 %tmp_54_2, i64 %tmp_54_2, i64 %tmp_54_2, i64 %tmp_54_2, i64 %tmp_54_2, i64 %tmp_54_2, i64 %tmp_54_2, i4 %i_3_1_t)
  %p_int_y13_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_y4, i64 %p_int_y4, i64 %p_int_y4, i64 %p_int_y4, i64 %p_int_y4, i64 %tmp_54_2, i64 %p_int_y4, i64 %p_int_y4, i64 %p_int_y4, i64 %p_int_y4, i64 %p_int_y4, i64 %p_int_y4, i64 %p_int_y4, i64 %p_int_y4, i64 %p_int_y4, i64 %p_int_y4, i4 %i_3_1_t)
  %p_int_y10_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_y1, i64 %p_int_y1, i64 %tmp_54_2, i64 %p_int_y1, i64 %p_int_y1, i64 %p_int_y1, i64 %p_int_y1, i64 %p_int_y1, i64 %p_int_y1, i64 %p_int_y1, i64 %p_int_y1, i64 %p_int_y1, i64 %p_int_y1, i64 %p_int_y1, i64 %p_int_y1, i64 %p_int_y1, i4 %i_3_1_t)
  %p_int_vz_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_8_vz_read_2, i64 %p_int_8_vz_read_2, i64 %p_int_2_vz_read_2, i64 %p_int_8_vz_read_2, i64 %p_int_8_vz_read_2, i64 %p_int_5_vz_read51, i64 %p_int_8_vz_read_2, i64 %p_int_8_vz_read_2, i64 %p_int_8_vz_read_2, i64 %p_int_8_vz_read_2, i64 %p_int_8_vz_read_2, i64 %p_int_8_vz_read_2, i64 %p_int_8_vz_read_2, i64 %p_int_8_vz_read_2, i64 %p_int_8_vz_read_2, i64 %p_int_8_vz_read_2, i4 %i_3_1_t)
  %tmp_55_2 = sitofp i64 %p_int_vz_load_2_phi to double
  %tmp_56_2 = fmul double %tmp_55_2, 5.000000e-03
  %tmp_57_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_56_2)
  %p_int_z_load_2_phi = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_z8, i64 %p_int_z8, i64 %p_int_z2, i64 %p_int_z8, i64 %p_int_z8, i64 %p_int_z5, i64 %p_int_z8, i64 %p_int_z8, i64 %p_int_z8, i64 %p_int_z8, i64 %p_int_z8, i64 %p_int_z8, i64 %p_int_z8, i64 %p_int_z8, i64 %p_int_z8, i64 %p_int_z8, i4 %i_3_1_t)
  %tmp_58_2 = add nsw i64 %tmp_57_2, %p_int_z_load_2_phi
  %p_int_z24_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %tmp_58_2, i64 %tmp_58_2, i64 %p_int_z8, i64 %tmp_58_2, i64 %tmp_58_2, i64 %p_int_z8, i64 %tmp_58_2, i64 %tmp_58_2, i64 %tmp_58_2, i64 %tmp_58_2, i64 %tmp_58_2, i64 %tmp_58_2, i64 %tmp_58_2, i64 %tmp_58_2, i64 %tmp_58_2, i64 %tmp_58_2, i4 %i_3_1_t)
  %p_int_z2126_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_z5, i64 %p_int_z5, i64 %p_int_z5, i64 %p_int_z5, i64 %p_int_z5, i64 %tmp_58_2, i64 %p_int_z5, i64 %p_int_z5, i64 %p_int_z5, i64 %p_int_z5, i64 %p_int_z5, i64 %p_int_z5, i64 %p_int_z5, i64 %p_int_z5, i64 %p_int_z5, i64 %p_int_z5, i4 %i_3_1_t)
  %p_int_z18_1 = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_z2, i64 %p_int_z2, i64 %tmp_58_2, i64 %p_int_z2, i64 %p_int_z2, i64 %p_int_z2, i64 %p_int_z2, i64 %p_int_z2, i64 %p_int_z2, i64 %p_int_z2, i64 %p_int_z2, i64 %p_int_z2, i64 %p_int_z2, i64 %p_int_z2, i64 %p_int_z2, i64 %p_int_z2, i4 %i_3_1_t)
  %i_3_2 = add i4 %i, 3
  br label %1

; <label>:2                                       ; preds = %1
  %mrv = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } undef, i64 %p_int_x, 0
  %mrv_1 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv, i64 %p_int_x1, 1
  %mrv_2 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_1, i64 %p_int_x2, 2
  %mrv_3 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_2, i64 %p_int_x3, 3
  %mrv_4 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_3, i64 %p_int_x4, 4
  %mrv_5 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_4, i64 %p_int_x5, 5
  %mrv_6 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_5, i64 %p_int_x6, 6
  %mrv_7 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_6, i64 %p_int_x7, 7
  %mrv_8 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_7, i64 %p_int_x8, 8
  %mrv_9 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_8, i64 %p_int_y, 9
  %mrv_s = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_9, i64 %p_int_y9, 10
  %mrv_10 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_s, i64 %p_int_y1, 11
  %mrv_11 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_10, i64 %p_int_y2, 12
  %mrv_12 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_11, i64 %p_int_y3, 13
  %mrv_13 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_12, i64 %p_int_y4, 14
  %mrv_14 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_13, i64 %p_int_y5, 15
  %mrv_15 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_14, i64 %p_int_y6, 16
  %mrv_16 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_15, i64 %p_int_y7, 17
  %mrv_17 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_16, i64 %p_int_z, 18
  %mrv_18 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_17, i64 %p_int_z1, 19
  %mrv_19 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_18, i64 %p_int_z2, 20
  %mrv_20 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_19, i64 %p_int_z3, 21
  %mrv_21 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_20, i64 %p_int_z4, 22
  %mrv_22 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_21, i64 %p_int_z5, 23
  %mrv_23 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_22, i64 %p_int_z6, 24
  %mrv_24 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_23, i64 %p_int_z7, 25
  %mrv_25 = insertvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_24, i64 %p_int_z8, 26
  ret { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %mrv_25
}

define void @astroSim(double* %result_x, double* %result_y, double* %result_z, double* %result_vx, double* %result_vy, double* %result_vz, double* %result_ax, double* %result_ay, double* %result_az, double* %result_m) {
  call void (...)* @_ssdm_op_SpecBitsMap(double* %result_x), !map !992
  call void (...)* @_ssdm_op_SpecBitsMap(double* %result_y), !map !996
  call void (...)* @_ssdm_op_SpecBitsMap(double* %result_z), !map !1000
  call void (...)* @_ssdm_op_SpecBitsMap(double* %result_vx), !map !1004
  call void (...)* @_ssdm_op_SpecBitsMap(double* %result_vy), !map !1008
  call void (...)* @_ssdm_op_SpecBitsMap(double* %result_vz), !map !1012
  call void (...)* @_ssdm_op_SpecBitsMap(double* %result_ax), !map !1016
  call void (...)* @_ssdm_op_SpecBitsMap(double* %result_ay), !map !1020
  call void (...)* @_ssdm_op_SpecBitsMap(double* %result_az), !map !1024
  call void (...)* @_ssdm_op_SpecBitsMap(double* %result_m), !map !1028
  call void (...)* @_ssdm_op_SpecTopModule([9 x i8]* @astroSim_str) nounwind
  call void (...)* @_ssdm_op_SpecInterface(double* %result_x, double* %result_y, double* %result_z, double* %result_vx, double* %result_vy, double* %result_vz, double* %result_ax, double* %result_ay, double* %result_az, double* %result_m, [6 x i8]* @p_str1, i32 0, i32 0, [1 x i8]* @p_str, i32 0, i32 9, [1 x i8]* @p_str, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 16, i32 16, i32 16, i32 16, [1 x i8]* @p_str, [1 x i8]* @p_str) nounwind
  call void (...)* @_ssdm_op_SpecInterface(i32 0, [10 x i8]* @p_str2, i32 0, i32 0, [1 x i8]* @p_str, i32 0, i32 0, [9 x i8]* @p_str3, [1 x i8]* @p_str, [1 x i8]* @p_str, i32 0, i32 0, i32 0, i32 0, [1 x i8]* @p_str, [1 x i8]* @p_str) nounwind
  %p_x_6_load = load double* @p_x_6, align 16
  %p_y_6_load = load double* @p_y_6, align 8
  %p_z_6_load = load double* @p_z_6, align 16
  %p_vx_6_load = load double* @p_vx_6, align 8
  %p_vy_6_load = load double* @p_vy_6, align 16
  %p_vz_6_load = load double* @p_vz_6, align 8
  %p_x_7_load = load double* @p_x_7, align 16
  %p_y_7_load = load double* @p_y_7, align 8
  %p_z_7_load = load double* @p_z_7, align 16
  %p_vx_7_load = load double* @p_vx_7, align 8
  %p_vy_7_load = load double* @p_vy_7, align 16
  %p_vz_7_load = load double* @p_vz_7, align 8
  %p_x_8_load = load double* @p_x_8, align 16
  %p_y_8_load = load double* @p_y_8, align 8
  %p_z_8_load = load double* @p_z_8, align 16
  %p_vx_8_load = load double* @p_vx_8, align 8
  %p_vy_8_load = load double* @p_vy_8, align 16
  %p_vz_8_load = load double* @p_vz_8, align 8
  %p_vz_2_load_1 = load double* @p_vz_2, align 8
  %p_vz_5_load_1 = load double* @p_vz_5, align 8
  %p_vy_2_load_1 = load double* @p_vy_2, align 16
  %p_vy_5_load_1 = load double* @p_vy_5, align 16
  %p_vx_2_load_1 = load double* @p_vx_2, align 8
  %p_vx_5_load_1 = load double* @p_vx_5, align 8
  %p_z_2_load_1 = load double* @p_z_2, align 16
  %p_z_5_load_1 = load double* @p_z_5, align 16
  %p_y_2_load_1 = load double* @p_y_2, align 8
  %p_y_5_load_1 = load double* @p_y_5, align 8
  %p_x_2_load_1 = load double* @p_x_2, align 16
  %p_x_5_load_1 = load double* @p_x_5, align 16
  %p_vz_1_load_1 = load double* @p_vz_1, align 8
  %p_vz_4_load_1 = load double* @p_vz_4, align 8
  %p_vy_1_load_1 = load double* @p_vy_1, align 16
  %p_vy_4_load_1 = load double* @p_vy_4, align 16
  %p_vx_1_load_1 = load double* @p_vx_1, align 8
  %p_vx_4_load_1 = load double* @p_vx_4, align 8
  %p_z_1_load_1 = load double* @p_z_1, align 16
  %p_z_4_load_1 = load double* @p_z_4, align 16
  %p_y_1_load_1 = load double* @p_y_1, align 8
  %p_y_4_load_1 = load double* @p_y_4, align 8
  %p_x_1_load_1 = load double* @p_x_1, align 16
  %p_x_4_load_1 = load double* @p_x_4, align 16
  %p_vz_0_load_1 = load double* @p_vz_0, align 8
  %p_vz_3_load_1 = load double* @p_vz_3, align 8
  %p_vy_0_load = load double* @p_vy_0, align 16
  %p_vy_3_load = load double* @p_vy_3, align 16
  %p_vx_0_load = load double* @p_vx_0, align 8
  %p_vx_3_load = load double* @p_vx_3, align 8
  %p_z_0_load = load double* @p_z_0, align 16
  %p_z_3_load = load double* @p_z_3, align 16
  %p_y_0_load = load double* @p_y_0, align 8
  %p_y_3_load = load double* @p_y_3, align 8
  %p_x_0_load = load double* @p_x_0, align 16
  %p_x_3_load = load double* @p_x_3, align 16
  br label %1

; <label>:1                                       ; preds = %_ifconv, %0
  %p_int_vz_8 = phi i64 [ undef, %0 ], [ %p_int_8_vz_1, %_ifconv ]
  %p_int_vz_7 = phi i64 [ undef, %0 ], [ %p_int_7_vz_1, %_ifconv ]
  %p_int_vz_6 = phi i64 [ undef, %0 ], [ %p_int_6_vz_1, %_ifconv ]
  %p_int_vz_5 = phi i64 [ undef, %0 ], [ %p_int_8_vz_3, %_ifconv ]
  %p_int_vz_4 = phi i64 [ undef, %0 ], [ %p_int_7_vz_3, %_ifconv ]
  %p_int_vz_3 = phi i64 [ undef, %0 ], [ %p_int_6_vz_3, %_ifconv ]
  %p_int_8_vz_4 = phi i64 [ undef, %0 ], [ %p_int_8_vz_5, %_ifconv ]
  %p_int_7_vz_4 = phi i64 [ undef, %0 ], [ %p_int_7_vz_5, %_ifconv ]
  %p_int_6_vz_4 = phi i64 [ undef, %0 ], [ %p_int_6_vz_5, %_ifconv ]
  %p_int_vy_8 = phi i64 [ undef, %0 ], [ %p_int_8_vy_1, %_ifconv ]
  %p_int_vy_7 = phi i64 [ undef, %0 ], [ %p_int_7_vy_1, %_ifconv ]
  %p_int_vy_6 = phi i64 [ undef, %0 ], [ %p_int_6_vy_1, %_ifconv ]
  %p_int_vy_5 = phi i64 [ undef, %0 ], [ %p_int_8_vy_3, %_ifconv ]
  %p_int_vy_4 = phi i64 [ undef, %0 ], [ %p_int_7_vy_3, %_ifconv ]
  %p_int_vy_3 = phi i64 [ undef, %0 ], [ %p_int_6_vy_3, %_ifconv ]
  %p_int_8_vy_4 = phi i64 [ undef, %0 ], [ %p_int_8_vy_5, %_ifconv ]
  %p_int_7_vy_4 = phi i64 [ undef, %0 ], [ %p_int_7_vy_5, %_ifconv ]
  %p_int_6_vy_4 = phi i64 [ undef, %0 ], [ %p_int_6_vy_5, %_ifconv ]
  %p_int_vx_8 = phi i64 [ undef, %0 ], [ %p_int_8_vx_1, %_ifconv ]
  %p_int_vx_7 = phi i64 [ undef, %0 ], [ %p_int_7_vx_1, %_ifconv ]
  %p_int_vx_6 = phi i64 [ undef, %0 ], [ %p_int_6_vx_1, %_ifconv ]
  %p_int_vx_5 = phi i64 [ undef, %0 ], [ %p_int_8_vx_3, %_ifconv ]
  %p_int_vx_4 = phi i64 [ undef, %0 ], [ %p_int_7_vx_3, %_ifconv ]
  %p_int_vx_3 = phi i64 [ undef, %0 ], [ %p_int_6_vx_3, %_ifconv ]
  %p_int_8_vx_4 = phi i64 [ undef, %0 ], [ %p_int_8_vx_5, %_ifconv ]
  %p_int_7_vx_4 = phi i64 [ undef, %0 ], [ %p_int_7_vx_5, %_ifconv ]
  %p_int_6_vx_4 = phi i64 [ undef, %0 ], [ %p_int_6_vx_5, %_ifconv ]
  %p_int_z_8 = phi i64 [ undef, %0 ], [ %p_int_8_z_11, %_ifconv ]
  %p_int_z_7 = phi i64 [ undef, %0 ], [ %p_int_7_z_11, %_ifconv ]
  %p_int_z_6 = phi i64 [ undef, %0 ], [ %p_int_6_z_11, %_ifconv ]
  %p_int_z_5 = phi i64 [ undef, %0 ], [ %p_int_8_z_13, %_ifconv ]
  %p_int_z_4 = phi i64 [ undef, %0 ], [ %p_int_7_z_13, %_ifconv ]
  %p_int_z_3 = phi i64 [ undef, %0 ], [ %p_int_6_z_13, %_ifconv ]
  %p_int_8_z_26 = phi i64 [ undef, %0 ], [ %p_int_8_z_27, %_ifconv ]
  %p_int_7_z_26 = phi i64 [ undef, %0 ], [ %p_int_7_z_27, %_ifconv ]
  %p_int_6_z_26 = phi i64 [ undef, %0 ], [ %p_int_6_z_27, %_ifconv ]
  %p_int_y_8 = phi i64 [ undef, %0 ], [ %p_int_8_y_11, %_ifconv ]
  %p_int_y_7 = phi i64 [ undef, %0 ], [ %p_int_7_y_11, %_ifconv ]
  %p_int_y_6 = phi i64 [ undef, %0 ], [ %p_int_6_y_10, %_ifconv ]
  %p_int_y_5 = phi i64 [ undef, %0 ], [ %p_int_8_y_13, %_ifconv ]
  %p_int_y_4 = phi i64 [ undef, %0 ], [ %p_int_7_y_13, %_ifconv ]
  %p_int_y_3 = phi i64 [ undef, %0 ], [ %p_int_6_y_12, %_ifconv ]
  %p_int_8_y_26 = phi i64 [ undef, %0 ], [ %p_int_8_y_27, %_ifconv ]
  %p_int_7_y_26 = phi i64 [ undef, %0 ], [ %p_int_7_y_27, %_ifconv ]
  %p_int_6_y_26 = phi i64 [ undef, %0 ], [ %p_int_6_y_27, %_ifconv ]
  %p_int_x_8 = phi i64 [ undef, %0 ], [ %p_int_8_x_11, %_ifconv ]
  %p_int_x_7 = phi i64 [ undef, %0 ], [ %p_int_7_x_11, %_ifconv ]
  %p_int_x_6 = phi i64 [ undef, %0 ], [ %p_int_6_x_10, %_ifconv ]
  %p_int_x_5 = phi i64 [ undef, %0 ], [ %p_int_8_x_13, %_ifconv ]
  %p_int_x_4 = phi i64 [ undef, %0 ], [ %p_int_7_x_13, %_ifconv ]
  %p_int_x_3 = phi i64 [ undef, %0 ], [ %p_int_6_x_12, %_ifconv ]
  %p_int_8_x_26 = phi i64 [ undef, %0 ], [ %p_int_8_x_27, %_ifconv ]
  %p_int_7_x_26 = phi i64 [ undef, %0 ], [ %p_int_7_x_27, %_ifconv ]
  %p_int_6_x_26 = phi i64 [ undef, %0 ], [ %p_int_6_x_27, %_ifconv ]
  %i_0_i = phi i4 [ 0, %0 ], [ %i_2, %_ifconv ]
  %empty = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp = icmp eq i4 %i_0_i, -7
  br i1 %tmp, label %to_int.exit.0.preheader, label %_ifconv

to_int.exit.0.preheader:                          ; preds = %1
  br label %to_int.exit.0

_ifconv:                                          ; preds = %1
  %sel_tmp = icmp eq i4 %i_0_i, 3
  %sel_tmp1 = select i1 %sel_tmp, double %p_x_3_load, double %p_x_6_load
  %sel_tmp2 = icmp eq i4 %i_0_i, 0
  %p_x_load_0_phi = select i1 %sel_tmp2, double %p_x_0_load, double %sel_tmp1
  %tmp_s = fmul double %p_x_load_0_phi, 1.000000e+16
  %p_int_0_x_21 = call fastcc i64 @__hls_fptosi_double_(double %tmp_s) nounwind
  %p_int_6_x_3 = select i1 %sel_tmp, i64 %p_int_x_6, i64 %p_int_0_x_21
  %p_int_6_x_10 = select i1 %sel_tmp2, i64 %p_int_x_6, i64 %p_int_6_x_3
  %p_int_6_x_11 = select i1 %sel_tmp, i64 %p_int_0_x_21, i64 %p_int_x_3
  %p_int_6_x_12 = select i1 %sel_tmp2, i64 %p_int_x_3, i64 %p_int_6_x_11
  %p_int_6_x_27 = select i1 %sel_tmp2, i64 %p_int_0_x_21, i64 %p_int_6_x_26
  %tmp_1 = select i1 %sel_tmp2, double %p_y_0_load, double %p_y_6_load
  %p_y_load_0_phi = select i1 %sel_tmp, double %p_y_3_load, double %tmp_1
  %tmp_27 = fmul double %p_y_load_0_phi, 1.000000e+16
  %p_int_0_y_21 = call fastcc i64 @__hls_fptosi_double_(double %tmp_27) nounwind
  %p_int_6_y_7 = select i1 %sel_tmp, i64 %p_int_y_6, i64 %p_int_0_y_21
  %p_int_6_y_10 = select i1 %sel_tmp2, i64 %p_int_y_6, i64 %p_int_6_y_7
  %p_int_6_y_11 = select i1 %sel_tmp, i64 %p_int_0_y_21, i64 %p_int_y_3
  %p_int_6_y_12 = select i1 %sel_tmp2, i64 %p_int_y_3, i64 %p_int_6_y_11
  %p_int_6_y_27 = select i1 %sel_tmp2, i64 %p_int_0_y_21, i64 %p_int_6_y_26
  %tmp_2 = select i1 %sel_tmp2, double %p_z_0_load, double %p_z_6_load
  %p_z_load_0_phi = select i1 %sel_tmp, double %p_z_3_load, double %tmp_2
  %tmp_38 = fmul double %p_z_load_0_phi, 1.000000e+16
  %p_int_0_z_21 = call fastcc i64 @__hls_fptosi_double_(double %tmp_38) nounwind
  %p_int_6_z_10 = select i1 %sel_tmp, i64 %p_int_z_6, i64 %p_int_0_z_21
  %p_int_6_z_11 = select i1 %sel_tmp2, i64 %p_int_z_6, i64 %p_int_6_z_10
  %p_int_6_z_12 = select i1 %sel_tmp, i64 %p_int_0_z_21, i64 %p_int_z_3
  %p_int_6_z_13 = select i1 %sel_tmp2, i64 %p_int_z_3, i64 %p_int_6_z_12
  %p_int_6_z_27 = select i1 %sel_tmp2, i64 %p_int_0_z_21, i64 %p_int_6_z_26
  %tmp_3 = select i1 %sel_tmp2, double %p_vx_0_load, double %p_vx_6_load
  %p_vx_load_0_phi = select i1 %sel_tmp, double %p_vx_3_load, double %tmp_3
  %tmp_40 = fmul double %p_vx_load_0_phi, 1.000000e+16
  %p_int_0_vx = call fastcc i64 @__hls_fptosi_double_(double %tmp_40) nounwind
  %p_int_6_vx = select i1 %sel_tmp, i64 %p_int_vx_6, i64 %p_int_0_vx
  %p_int_6_vx_1 = select i1 %sel_tmp2, i64 %p_int_vx_6, i64 %p_int_6_vx
  %p_int_6_vx_2 = select i1 %sel_tmp, i64 %p_int_0_vx, i64 %p_int_vx_3
  %p_int_6_vx_3 = select i1 %sel_tmp2, i64 %p_int_vx_3, i64 %p_int_6_vx_2
  %p_int_6_vx_5 = select i1 %sel_tmp2, i64 %p_int_0_vx, i64 %p_int_6_vx_4
  %tmp_4 = select i1 %sel_tmp2, double %p_vy_0_load, double %p_vy_6_load
  %p_vy_load_0_phi = select i1 %sel_tmp, double %p_vy_3_load, double %tmp_4
  %tmp_41 = fmul double %p_vy_load_0_phi, 1.000000e+16
  %p_int_0_vy = call fastcc i64 @__hls_fptosi_double_(double %tmp_41) nounwind
  %p_int_6_vy = select i1 %sel_tmp, i64 %p_int_vy_6, i64 %p_int_0_vy
  %p_int_6_vy_1 = select i1 %sel_tmp2, i64 %p_int_vy_6, i64 %p_int_6_vy
  %p_int_6_vy_2 = select i1 %sel_tmp, i64 %p_int_0_vy, i64 %p_int_vy_3
  %p_int_6_vy_3 = select i1 %sel_tmp2, i64 %p_int_vy_3, i64 %p_int_6_vy_2
  %p_int_6_vy_5 = select i1 %sel_tmp2, i64 %p_int_0_vy, i64 %p_int_6_vy_4
  %tmp_5 = select i1 %sel_tmp2, double %p_vz_0_load_1, double %p_vz_6_load
  %p_vz_load_0_phi = select i1 %sel_tmp, double %p_vz_3_load_1, double %tmp_5
  %tmp_42 = fmul double %p_vz_load_0_phi, 1.000000e+16
  %p_int_0_vz = call fastcc i64 @__hls_fptosi_double_(double %tmp_42) nounwind
  %p_int_6_vz = select i1 %sel_tmp, i64 %p_int_vz_6, i64 %p_int_0_vz
  %p_int_6_vz_1 = select i1 %sel_tmp2, i64 %p_int_vz_6, i64 %p_int_6_vz
  %p_int_6_vz_2 = select i1 %sel_tmp, i64 %p_int_0_vz, i64 %p_int_vz_3
  %p_int_6_vz_3 = select i1 %sel_tmp2, i64 %p_int_vz_3, i64 %p_int_6_vz_2
  %p_int_6_vz_5 = select i1 %sel_tmp2, i64 %p_int_0_vz, i64 %p_int_6_vz_4
  %tmp_6 = select i1 %sel_tmp2, double %p_x_1_load_1, double %p_x_7_load
  %p_x_load_1_phi = select i1 %sel_tmp, double %p_x_4_load_1, double %tmp_6
  %tmp_59_1 = fmul double %p_x_load_1_phi, 1.000000e+16
  %p_int_1_x_21 = call fastcc i64 @__hls_fptosi_double_(double %tmp_59_1) nounwind
  %p_int_7_x_10 = select i1 %sel_tmp, i64 %p_int_x_7, i64 %p_int_1_x_21
  %p_int_7_x_11 = select i1 %sel_tmp2, i64 %p_int_x_7, i64 %p_int_7_x_10
  %p_int_7_x_12 = select i1 %sel_tmp, i64 %p_int_1_x_21, i64 %p_int_x_4
  %p_int_7_x_13 = select i1 %sel_tmp2, i64 %p_int_x_4, i64 %p_int_7_x_12
  %p_int_7_x_27 = select i1 %sel_tmp2, i64 %p_int_1_x_21, i64 %p_int_7_x_26
  %tmp_7 = select i1 %sel_tmp2, double %p_y_1_load_1, double %p_y_7_load
  %p_y_load_1_phi = select i1 %sel_tmp, double %p_y_4_load_1, double %tmp_7
  %tmp_61_1 = fmul double %p_y_load_1_phi, 1.000000e+16
  %p_int_1_y_21 = call fastcc i64 @__hls_fptosi_double_(double %tmp_61_1) nounwind
  %p_int_7_y_10 = select i1 %sel_tmp, i64 %p_int_y_7, i64 %p_int_1_y_21
  %p_int_7_y_11 = select i1 %sel_tmp2, i64 %p_int_y_7, i64 %p_int_7_y_10
  %p_int_7_y_12 = select i1 %sel_tmp, i64 %p_int_1_y_21, i64 %p_int_y_4
  %p_int_7_y_13 = select i1 %sel_tmp2, i64 %p_int_y_4, i64 %p_int_7_y_12
  %p_int_7_y_27 = select i1 %sel_tmp2, i64 %p_int_1_y_21, i64 %p_int_7_y_26
  %tmp_8 = select i1 %sel_tmp2, double %p_z_1_load_1, double %p_z_7_load
  %p_z_load_1_phi = select i1 %sel_tmp, double %p_z_4_load_1, double %tmp_8
  %tmp_63_1 = fmul double %p_z_load_1_phi, 1.000000e+16
  %p_int_1_z_21 = call fastcc i64 @__hls_fptosi_double_(double %tmp_63_1) nounwind
  %p_int_7_z_10 = select i1 %sel_tmp, i64 %p_int_z_7, i64 %p_int_1_z_21
  %p_int_7_z_11 = select i1 %sel_tmp2, i64 %p_int_z_7, i64 %p_int_7_z_10
  %p_int_7_z_12 = select i1 %sel_tmp, i64 %p_int_1_z_21, i64 %p_int_z_4
  %p_int_7_z_13 = select i1 %sel_tmp2, i64 %p_int_z_4, i64 %p_int_7_z_12
  %p_int_7_z_27 = select i1 %sel_tmp2, i64 %p_int_1_z_21, i64 %p_int_7_z_26
  %tmp_9 = select i1 %sel_tmp2, double %p_vx_1_load_1, double %p_vx_7_load
  %p_vx_load_1_phi = select i1 %sel_tmp, double %p_vx_4_load_1, double %tmp_9
  %tmp_65_1 = fmul double %p_vx_load_1_phi, 1.000000e+16
  %p_int_1_vx = call fastcc i64 @__hls_fptosi_double_(double %tmp_65_1) nounwind
  %p_int_7_vx = select i1 %sel_tmp, i64 %p_int_vx_7, i64 %p_int_1_vx
  %p_int_7_vx_1 = select i1 %sel_tmp2, i64 %p_int_vx_7, i64 %p_int_7_vx
  %p_int_7_vx_2 = select i1 %sel_tmp, i64 %p_int_1_vx, i64 %p_int_vx_4
  %p_int_7_vx_3 = select i1 %sel_tmp2, i64 %p_int_vx_4, i64 %p_int_7_vx_2
  %p_int_7_vx_5 = select i1 %sel_tmp2, i64 %p_int_1_vx, i64 %p_int_7_vx_4
  %tmp_10 = select i1 %sel_tmp2, double %p_vy_1_load_1, double %p_vy_7_load
  %p_vy_load_1_phi = select i1 %sel_tmp, double %p_vy_4_load_1, double %tmp_10
  %tmp_67_1 = fmul double %p_vy_load_1_phi, 1.000000e+16
  %p_int_1_vy = call fastcc i64 @__hls_fptosi_double_(double %tmp_67_1) nounwind
  %p_int_7_vy = select i1 %sel_tmp, i64 %p_int_vy_7, i64 %p_int_1_vy
  %p_int_7_vy_1 = select i1 %sel_tmp2, i64 %p_int_vy_7, i64 %p_int_7_vy
  %p_int_7_vy_2 = select i1 %sel_tmp, i64 %p_int_1_vy, i64 %p_int_vy_4
  %p_int_7_vy_3 = select i1 %sel_tmp2, i64 %p_int_vy_4, i64 %p_int_7_vy_2
  %p_int_7_vy_5 = select i1 %sel_tmp2, i64 %p_int_1_vy, i64 %p_int_7_vy_4
  %tmp_11 = select i1 %sel_tmp2, double %p_vz_1_load_1, double %p_vz_7_load
  %p_vz_load_1_phi = select i1 %sel_tmp, double %p_vz_4_load_1, double %tmp_11
  %tmp_69_1 = fmul double %p_vz_load_1_phi, 1.000000e+16
  %p_int_1_vz = call fastcc i64 @__hls_fptosi_double_(double %tmp_69_1) nounwind
  %p_int_7_vz = select i1 %sel_tmp, i64 %p_int_vz_7, i64 %p_int_1_vz
  %p_int_7_vz_1 = select i1 %sel_tmp2, i64 %p_int_vz_7, i64 %p_int_7_vz
  %p_int_7_vz_2 = select i1 %sel_tmp, i64 %p_int_1_vz, i64 %p_int_vz_4
  %p_int_7_vz_3 = select i1 %sel_tmp2, i64 %p_int_vz_4, i64 %p_int_7_vz_2
  %p_int_7_vz_5 = select i1 %sel_tmp2, i64 %p_int_1_vz, i64 %p_int_7_vz_4
  %tmp_12 = select i1 %sel_tmp2, double %p_x_2_load_1, double %p_x_8_load
  %p_x_load_2_phi = select i1 %sel_tmp, double %p_x_5_load_1, double %tmp_12
  %tmp_59_2 = fmul double %p_x_load_2_phi, 1.000000e+16
  %p_int_2_x_21 = call fastcc i64 @__hls_fptosi_double_(double %tmp_59_2) nounwind
  %p_int_8_x_10 = select i1 %sel_tmp, i64 %p_int_x_8, i64 %p_int_2_x_21
  %p_int_8_x_11 = select i1 %sel_tmp2, i64 %p_int_x_8, i64 %p_int_8_x_10
  %p_int_8_x_12 = select i1 %sel_tmp, i64 %p_int_2_x_21, i64 %p_int_x_5
  %p_int_8_x_13 = select i1 %sel_tmp2, i64 %p_int_x_5, i64 %p_int_8_x_12
  %p_int_8_x_27 = select i1 %sel_tmp2, i64 %p_int_2_x_21, i64 %p_int_8_x_26
  %tmp_13 = select i1 %sel_tmp2, double %p_y_2_load_1, double %p_y_8_load
  %p_y_load_2_phi = select i1 %sel_tmp, double %p_y_5_load_1, double %tmp_13
  %tmp_61_2 = fmul double %p_y_load_2_phi, 1.000000e+16
  %p_int_2_y_21 = call fastcc i64 @__hls_fptosi_double_(double %tmp_61_2) nounwind
  %p_int_8_y_10 = select i1 %sel_tmp, i64 %p_int_y_8, i64 %p_int_2_y_21
  %p_int_8_y_11 = select i1 %sel_tmp2, i64 %p_int_y_8, i64 %p_int_8_y_10
  %p_int_8_y_12 = select i1 %sel_tmp, i64 %p_int_2_y_21, i64 %p_int_y_5
  %p_int_8_y_13 = select i1 %sel_tmp2, i64 %p_int_y_5, i64 %p_int_8_y_12
  %p_int_8_y_27 = select i1 %sel_tmp2, i64 %p_int_2_y_21, i64 %p_int_8_y_26
  %tmp_14 = select i1 %sel_tmp2, double %p_z_2_load_1, double %p_z_8_load
  %p_z_load_2_phi = select i1 %sel_tmp, double %p_z_5_load_1, double %tmp_14
  %tmp_63_2 = fmul double %p_z_load_2_phi, 1.000000e+16
  %p_int_2_z_21 = call fastcc i64 @__hls_fptosi_double_(double %tmp_63_2) nounwind
  %p_int_8_z_10 = select i1 %sel_tmp, i64 %p_int_z_8, i64 %p_int_2_z_21
  %p_int_8_z_11 = select i1 %sel_tmp2, i64 %p_int_z_8, i64 %p_int_8_z_10
  %p_int_8_z_12 = select i1 %sel_tmp, i64 %p_int_2_z_21, i64 %p_int_z_5
  %p_int_8_z_13 = select i1 %sel_tmp2, i64 %p_int_z_5, i64 %p_int_8_z_12
  %p_int_8_z_27 = select i1 %sel_tmp2, i64 %p_int_2_z_21, i64 %p_int_8_z_26
  %tmp_15 = select i1 %sel_tmp2, double %p_vx_2_load_1, double %p_vx_8_load
  %p_vx_load_2_phi = select i1 %sel_tmp, double %p_vx_5_load_1, double %tmp_15
  %tmp_65_2 = fmul double %p_vx_load_2_phi, 1.000000e+16
  %p_int_2_vx = call fastcc i64 @__hls_fptosi_double_(double %tmp_65_2) nounwind
  %p_int_8_vx = select i1 %sel_tmp, i64 %p_int_vx_8, i64 %p_int_2_vx
  %p_int_8_vx_1 = select i1 %sel_tmp2, i64 %p_int_vx_8, i64 %p_int_8_vx
  %p_int_8_vx_2 = select i1 %sel_tmp, i64 %p_int_2_vx, i64 %p_int_vx_5
  %p_int_8_vx_3 = select i1 %sel_tmp2, i64 %p_int_vx_5, i64 %p_int_8_vx_2
  %p_int_8_vx_5 = select i1 %sel_tmp2, i64 %p_int_2_vx, i64 %p_int_8_vx_4
  %tmp_16 = select i1 %sel_tmp2, double %p_vy_2_load_1, double %p_vy_8_load
  %p_vy_load_2_phi = select i1 %sel_tmp, double %p_vy_5_load_1, double %tmp_16
  %tmp_67_2 = fmul double %p_vy_load_2_phi, 1.000000e+16
  %p_int_2_vy = call fastcc i64 @__hls_fptosi_double_(double %tmp_67_2) nounwind
  %p_int_8_vy = select i1 %sel_tmp, i64 %p_int_vy_8, i64 %p_int_2_vy
  %p_int_8_vy_1 = select i1 %sel_tmp2, i64 %p_int_vy_8, i64 %p_int_8_vy
  %p_int_8_vy_2 = select i1 %sel_tmp, i64 %p_int_2_vy, i64 %p_int_vy_5
  %p_int_8_vy_3 = select i1 %sel_tmp2, i64 %p_int_vy_5, i64 %p_int_8_vy_2
  %p_int_8_vy_5 = select i1 %sel_tmp2, i64 %p_int_2_vy, i64 %p_int_8_vy_4
  %tmp_17 = select i1 %sel_tmp2, double %p_vz_2_load_1, double %p_vz_8_load
  %p_vz_load_2_phi = select i1 %sel_tmp, double %p_vz_5_load_1, double %tmp_17
  %tmp_69_2 = fmul double %p_vz_load_2_phi, 1.000000e+16
  %p_int_2_vz = call fastcc i64 @__hls_fptosi_double_(double %tmp_69_2) nounwind
  %p_int_8_vz = select i1 %sel_tmp, i64 %p_int_vz_8, i64 %p_int_2_vz
  %p_int_8_vz_1 = select i1 %sel_tmp2, i64 %p_int_vz_8, i64 %p_int_8_vz
  %p_int_8_vz_2 = select i1 %sel_tmp, i64 %p_int_2_vz, i64 %p_int_vz_5
  %p_int_8_vz_3 = select i1 %sel_tmp2, i64 %p_int_vz_5, i64 %p_int_8_vz_2
  %p_int_8_vz_5 = select i1 %sel_tmp2, i64 %p_int_2_vz, i64 %p_int_8_vz_4
  %i_2 = add i4 %i_0_i, 3
  br label %1

to_int.exit.0:                                    ; preds = %to_int.exit.0.preheader, %janus_step.exit.9
  %p_int_vz_8_2 = phi i64 [ %p_int_vz_8_10, %janus_step.exit.9 ], [ %p_int_vz_8, %to_int.exit.0.preheader ]
  %p_int_vz_7_2 = phi i64 [ %p_int_vz_7_10, %janus_step.exit.9 ], [ %p_int_vz_7, %to_int.exit.0.preheader ]
  %p_int_vz_6_2 = phi i64 [ %p_int_vz_6_10, %janus_step.exit.9 ], [ %p_int_vz_6, %to_int.exit.0.preheader ]
  %p_int_vz_5_2 = phi i64 [ %p_int_vz_5_10, %janus_step.exit.9 ], [ %p_int_vz_5, %to_int.exit.0.preheader ]
  %p_int_vz_4_2 = phi i64 [ %p_int_vz_4_10, %janus_step.exit.9 ], [ %p_int_vz_4, %to_int.exit.0.preheader ]
  %p_int_vz_3_2 = phi i64 [ %p_int_vz_3_10, %janus_step.exit.9 ], [ %p_int_vz_3, %to_int.exit.0.preheader ]
  %p_int_vz_2_2 = phi i64 [ %p_int_8_vz_80, %janus_step.exit.9 ], [ %p_int_8_vz_4, %to_int.exit.0.preheader ]
  %p_int_vz_1_2 = phi i64 [ %p_int_7_vz_80, %janus_step.exit.9 ], [ %p_int_7_vz_4, %to_int.exit.0.preheader ]
  %p_int_vz_0_2 = phi i64 [ %p_int_6_vz_80, %janus_step.exit.9 ], [ %p_int_6_vz_4, %to_int.exit.0.preheader ]
  %p_int_vy_8_2 = phi i64 [ %p_int_vy_8_10, %janus_step.exit.9 ], [ %p_int_vy_8, %to_int.exit.0.preheader ]
  %p_int_vy_7_2 = phi i64 [ %p_int_vy_7_10, %janus_step.exit.9 ], [ %p_int_vy_7, %to_int.exit.0.preheader ]
  %p_int_vy_6_2 = phi i64 [ %p_int_vy_6_10, %janus_step.exit.9 ], [ %p_int_vy_6, %to_int.exit.0.preheader ]
  %p_int_vy_5_2 = phi i64 [ %p_int_vy_5_10, %janus_step.exit.9 ], [ %p_int_vy_5, %to_int.exit.0.preheader ]
  %p_int_vy_4_2 = phi i64 [ %p_int_vy_4_10, %janus_step.exit.9 ], [ %p_int_vy_4, %to_int.exit.0.preheader ]
  %p_int_vy_3_2 = phi i64 [ %p_int_vy_3_10, %janus_step.exit.9 ], [ %p_int_vy_3, %to_int.exit.0.preheader ]
  %p_int_vy_2_2 = phi i64 [ %p_int_8_vy_80, %janus_step.exit.9 ], [ %p_int_8_vy_4, %to_int.exit.0.preheader ]
  %p_int_vy_1_2 = phi i64 [ %p_int_7_vy_80, %janus_step.exit.9 ], [ %p_int_7_vy_4, %to_int.exit.0.preheader ]
  %p_int_vy_0_2 = phi i64 [ %p_int_6_vy_80, %janus_step.exit.9 ], [ %p_int_6_vy_4, %to_int.exit.0.preheader ]
  %p_int_vx_8_2 = phi i64 [ %p_int_vx_8_10, %janus_step.exit.9 ], [ %p_int_vx_8, %to_int.exit.0.preheader ]
  %p_int_vx_7_2 = phi i64 [ %p_int_vx_7_10, %janus_step.exit.9 ], [ %p_int_vx_7, %to_int.exit.0.preheader ]
  %p_int_vx_6_2 = phi i64 [ %p_int_vx_6_10, %janus_step.exit.9 ], [ %p_int_vx_6, %to_int.exit.0.preheader ]
  %p_int_vx_5_2 = phi i64 [ %p_int_vx_5_10, %janus_step.exit.9 ], [ %p_int_vx_5, %to_int.exit.0.preheader ]
  %p_int_vx_4_2 = phi i64 [ %p_int_vx_4_10, %janus_step.exit.9 ], [ %p_int_vx_4, %to_int.exit.0.preheader ]
  %p_int_vx_3_2 = phi i64 [ %p_int_vx_3_10, %janus_step.exit.9 ], [ %p_int_vx_3, %to_int.exit.0.preheader ]
  %p_int_vx_2_2 = phi i64 [ %p_int_8_vx_80, %janus_step.exit.9 ], [ %p_int_8_vx_4, %to_int.exit.0.preheader ]
  %p_int_vx_1_2 = phi i64 [ %p_int_7_vx_80, %janus_step.exit.9 ], [ %p_int_7_vx_4, %to_int.exit.0.preheader ]
  %p_int_vx_0_2 = phi i64 [ %p_int_6_vx_80, %janus_step.exit.9 ], [ %p_int_6_vx_4, %to_int.exit.0.preheader ]
  %p_int_z_8_2 = phi i64 [ %p_int_8_z_37, %janus_step.exit.9 ], [ %p_int_z_8, %to_int.exit.0.preheader ]
  %p_int_z_7_2 = phi i64 [ %p_int_7_z_37, %janus_step.exit.9 ], [ %p_int_z_7, %to_int.exit.0.preheader ]
  %p_int_z_6_2 = phi i64 [ %p_int_6_z_37, %janus_step.exit.9 ], [ %p_int_z_6, %to_int.exit.0.preheader ]
  %p_int_z_5_2 = phi i64 [ %p_int_5_z_20, %janus_step.exit.9 ], [ %p_int_z_5, %to_int.exit.0.preheader ]
  %p_int_z_4_2 = phi i64 [ %p_int_4_z_20, %janus_step.exit.9 ], [ %p_int_z_4, %to_int.exit.0.preheader ]
  %p_int_z_3_2 = phi i64 [ %p_int_3_z_20, %janus_step.exit.9 ], [ %p_int_z_3, %to_int.exit.0.preheader ]
  %p_int_z_2_2 = phi i64 [ %p_int_2_z_20, %janus_step.exit.9 ], [ %p_int_8_z_26, %to_int.exit.0.preheader ]
  %p_int_z_1_2 = phi i64 [ %p_int_1_z_20, %janus_step.exit.9 ], [ %p_int_7_z_26, %to_int.exit.0.preheader ]
  %p_int_z_0_2 = phi i64 [ %p_int_0_z_20, %janus_step.exit.9 ], [ %p_int_6_z_26, %to_int.exit.0.preheader ]
  %p_int_y_8_2 = phi i64 [ %p_int_8_y_37, %janus_step.exit.9 ], [ %p_int_y_8, %to_int.exit.0.preheader ]
  %p_int_y_7_2 = phi i64 [ %p_int_7_y_37, %janus_step.exit.9 ], [ %p_int_y_7, %to_int.exit.0.preheader ]
  %p_int_y_6_2 = phi i64 [ %p_int_6_y_38, %janus_step.exit.9 ], [ %p_int_y_6, %to_int.exit.0.preheader ]
  %p_int_y_5_2 = phi i64 [ %p_int_5_y_20, %janus_step.exit.9 ], [ %p_int_y_5, %to_int.exit.0.preheader ]
  %p_int_y_4_2 = phi i64 [ %p_int_4_y_20, %janus_step.exit.9 ], [ %p_int_y_4, %to_int.exit.0.preheader ]
  %p_int_y_3_2 = phi i64 [ %p_int_3_y_20, %janus_step.exit.9 ], [ %p_int_y_3, %to_int.exit.0.preheader ]
  %p_int_y_2_2 = phi i64 [ %p_int_2_y_20, %janus_step.exit.9 ], [ %p_int_8_y_26, %to_int.exit.0.preheader ]
  %p_int_y_1_2 = phi i64 [ %p_int_1_y_20, %janus_step.exit.9 ], [ %p_int_7_y_26, %to_int.exit.0.preheader ]
  %p_int_y_0_2 = phi i64 [ %p_int_0_y_20, %janus_step.exit.9 ], [ %p_int_6_y_26, %to_int.exit.0.preheader ]
  %p_int_x_8_2 = phi i64 [ %p_int_8_x_37, %janus_step.exit.9 ], [ %p_int_x_8, %to_int.exit.0.preheader ]
  %p_int_x_7_2 = phi i64 [ %p_int_7_x_37, %janus_step.exit.9 ], [ %p_int_x_7, %to_int.exit.0.preheader ]
  %p_int_x_6_2 = phi i64 [ %p_int_6_x_38, %janus_step.exit.9 ], [ %p_int_x_6, %to_int.exit.0.preheader ]
  %p_int_x_5_2 = phi i64 [ %p_int_5_x_20, %janus_step.exit.9 ], [ %p_int_x_5, %to_int.exit.0.preheader ]
  %p_int_x_4_2 = phi i64 [ %p_int_4_x_20, %janus_step.exit.9 ], [ %p_int_x_4, %to_int.exit.0.preheader ]
  %p_int_x_3_2 = phi i64 [ %p_int_3_x_20, %janus_step.exit.9 ], [ %p_int_x_3, %to_int.exit.0.preheader ]
  %p_int_x_2_2 = phi i64 [ %p_int_2_x_20, %janus_step.exit.9 ], [ %p_int_8_x_26, %to_int.exit.0.preheader ]
  %p_int_x_1_2 = phi i64 [ %p_int_1_x_20, %janus_step.exit.9 ], [ %p_int_7_x_26, %to_int.exit.0.preheader ]
  %p_int_x_0_2 = phi i64 [ %p_int_0_x_20, %janus_step.exit.9 ], [ %p_int_6_x_26, %to_int.exit.0.preheader ]
  %t = phi i32 [ %t_1_9, %janus_step.exit.9 ], [ 0, %to_int.exit.0.preheader ]
  %empty_10 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 629, i64 629, i64 629)
  call void (...)* @_ssdm_op_SpecLoopName([7 x i8]* @p_str5) nounwind
  %tmp_18 = call i32 (...)* @_ssdm_op_SpecRegionBegin([7 x i8]* @p_str5)
  %drift_ret1 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_x_0_2, i64 %p_int_x_1_2, i64 %p_int_x_2_2, i64 %p_int_x_3_2, i64 %p_int_x_4_2, i64 %p_int_x_5_2, i64 %p_int_x_6_2, i64 %p_int_x_7_2, i64 %p_int_x_8_2, i64 %p_int_y_0_2, i64 %p_int_y_1_2, i64 %p_int_y_2_2, i64 %p_int_y_3_2, i64 %p_int_y_4_2, i64 %p_int_y_5_2, i64 %p_int_y_6_2, i64 %p_int_y_7_2, i64 %p_int_y_8_2, i64 %p_int_z_0_2, i64 %p_int_z_1_2, i64 %p_int_z_2_2, i64 %p_int_z_3_2, i64 %p_int_z_4_2, i64 %p_int_z_5_2, i64 %p_int_z_6_2, i64 %p_int_z_7_2, i64 %p_int_z_8_2, i64 %p_int_vx_0_2, i64 %p_int_vx_1_2, i64 %p_int_vx_2_2, i64 %p_int_vx_3_2, i64 %p_int_vx_4_2, i64 %p_int_vx_5_2, i64 %p_int_vx_6_2, i64 %p_int_vx_7_2, i64 %p_int_vx_8_2, i64 %p_int_vy_0_2, i64 %p_int_vy_1_2, i64 %p_int_vy_2_2, i64 %p_int_vy_3_2, i64 %p_int_vy_4_2, i64 %p_int_vy_5_2, i64 %p_int_vy_6_2, i64 %p_int_vy_7_2, i64 %p_int_vy_8_2, i64 %p_int_vz_0_2, i64 %p_int_vz_1_2, i64 %p_int_vz_2_2, i64 %p_int_vz_3_2, i64 %p_int_vz_4_2, i64 %p_int_vz_5_2, i64 %p_int_vz_6_2, i64 %p_int_vz_7_2, i64 %p_int_vz_8_2)
  %p_int_0_x = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 0
  %p_int_1_x = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 1
  %p_int_2_x = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 2
  %p_int_3_x = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 3
  %p_int_4_x = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 4
  %p_int_5_x = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 5
  %p_int_6_x = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 6
  %p_int_7_x = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 7
  %p_int_8_x = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 8
  %p_int_0_y = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 9
  %p_int_1_y = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 10
  %p_int_2_y = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 11
  %p_int_3_y = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 12
  %p_int_4_y = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 13
  %p_int_5_y = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 14
  %p_int_6_y = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 15
  %p_int_7_y = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 16
  %p_int_8_y = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 17
  %p_int_0_z = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 18
  %p_int_1_z = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 19
  %p_int_2_z = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 20
  %p_int_3_z = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 21
  %p_int_4_z = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 22
  %p_int_5_z = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 23
  %p_int_6_z = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 24
  %p_int_7_z = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 25
  %p_int_8_z = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret1, 26
  call fastcc void @to_double(i64 %p_int_0_x, i64 %p_int_1_x, i64 %p_int_2_x, i64 %p_int_3_x, i64 %p_int_4_x, i64 %p_int_5_x, i64 %p_int_6_x, i64 %p_int_7_x, i64 %p_int_8_x, i64 %p_int_0_y, i64 %p_int_1_y, i64 %p_int_2_y, i64 %p_int_3_y, i64 %p_int_4_y, i64 %p_int_5_y, i64 %p_int_6_y, i64 %p_int_7_y, i64 %p_int_8_y, i64 %p_int_0_z, i64 %p_int_1_z, i64 %p_int_2_z, i64 %p_int_3_z, i64 %p_int_4_z, i64 %p_int_5_z, i64 %p_int_6_z, i64 %p_int_7_z, i64 %p_int_8_z, i64 %p_int_vx_0_2, i64 %p_int_vx_1_2, i64 %p_int_vx_2_2, i64 %p_int_vx_3_2, i64 %p_int_vx_4_2, i64 %p_int_vx_5_2, i64 %p_int_vx_6_2, i64 %p_int_vx_7_2, i64 %p_int_vx_8_2, i64 %p_int_vy_0_2, i64 %p_int_vy_1_2, i64 %p_int_vy_2_2, i64 %p_int_vy_3_2, i64 %p_int_vy_4_2, i64 %p_int_vy_5_2, i64 %p_int_vy_6_2, i64 %p_int_vy_7_2, i64 %p_int_vy_8_2, i64 %p_int_vz_0_2, i64 %p_int_vz_1_2, i64 %p_int_vz_2_2, i64 %p_int_vz_3_2, i64 %p_int_vz_4_2, i64 %p_int_vz_5_2, i64 %p_int_vz_6_2, i64 %p_int_vz_7_2, i64 %p_int_vz_8_2)
  call fastcc void @gravity() nounwind
  br label %2

; <label>:2                                       ; preds = %_ifconv220, %to_int.exit.0
  %p_int_vz_8_3 = phi i64 [ %p_int_vz_8_2, %to_int.exit.0 ], [ %p_int_8_vz_8, %_ifconv220 ]
  %p_int_vz_7_3 = phi i64 [ %p_int_vz_7_2, %to_int.exit.0 ], [ %p_int_7_vz_8, %_ifconv220 ]
  %p_int_vz_6_3 = phi i64 [ %p_int_vz_6_2, %to_int.exit.0 ], [ %p_int_6_vz_8, %_ifconv220 ]
  %p_int_vz_5_3 = phi i64 [ %p_int_vz_5_2, %to_int.exit.0 ], [ %p_int_8_vz_6, %_ifconv220 ]
  %p_int_vz_4_3 = phi i64 [ %p_int_vz_4_2, %to_int.exit.0 ], [ %p_int_7_vz_6, %_ifconv220 ]
  %p_int_vz_3_3 = phi i64 [ %p_int_vz_3_2, %to_int.exit.0 ], [ %p_int_6_vz_6, %_ifconv220 ]
  %p_int_8_vz_52 = phi i64 [ %p_int_vz_2_2, %to_int.exit.0 ], [ %p_int_8_vz_53, %_ifconv220 ]
  %p_int_7_vz_52 = phi i64 [ %p_int_vz_1_2, %to_int.exit.0 ], [ %p_int_7_vz_53, %_ifconv220 ]
  %p_int_6_vz_52 = phi i64 [ %p_int_vz_0_2, %to_int.exit.0 ], [ %p_int_6_vz_53, %_ifconv220 ]
  %p_int_vy_8_3 = phi i64 [ %p_int_vy_8_2, %to_int.exit.0 ], [ %p_int_8_vy_8, %_ifconv220 ]
  %p_int_vy_7_3 = phi i64 [ %p_int_vy_7_2, %to_int.exit.0 ], [ %p_int_7_vy_8, %_ifconv220 ]
  %p_int_vy_6_3 = phi i64 [ %p_int_vy_6_2, %to_int.exit.0 ], [ %p_int_6_vy_8, %_ifconv220 ]
  %p_int_vy_5_3 = phi i64 [ %p_int_vy_5_2, %to_int.exit.0 ], [ %p_int_8_vy_6, %_ifconv220 ]
  %p_int_vy_4_3 = phi i64 [ %p_int_vy_4_2, %to_int.exit.0 ], [ %p_int_7_vy_6, %_ifconv220 ]
  %p_int_vy_3_3 = phi i64 [ %p_int_vy_3_2, %to_int.exit.0 ], [ %p_int_6_vy_6, %_ifconv220 ]
  %p_int_8_vy_52 = phi i64 [ %p_int_vy_2_2, %to_int.exit.0 ], [ %p_int_8_vy_53, %_ifconv220 ]
  %p_int_7_vy_52 = phi i64 [ %p_int_vy_1_2, %to_int.exit.0 ], [ %p_int_7_vy_53, %_ifconv220 ]
  %p_int_6_vy_52 = phi i64 [ %p_int_vy_0_2, %to_int.exit.0 ], [ %p_int_6_vy_53, %_ifconv220 ]
  %p_int_vx_8_3 = phi i64 [ %p_int_vx_8_2, %to_int.exit.0 ], [ %p_int_8_vx_8, %_ifconv220 ]
  %p_int_vx_7_3 = phi i64 [ %p_int_vx_7_2, %to_int.exit.0 ], [ %p_int_7_vx_8, %_ifconv220 ]
  %p_int_vx_6_3 = phi i64 [ %p_int_vx_6_2, %to_int.exit.0 ], [ %p_int_6_vx_8, %_ifconv220 ]
  %p_int_vx_5_3 = phi i64 [ %p_int_vx_5_2, %to_int.exit.0 ], [ %p_int_8_vx_6, %_ifconv220 ]
  %p_int_vx_4_3 = phi i64 [ %p_int_vx_4_2, %to_int.exit.0 ], [ %p_int_7_vx_6, %_ifconv220 ]
  %p_int_vx_3_3 = phi i64 [ %p_int_vx_3_2, %to_int.exit.0 ], [ %p_int_6_vx_6, %_ifconv220 ]
  %p_int_8_vx_52 = phi i64 [ %p_int_vx_2_2, %to_int.exit.0 ], [ %p_int_8_vx_53, %_ifconv220 ]
  %p_int_7_vx_52 = phi i64 [ %p_int_vx_1_2, %to_int.exit.0 ], [ %p_int_7_vx_53, %_ifconv220 ]
  %p_int_6_vx_52 = phi i64 [ %p_int_vx_0_2, %to_int.exit.0 ], [ %p_int_6_vx_53, %_ifconv220 ]
  %i_0_i_i = phi i4 [ 0, %to_int.exit.0 ], [ %i_4_0_2, %_ifconv220 ]
  %tmp_43 = icmp eq i4 %i_0_i_i, -7
  br i1 %tmp_43, label %janus_step.exit.0, label %_ifconv220

_ifconv220:                                       ; preds = %2
  %empty_11 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_20 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str7)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %p_ax_6_load = load double* @p_ax_6, align 16
  %p_ax_0_load = load double* @p_ax_0, align 16
  %p_ax_3_load = load double* @p_ax_3, align 16
  %sel_tmp3 = icmp eq i4 %i_0_i_i, 0
  %sel_tmp4 = select i1 %sel_tmp3, double %p_ax_0_load, double %p_ax_6_load
  %sel_tmp5 = icmp eq i4 %i_0_i_i, 3
  %p_ax_load_0_0_phi = select i1 %sel_tmp5, double %p_ax_3_load, double %sel_tmp4
  %tmp_44 = fmul double %p_ax_load_0_0_phi, 1.000000e-02
  %tmp_45 = fmul double %tmp_44, 1.000000e+16
  %tmp_46 = call fastcc i64 @__hls_fptosi_double_(double %tmp_45) nounwind
  %p_int_vx_load_0_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vx_52, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i64 %p_int_vx_3_3, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i64 %p_int_vx_6_3, i4 %i_0_i_i)
  %p_int_0_vx_1 = add nsw i64 %tmp_46, %p_int_vx_load_0_0_ph
  %p_int_6_vx_7 = select i1 %sel_tmp5, i64 %p_int_vx_6_3, i64 %p_int_0_vx_1
  %p_int_6_vx_8 = select i1 %sel_tmp3, i64 %p_int_vx_6_3, i64 %p_int_6_vx_7
  %p_int_6_vx_9 = select i1 %sel_tmp5, i64 %p_int_0_vx_1, i64 %p_int_vx_3_3
  %p_int_6_vx_6 = select i1 %sel_tmp3, i64 %p_int_vx_3_3, i64 %p_int_6_vx_9
  %p_int_6_vx_53 = select i1 %sel_tmp3, i64 %p_int_0_vx_1, i64 %p_int_6_vx_52
  %p_ay_6_load = load double* @p_ay_6, align 8
  %p_ay_0_load = load double* @p_ay_0, align 8
  %p_ay_3_load = load double* @p_ay_3, align 8
  %sel_tmp6 = select i1 %sel_tmp3, double %p_ay_0_load, double %p_ay_6_load
  %p_ay_load_0_0_phi = select i1 %sel_tmp5, double %p_ay_3_load, double %sel_tmp6
  %tmp_47 = fmul double %p_ay_load_0_0_phi, 1.000000e-02
  %tmp_48 = fmul double %tmp_47, 1.000000e+16
  %tmp_49 = call fastcc i64 @__hls_fptosi_double_(double %tmp_48) nounwind
  %p_int_vy_load_0_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vy_52, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i64 %p_int_vy_3_3, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i64 %p_int_vy_6_3, i4 %i_0_i_i)
  %p_int_0_vy_1 = add nsw i64 %tmp_49, %p_int_vy_load_0_0_ph
  %p_int_6_vy_7 = select i1 %sel_tmp5, i64 %p_int_vy_6_3, i64 %p_int_0_vy_1
  %p_int_6_vy_8 = select i1 %sel_tmp3, i64 %p_int_vy_6_3, i64 %p_int_6_vy_7
  %p_int_6_vy_9 = select i1 %sel_tmp5, i64 %p_int_0_vy_1, i64 %p_int_vy_3_3
  %p_int_6_vy_6 = select i1 %sel_tmp3, i64 %p_int_vy_3_3, i64 %p_int_6_vy_9
  %p_int_6_vy_53 = select i1 %sel_tmp3, i64 %p_int_0_vy_1, i64 %p_int_6_vy_52
  %p_az_6_load = load double* @p_az_6, align 16
  %p_az_0_load = load double* @p_az_0, align 16
  %p_az_3_load = load double* @p_az_3, align 16
  %sel_tmp7 = select i1 %sel_tmp3, double %p_az_0_load, double %p_az_6_load
  %p_az_load_0_0_phi = select i1 %sel_tmp5, double %p_az_3_load, double %sel_tmp7
  %tmp_50 = fmul double %p_az_load_0_0_phi, 1.000000e-02
  %tmp_51 = fmul double %tmp_50, 1.000000e+16
  %tmp_52 = call fastcc i64 @__hls_fptosi_double_(double %tmp_51) nounwind
  %p_int_vz_load_0_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vz_52, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i64 %p_int_vz_3_3, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i64 %p_int_vz_6_3, i4 %i_0_i_i)
  %p_int_0_vz_1 = add nsw i64 %tmp_52, %p_int_vz_load_0_0_ph
  %p_int_6_vz_7 = select i1 %sel_tmp5, i64 %p_int_vz_6_3, i64 %p_int_0_vz_1
  %p_int_6_vz_8 = select i1 %sel_tmp3, i64 %p_int_vz_6_3, i64 %p_int_6_vz_7
  %p_int_6_vz_9 = select i1 %sel_tmp5, i64 %p_int_0_vz_1, i64 %p_int_vz_3_3
  %p_int_6_vz_6 = select i1 %sel_tmp3, i64 %p_int_vz_3_3, i64 %p_int_6_vz_9
  %p_int_6_vz_53 = select i1 %sel_tmp3, i64 %p_int_0_vz_1, i64 %p_int_6_vz_52
  %empty_12 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str7, i32 %tmp_20)
  %i_4_0_0_t = add i4 %i_0_i_i, 1
  %p_ax_7_load = load double* @p_ax_7, align 16
  %p_ax_1_load = load double* @p_ax_1, align 16
  %p_ax_4_load = load double* @p_ax_4, align 16
  %sel_tmp8 = select i1 %sel_tmp3, double %p_ax_1_load, double %p_ax_7_load
  %p_ax_load_0_1_phi = select i1 %sel_tmp5, double %p_ax_4_load, double %sel_tmp8
  %tmp_73_0_1 = fmul double %p_ax_load_0_1_phi, 1.000000e-02
  %tmp_74_0_1 = fmul double %tmp_73_0_1, 1.000000e+16
  %tmp_75_0_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_0_1) nounwind
  %p_int_vx_load_0_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_7_3, i64 %p_int_7_vx_52, i64 %p_int_vx_7_3, i64 %p_int_vx_7_3, i64 %p_int_vx_4_3, i64 %p_int_vx_7_3, i64 %p_int_vx_7_3, i64 %p_int_vx_7_3, i64 %p_int_vx_7_3, i64 %p_int_vx_7_3, i64 %p_int_vx_7_3, i64 %p_int_vx_7_3, i64 %p_int_vx_7_3, i64 %p_int_vx_7_3, i64 %p_int_vx_7_3, i64 %p_int_vx_7_3, i4 %i_4_0_0_t)
  %p_int_1_vx_1 = add nsw i64 %tmp_75_0_1, %p_int_vx_load_0_1_ph
  %p_int_7_vx_7 = select i1 %sel_tmp5, i64 %p_int_vx_7_3, i64 %p_int_1_vx_1
  %p_int_7_vx_8 = select i1 %sel_tmp3, i64 %p_int_vx_7_3, i64 %p_int_7_vx_7
  %p_int_7_vx_9 = select i1 %sel_tmp5, i64 %p_int_1_vx_1, i64 %p_int_vx_4_3
  %p_int_7_vx_6 = select i1 %sel_tmp3, i64 %p_int_vx_4_3, i64 %p_int_7_vx_9
  %p_int_7_vx_53 = select i1 %sel_tmp3, i64 %p_int_1_vx_1, i64 %p_int_7_vx_52
  %p_ay_7_load = load double* @p_ay_7, align 8
  %p_ay_1_load_1 = load double* @p_ay_1, align 8
  %p_ay_4_load_1 = load double* @p_ay_4, align 8
  %sel_tmp9 = select i1 %sel_tmp3, double %p_ay_1_load_1, double %p_ay_7_load
  %p_ay_load_0_1_phi = select i1 %sel_tmp5, double %p_ay_4_load_1, double %sel_tmp9
  %tmp_77_0_1 = fmul double %p_ay_load_0_1_phi, 1.000000e-02
  %tmp_78_0_1 = fmul double %tmp_77_0_1, 1.000000e+16
  %tmp_79_0_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_0_1) nounwind
  %p_int_vy_load_0_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_7_3, i64 %p_int_7_vy_52, i64 %p_int_vy_7_3, i64 %p_int_vy_7_3, i64 %p_int_vy_4_3, i64 %p_int_vy_7_3, i64 %p_int_vy_7_3, i64 %p_int_vy_7_3, i64 %p_int_vy_7_3, i64 %p_int_vy_7_3, i64 %p_int_vy_7_3, i64 %p_int_vy_7_3, i64 %p_int_vy_7_3, i64 %p_int_vy_7_3, i64 %p_int_vy_7_3, i64 %p_int_vy_7_3, i4 %i_4_0_0_t)
  %p_int_1_vy_1 = add nsw i64 %tmp_79_0_1, %p_int_vy_load_0_1_ph
  %p_int_7_vy_7 = select i1 %sel_tmp5, i64 %p_int_vy_7_3, i64 %p_int_1_vy_1
  %p_int_7_vy_8 = select i1 %sel_tmp3, i64 %p_int_vy_7_3, i64 %p_int_7_vy_7
  %p_int_7_vy_9 = select i1 %sel_tmp5, i64 %p_int_1_vy_1, i64 %p_int_vy_4_3
  %p_int_7_vy_6 = select i1 %sel_tmp3, i64 %p_int_vy_4_3, i64 %p_int_7_vy_9
  %p_int_7_vy_53 = select i1 %sel_tmp3, i64 %p_int_1_vy_1, i64 %p_int_7_vy_52
  %p_az_7_load = load double* @p_az_7, align 16
  %p_az_1_load_1 = load double* @p_az_1, align 16
  %p_az_4_load_1 = load double* @p_az_4, align 16
  %sel_tmp10 = select i1 %sel_tmp3, double %p_az_1_load_1, double %p_az_7_load
  %p_az_load_0_1_phi = select i1 %sel_tmp5, double %p_az_4_load_1, double %sel_tmp10
  %tmp_81_0_1 = fmul double %p_az_load_0_1_phi, 1.000000e-02
  %tmp_82_0_1 = fmul double %tmp_81_0_1, 1.000000e+16
  %tmp_83_0_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_0_1) nounwind
  %p_int_vz_load_0_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_7_3, i64 %p_int_7_vz_52, i64 %p_int_vz_7_3, i64 %p_int_vz_7_3, i64 %p_int_vz_4_3, i64 %p_int_vz_7_3, i64 %p_int_vz_7_3, i64 %p_int_vz_7_3, i64 %p_int_vz_7_3, i64 %p_int_vz_7_3, i64 %p_int_vz_7_3, i64 %p_int_vz_7_3, i64 %p_int_vz_7_3, i64 %p_int_vz_7_3, i64 %p_int_vz_7_3, i64 %p_int_vz_7_3, i4 %i_4_0_0_t)
  %p_int_1_vz_1 = add nsw i64 %tmp_83_0_1, %p_int_vz_load_0_1_ph
  %p_int_7_vz_7 = select i1 %sel_tmp5, i64 %p_int_vz_7_3, i64 %p_int_1_vz_1
  %p_int_7_vz_8 = select i1 %sel_tmp3, i64 %p_int_vz_7_3, i64 %p_int_7_vz_7
  %p_int_7_vz_9 = select i1 %sel_tmp5, i64 %p_int_1_vz_1, i64 %p_int_vz_4_3
  %p_int_7_vz_6 = select i1 %sel_tmp3, i64 %p_int_vz_4_3, i64 %p_int_7_vz_9
  %p_int_7_vz_53 = select i1 %sel_tmp3, i64 %p_int_1_vz_1, i64 %p_int_7_vz_52
  %i_4_0_1_t = add i4 %i_0_i_i, 2
  %p_ax_8_load = load double* @p_ax_8, align 16
  %p_ax_2_load_1 = load double* @p_ax_2, align 16
  %p_ax_5_load_1 = load double* @p_ax_5, align 16
  %sel_tmp11 = select i1 %sel_tmp3, double %p_ax_2_load_1, double %p_ax_8_load
  %p_ax_load_0_2_phi = select i1 %sel_tmp5, double %p_ax_5_load_1, double %sel_tmp11
  %tmp_73_0_2 = fmul double %p_ax_load_0_2_phi, 1.000000e-02
  %tmp_74_0_2 = fmul double %tmp_73_0_2, 1.000000e+16
  %tmp_75_0_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_0_2) nounwind
  %p_int_vx_load_0_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_8_3, i64 %p_int_vx_8_3, i64 %p_int_8_vx_52, i64 %p_int_vx_8_3, i64 %p_int_vx_8_3, i64 %p_int_vx_5_3, i64 %p_int_vx_8_3, i64 %p_int_vx_8_3, i64 %p_int_vx_8_3, i64 %p_int_vx_8_3, i64 %p_int_vx_8_3, i64 %p_int_vx_8_3, i64 %p_int_vx_8_3, i64 %p_int_vx_8_3, i64 %p_int_vx_8_3, i64 %p_int_vx_8_3, i4 %i_4_0_1_t)
  %p_int_2_vx_1 = add nsw i64 %tmp_75_0_2, %p_int_vx_load_0_2_ph
  %p_int_8_vx_7 = select i1 %sel_tmp5, i64 %p_int_vx_8_3, i64 %p_int_2_vx_1
  %p_int_8_vx_8 = select i1 %sel_tmp3, i64 %p_int_vx_8_3, i64 %p_int_8_vx_7
  %p_int_8_vx_9 = select i1 %sel_tmp5, i64 %p_int_2_vx_1, i64 %p_int_vx_5_3
  %p_int_8_vx_6 = select i1 %sel_tmp3, i64 %p_int_vx_5_3, i64 %p_int_8_vx_9
  %p_int_8_vx_53 = select i1 %sel_tmp3, i64 %p_int_2_vx_1, i64 %p_int_8_vx_52
  %p_ay_8_load = load double* @p_ay_8, align 8
  %p_ay_2_load_1 = load double* @p_ay_2, align 8
  %p_ay_5_load_1 = load double* @p_ay_5, align 8
  %sel_tmp12 = select i1 %sel_tmp3, double %p_ay_2_load_1, double %p_ay_8_load
  %p_ay_load_0_2_phi = select i1 %sel_tmp5, double %p_ay_5_load_1, double %sel_tmp12
  %tmp_77_0_2 = fmul double %p_ay_load_0_2_phi, 1.000000e-02
  %tmp_78_0_2 = fmul double %tmp_77_0_2, 1.000000e+16
  %tmp_79_0_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_0_2) nounwind
  %p_int_vy_load_0_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_8_3, i64 %p_int_vy_8_3, i64 %p_int_8_vy_52, i64 %p_int_vy_8_3, i64 %p_int_vy_8_3, i64 %p_int_vy_5_3, i64 %p_int_vy_8_3, i64 %p_int_vy_8_3, i64 %p_int_vy_8_3, i64 %p_int_vy_8_3, i64 %p_int_vy_8_3, i64 %p_int_vy_8_3, i64 %p_int_vy_8_3, i64 %p_int_vy_8_3, i64 %p_int_vy_8_3, i64 %p_int_vy_8_3, i4 %i_4_0_1_t)
  %p_int_2_vy_1 = add nsw i64 %tmp_79_0_2, %p_int_vy_load_0_2_ph
  %p_int_8_vy_7 = select i1 %sel_tmp5, i64 %p_int_vy_8_3, i64 %p_int_2_vy_1
  %p_int_8_vy_8 = select i1 %sel_tmp3, i64 %p_int_vy_8_3, i64 %p_int_8_vy_7
  %p_int_8_vy_9 = select i1 %sel_tmp5, i64 %p_int_2_vy_1, i64 %p_int_vy_5_3
  %p_int_8_vy_6 = select i1 %sel_tmp3, i64 %p_int_vy_5_3, i64 %p_int_8_vy_9
  %p_int_8_vy_53 = select i1 %sel_tmp3, i64 %p_int_2_vy_1, i64 %p_int_8_vy_52
  %p_az_8_load = load double* @p_az_8, align 16
  %p_az_2_load_1 = load double* @p_az_2, align 16
  %p_az_5_load_1 = load double* @p_az_5, align 16
  %sel_tmp13 = select i1 %sel_tmp3, double %p_az_2_load_1, double %p_az_8_load
  %p_az_load_0_2_phi = select i1 %sel_tmp5, double %p_az_5_load_1, double %sel_tmp13
  %tmp_81_0_2 = fmul double %p_az_load_0_2_phi, 1.000000e-02
  %tmp_82_0_2 = fmul double %tmp_81_0_2, 1.000000e+16
  %tmp_83_0_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_0_2) nounwind
  %p_int_vz_load_0_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_8_3, i64 %p_int_vz_8_3, i64 %p_int_8_vz_52, i64 %p_int_vz_8_3, i64 %p_int_vz_8_3, i64 %p_int_vz_5_3, i64 %p_int_vz_8_3, i64 %p_int_vz_8_3, i64 %p_int_vz_8_3, i64 %p_int_vz_8_3, i64 %p_int_vz_8_3, i64 %p_int_vz_8_3, i64 %p_int_vz_8_3, i64 %p_int_vz_8_3, i64 %p_int_vz_8_3, i64 %p_int_vz_8_3, i4 %i_4_0_1_t)
  %p_int_2_vz_1 = add nsw i64 %tmp_83_0_2, %p_int_vz_load_0_2_ph
  %p_int_8_vz_7 = select i1 %sel_tmp5, i64 %p_int_vz_8_3, i64 %p_int_2_vz_1
  %p_int_8_vz_8 = select i1 %sel_tmp3, i64 %p_int_vz_8_3, i64 %p_int_8_vz_7
  %p_int_8_vz_9 = select i1 %sel_tmp5, i64 %p_int_2_vz_1, i64 %p_int_vz_5_3
  %p_int_8_vz_6 = select i1 %sel_tmp3, i64 %p_int_vz_5_3, i64 %p_int_8_vz_9
  %p_int_8_vz_53 = select i1 %sel_tmp3, i64 %p_int_2_vz_1, i64 %p_int_8_vz_52
  %i_4_0_2 = add i4 %i_0_i_i, 3
  br label %2

janus_step.exit.0:                                ; preds = %2
  %drift_ret = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x, i64 %p_int_1_x, i64 %p_int_2_x, i64 %p_int_3_x, i64 %p_int_4_x, i64 %p_int_5_x, i64 %p_int_6_x, i64 %p_int_7_x, i64 %p_int_8_x, i64 %p_int_0_y, i64 %p_int_1_y, i64 %p_int_2_y, i64 %p_int_3_y, i64 %p_int_4_y, i64 %p_int_5_y, i64 %p_int_6_y, i64 %p_int_7_y, i64 %p_int_8_y, i64 %p_int_0_z, i64 %p_int_1_z, i64 %p_int_2_z, i64 %p_int_3_z, i64 %p_int_4_z, i64 %p_int_5_z, i64 %p_int_6_z, i64 %p_int_7_z, i64 %p_int_8_z, i64 %p_int_6_vx_52, i64 %p_int_7_vx_52, i64 %p_int_8_vx_52, i64 %p_int_vx_3_3, i64 %p_int_vx_4_3, i64 %p_int_vx_5_3, i64 %p_int_vx_6_3, i64 %p_int_vx_7_3, i64 %p_int_vx_8_3, i64 %p_int_6_vy_52, i64 %p_int_7_vy_52, i64 %p_int_8_vy_52, i64 %p_int_vy_3_3, i64 %p_int_vy_4_3, i64 %p_int_vy_5_3, i64 %p_int_vy_6_3, i64 %p_int_vy_7_3, i64 %p_int_vy_8_3, i64 %p_int_6_vz_52, i64 %p_int_7_vz_52, i64 %p_int_8_vz_52, i64 %p_int_vz_3_3, i64 %p_int_vz_4_3, i64 %p_int_vz_5_3, i64 %p_int_vz_6_3, i64 %p_int_vz_7_3, i64 %p_int_vz_8_3)
  %p_int_0_x_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 0
  %p_int_1_x_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 1
  %p_int_2_x_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 2
  %p_int_3_x_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 3
  %p_int_4_x_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 4
  %p_int_5_x_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 5
  %p_int_6_x_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 6
  %p_int_7_x_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 7
  %p_int_8_x_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 8
  %p_int_0_y_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 9
  %p_int_1_y_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 10
  %p_int_2_y_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 11
  %p_int_3_y_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 12
  %p_int_4_y_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 13
  %p_int_5_y_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 14
  %p_int_6_y_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 15
  %p_int_7_y_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 16
  %p_int_8_y_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 17
  %p_int_0_z_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 18
  %p_int_1_z_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 19
  %p_int_2_z_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 20
  %p_int_3_z_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 21
  %p_int_4_z_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 22
  %p_int_5_z_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 23
  %p_int_6_z_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 24
  %p_int_7_z_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 25
  %p_int_8_z_1 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret, 26
  call fastcc void @to_double(i64 %p_int_0_x_1, i64 %p_int_1_x_1, i64 %p_int_2_x_1, i64 %p_int_3_x_1, i64 %p_int_4_x_1, i64 %p_int_5_x_1, i64 %p_int_6_x_1, i64 %p_int_7_x_1, i64 %p_int_8_x_1, i64 %p_int_0_y_1, i64 %p_int_1_y_1, i64 %p_int_2_y_1, i64 %p_int_3_y_1, i64 %p_int_4_y_1, i64 %p_int_5_y_1, i64 %p_int_6_y_1, i64 %p_int_7_y_1, i64 %p_int_8_y_1, i64 %p_int_0_z_1, i64 %p_int_1_z_1, i64 %p_int_2_z_1, i64 %p_int_3_z_1, i64 %p_int_4_z_1, i64 %p_int_5_z_1, i64 %p_int_6_z_1, i64 %p_int_7_z_1, i64 %p_int_8_z_1, i64 %p_int_6_vx_52, i64 %p_int_7_vx_52, i64 %p_int_8_vx_52, i64 %p_int_vx_3_3, i64 %p_int_vx_4_3, i64 %p_int_vx_5_3, i64 %p_int_vx_6_3, i64 %p_int_vx_7_3, i64 %p_int_vx_8_3, i64 %p_int_6_vy_52, i64 %p_int_7_vy_52, i64 %p_int_8_vy_52, i64 %p_int_vy_3_3, i64 %p_int_vy_4_3, i64 %p_int_vy_5_3, i64 %p_int_vy_6_3, i64 %p_int_vy_7_3, i64 %p_int_vy_8_3, i64 %p_int_6_vz_52, i64 %p_int_7_vz_52, i64 %p_int_8_vz_52, i64 %p_int_vz_3_3, i64 %p_int_vz_4_3, i64 %p_int_vz_5_3, i64 %p_int_vz_6_3, i64 %p_int_vz_7_3, i64 %p_int_vz_8_3)
  %empty_13 = call i32 (...)* @_ssdm_op_SpecRegionEnd([7 x i8]* @p_str5, i32 %tmp_18)
  %tmp_19 = call i32 (...)* @_ssdm_op_SpecRegionBegin([7 x i8]* @p_str5)
  %drift_ret2 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_1, i64 %p_int_1_x_1, i64 %p_int_2_x_1, i64 %p_int_3_x_1, i64 %p_int_4_x_1, i64 %p_int_5_x_1, i64 %p_int_6_x_1, i64 %p_int_7_x_1, i64 %p_int_8_x_1, i64 %p_int_0_y_1, i64 %p_int_1_y_1, i64 %p_int_2_y_1, i64 %p_int_3_y_1, i64 %p_int_4_y_1, i64 %p_int_5_y_1, i64 %p_int_6_y_1, i64 %p_int_7_y_1, i64 %p_int_8_y_1, i64 %p_int_0_z_1, i64 %p_int_1_z_1, i64 %p_int_2_z_1, i64 %p_int_3_z_1, i64 %p_int_4_z_1, i64 %p_int_5_z_1, i64 %p_int_6_z_1, i64 %p_int_7_z_1, i64 %p_int_8_z_1, i64 %p_int_6_vx_52, i64 %p_int_7_vx_52, i64 %p_int_8_vx_52, i64 %p_int_vx_3_3, i64 %p_int_vx_4_3, i64 %p_int_vx_5_3, i64 %p_int_vx_6_3, i64 %p_int_vx_7_3, i64 %p_int_vx_8_3, i64 %p_int_6_vy_52, i64 %p_int_7_vy_52, i64 %p_int_8_vy_52, i64 %p_int_vy_3_3, i64 %p_int_vy_4_3, i64 %p_int_vy_5_3, i64 %p_int_vy_6_3, i64 %p_int_vy_7_3, i64 %p_int_vy_8_3, i64 %p_int_6_vz_52, i64 %p_int_7_vz_52, i64 %p_int_8_vz_52, i64 %p_int_vz_3_3, i64 %p_int_vz_4_3, i64 %p_int_vz_5_3, i64 %p_int_vz_6_3, i64 %p_int_vz_7_3, i64 %p_int_vz_8_3)
  %p_int_0_x_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 0
  %p_int_1_x_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 1
  %p_int_2_x_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 2
  %p_int_3_x_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 3
  %p_int_4_x_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 4
  %p_int_5_x_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 5
  %p_int_6_x_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 6
  %p_int_7_x_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 7
  %p_int_8_x_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 8
  %p_int_0_y_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 9
  %p_int_1_y_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 10
  %p_int_2_y_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 11
  %p_int_3_y_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 12
  %p_int_4_y_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 13
  %p_int_5_y_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 14
  %p_int_6_y_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 15
  %p_int_7_y_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 16
  %p_int_8_y_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 17
  %p_int_0_z_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 18
  %p_int_1_z_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 19
  %p_int_2_z_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 20
  %p_int_3_z_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 21
  %p_int_4_z_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 22
  %p_int_5_z_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 23
  %p_int_6_z_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 24
  %p_int_7_z_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 25
  %p_int_8_z_2 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret2, 26
  call fastcc void @to_double(i64 %p_int_0_x_2, i64 %p_int_1_x_2, i64 %p_int_2_x_2, i64 %p_int_3_x_2, i64 %p_int_4_x_2, i64 %p_int_5_x_2, i64 %p_int_6_x_2, i64 %p_int_7_x_2, i64 %p_int_8_x_2, i64 %p_int_0_y_2, i64 %p_int_1_y_2, i64 %p_int_2_y_2, i64 %p_int_3_y_2, i64 %p_int_4_y_2, i64 %p_int_5_y_2, i64 %p_int_6_y_2, i64 %p_int_7_y_2, i64 %p_int_8_y_2, i64 %p_int_0_z_2, i64 %p_int_1_z_2, i64 %p_int_2_z_2, i64 %p_int_3_z_2, i64 %p_int_4_z_2, i64 %p_int_5_z_2, i64 %p_int_6_z_2, i64 %p_int_7_z_2, i64 %p_int_8_z_2, i64 %p_int_6_vx_52, i64 %p_int_7_vx_52, i64 %p_int_8_vx_52, i64 %p_int_vx_3_3, i64 %p_int_vx_4_3, i64 %p_int_vx_5_3, i64 %p_int_vx_6_3, i64 %p_int_vx_7_3, i64 %p_int_vx_8_3, i64 %p_int_6_vy_52, i64 %p_int_7_vy_52, i64 %p_int_8_vy_52, i64 %p_int_vy_3_3, i64 %p_int_vy_4_3, i64 %p_int_vy_5_3, i64 %p_int_vy_6_3, i64 %p_int_vy_7_3, i64 %p_int_vy_8_3, i64 %p_int_6_vz_52, i64 %p_int_7_vz_52, i64 %p_int_8_vz_52, i64 %p_int_vz_3_3, i64 %p_int_vz_4_3, i64 %p_int_vz_5_3, i64 %p_int_vz_6_3, i64 %p_int_vz_7_3, i64 %p_int_vz_8_3)
  call fastcc void @gravity() nounwind
  br label %3

; <label>:3                                       ; preds = %_ifconv365, %janus_step.exit.0
  %p_int_vz_8_5 = phi i64 [ %p_int_vz_8_3, %janus_step.exit.0 ], [ %p_int_8_vz_11, %_ifconv365 ]
  %p_int_vz_7_5 = phi i64 [ %p_int_vz_7_3, %janus_step.exit.0 ], [ %p_int_7_vz_11, %_ifconv365 ]
  %p_int_vz_6_5 = phi i64 [ %p_int_vz_6_3, %janus_step.exit.0 ], [ %p_int_6_vz_11, %_ifconv365 ]
  %p_int_vz_5_5 = phi i64 [ %p_int_vz_5_3, %janus_step.exit.0 ], [ %p_int_8_vz_13, %_ifconv365 ]
  %p_int_vz_4_5 = phi i64 [ %p_int_vz_4_3, %janus_step.exit.0 ], [ %p_int_7_vz_13, %_ifconv365 ]
  %p_int_vz_3_5 = phi i64 [ %p_int_vz_3_3, %janus_step.exit.0 ], [ %p_int_6_vz_13, %_ifconv365 ]
  %p_int_8_vz_56 = phi i64 [ %p_int_8_vz_52, %janus_step.exit.0 ], [ %p_int_8_vz_57, %_ifconv365 ]
  %p_int_7_vz_56 = phi i64 [ %p_int_7_vz_52, %janus_step.exit.0 ], [ %p_int_7_vz_57, %_ifconv365 ]
  %p_int_6_vz_56 = phi i64 [ %p_int_6_vz_52, %janus_step.exit.0 ], [ %p_int_6_vz_57, %_ifconv365 ]
  %p_int_vy_8_5 = phi i64 [ %p_int_vy_8_3, %janus_step.exit.0 ], [ %p_int_8_vy_11, %_ifconv365 ]
  %p_int_vy_7_5 = phi i64 [ %p_int_vy_7_3, %janus_step.exit.0 ], [ %p_int_7_vy_11, %_ifconv365 ]
  %p_int_vy_6_5 = phi i64 [ %p_int_vy_6_3, %janus_step.exit.0 ], [ %p_int_6_vy_11, %_ifconv365 ]
  %p_int_vy_5_5 = phi i64 [ %p_int_vy_5_3, %janus_step.exit.0 ], [ %p_int_8_vy_13, %_ifconv365 ]
  %p_int_vy_4_5 = phi i64 [ %p_int_vy_4_3, %janus_step.exit.0 ], [ %p_int_7_vy_13, %_ifconv365 ]
  %p_int_vy_3_5 = phi i64 [ %p_int_vy_3_3, %janus_step.exit.0 ], [ %p_int_6_vy_13, %_ifconv365 ]
  %p_int_8_vy_56 = phi i64 [ %p_int_8_vy_52, %janus_step.exit.0 ], [ %p_int_8_vy_57, %_ifconv365 ]
  %p_int_7_vy_56 = phi i64 [ %p_int_7_vy_52, %janus_step.exit.0 ], [ %p_int_7_vy_57, %_ifconv365 ]
  %p_int_6_vy_56 = phi i64 [ %p_int_6_vy_52, %janus_step.exit.0 ], [ %p_int_6_vy_57, %_ifconv365 ]
  %p_int_vx_8_5 = phi i64 [ %p_int_vx_8_3, %janus_step.exit.0 ], [ %p_int_8_vx_11, %_ifconv365 ]
  %p_int_vx_7_5 = phi i64 [ %p_int_vx_7_3, %janus_step.exit.0 ], [ %p_int_7_vx_11, %_ifconv365 ]
  %p_int_vx_6_5 = phi i64 [ %p_int_vx_6_3, %janus_step.exit.0 ], [ %p_int_6_vx_11, %_ifconv365 ]
  %p_int_vx_5_5 = phi i64 [ %p_int_vx_5_3, %janus_step.exit.0 ], [ %p_int_8_vx_13, %_ifconv365 ]
  %p_int_vx_4_5 = phi i64 [ %p_int_vx_4_3, %janus_step.exit.0 ], [ %p_int_7_vx_13, %_ifconv365 ]
  %p_int_vx_3_5 = phi i64 [ %p_int_vx_3_3, %janus_step.exit.0 ], [ %p_int_6_vx_13, %_ifconv365 ]
  %p_int_8_vx_56 = phi i64 [ %p_int_8_vx_52, %janus_step.exit.0 ], [ %p_int_8_vx_57, %_ifconv365 ]
  %p_int_7_vx_56 = phi i64 [ %p_int_7_vx_52, %janus_step.exit.0 ], [ %p_int_7_vx_57, %_ifconv365 ]
  %p_int_6_vx_56 = phi i64 [ %p_int_6_vx_52, %janus_step.exit.0 ], [ %p_int_6_vx_57, %_ifconv365 ]
  %i_0_i_i_1 = phi i4 [ 0, %janus_step.exit.0 ], [ %i_4_1_2, %_ifconv365 ]
  %tmp_71_1 = icmp eq i4 %i_0_i_i_1, -7
  br i1 %tmp_71_1, label %janus_step.exit.1, label %_ifconv365

_ifconv365:                                       ; preds = %3
  %empty_14 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_22 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str7)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %p_ax_6_load_1 = load double* @p_ax_6, align 16
  %p_ax_0_load_1 = load double* @p_ax_0, align 16
  %p_ax_3_load_1 = load double* @p_ax_3, align 16
  %sel_tmp14 = icmp eq i4 %i_0_i_i_1, 0
  %sel_tmp15 = select i1 %sel_tmp14, double %p_ax_0_load_1, double %p_ax_6_load_1
  %sel_tmp16 = icmp eq i4 %i_0_i_i_1, 3
  %p_ax_load_1_0_phi = select i1 %sel_tmp16, double %p_ax_3_load_1, double %sel_tmp15
  %tmp_73_1 = fmul double %p_ax_load_1_0_phi, 1.000000e-02
  %tmp_74_1 = fmul double %tmp_73_1, 1.000000e+16
  %tmp_75_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_1) nounwind
  %p_int_vx_load_1_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vx_56, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i64 %p_int_vx_3_5, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i64 %p_int_vx_6_5, i4 %i_0_i_i_1)
  %p_int_0_vx_2 = add nsw i64 %tmp_75_1, %p_int_vx_load_1_0_ph
  %p_int_6_vx_10 = select i1 %sel_tmp16, i64 %p_int_vx_6_5, i64 %p_int_0_vx_2
  %p_int_6_vx_11 = select i1 %sel_tmp14, i64 %p_int_vx_6_5, i64 %p_int_6_vx_10
  %p_int_6_vx_12 = select i1 %sel_tmp16, i64 %p_int_0_vx_2, i64 %p_int_vx_3_5
  %p_int_6_vx_13 = select i1 %sel_tmp14, i64 %p_int_vx_3_5, i64 %p_int_6_vx_12
  %p_int_6_vx_57 = select i1 %sel_tmp14, i64 %p_int_0_vx_2, i64 %p_int_6_vx_56
  %p_ay_6_load_1 = load double* @p_ay_6, align 8
  %p_ay_0_load_1 = load double* @p_ay_0, align 8
  %p_ay_3_load_1 = load double* @p_ay_3, align 8
  %sel_tmp17 = select i1 %sel_tmp14, double %p_ay_0_load_1, double %p_ay_6_load_1
  %p_ay_load_1_0_phi = select i1 %sel_tmp16, double %p_ay_3_load_1, double %sel_tmp17
  %tmp_77_1 = fmul double %p_ay_load_1_0_phi, 1.000000e-02
  %tmp_78_1 = fmul double %tmp_77_1, 1.000000e+16
  %tmp_79_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_1) nounwind
  %p_int_vy_load_1_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vy_56, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i64 %p_int_vy_3_5, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i64 %p_int_vy_6_5, i4 %i_0_i_i_1)
  %p_int_0_vy_2 = add nsw i64 %tmp_79_1, %p_int_vy_load_1_0_ph
  %p_int_6_vy_10 = select i1 %sel_tmp16, i64 %p_int_vy_6_5, i64 %p_int_0_vy_2
  %p_int_6_vy_11 = select i1 %sel_tmp14, i64 %p_int_vy_6_5, i64 %p_int_6_vy_10
  %p_int_6_vy_12 = select i1 %sel_tmp16, i64 %p_int_0_vy_2, i64 %p_int_vy_3_5
  %p_int_6_vy_13 = select i1 %sel_tmp14, i64 %p_int_vy_3_5, i64 %p_int_6_vy_12
  %p_int_6_vy_57 = select i1 %sel_tmp14, i64 %p_int_0_vy_2, i64 %p_int_6_vy_56
  %p_az_6_load_1 = load double* @p_az_6, align 16
  %p_az_0_load_1 = load double* @p_az_0, align 16
  %p_az_3_load_1 = load double* @p_az_3, align 16
  %sel_tmp18 = select i1 %sel_tmp14, double %p_az_0_load_1, double %p_az_6_load_1
  %p_az_load_1_0_phi = select i1 %sel_tmp16, double %p_az_3_load_1, double %sel_tmp18
  %tmp_81_1 = fmul double %p_az_load_1_0_phi, 1.000000e-02
  %tmp_82_1 = fmul double %tmp_81_1, 1.000000e+16
  %tmp_83_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_1) nounwind
  %p_int_vz_load_1_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vz_56, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i64 %p_int_vz_3_5, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i64 %p_int_vz_6_5, i4 %i_0_i_i_1)
  %p_int_0_vz_2 = add nsw i64 %tmp_83_1, %p_int_vz_load_1_0_ph
  %p_int_6_vz_10 = select i1 %sel_tmp16, i64 %p_int_vz_6_5, i64 %p_int_0_vz_2
  %p_int_6_vz_11 = select i1 %sel_tmp14, i64 %p_int_vz_6_5, i64 %p_int_6_vz_10
  %p_int_6_vz_12 = select i1 %sel_tmp16, i64 %p_int_0_vz_2, i64 %p_int_vz_3_5
  %p_int_6_vz_13 = select i1 %sel_tmp14, i64 %p_int_vz_3_5, i64 %p_int_6_vz_12
  %p_int_6_vz_57 = select i1 %sel_tmp14, i64 %p_int_0_vz_2, i64 %p_int_6_vz_56
  %empty_15 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str7, i32 %tmp_22)
  %i_4_1_0_t = add i4 %i_0_i_i_1, 1
  %p_ax_7_load_1 = load double* @p_ax_7, align 16
  %p_ax_1_load_2 = load double* @p_ax_1, align 16
  %p_ax_4_load_2 = load double* @p_ax_4, align 16
  %sel_tmp19 = select i1 %sel_tmp14, double %p_ax_1_load_2, double %p_ax_7_load_1
  %p_ax_load_1_1_phi = select i1 %sel_tmp16, double %p_ax_4_load_2, double %sel_tmp19
  %tmp_73_1_1 = fmul double %p_ax_load_1_1_phi, 1.000000e-02
  %tmp_74_1_1 = fmul double %tmp_73_1_1, 1.000000e+16
  %tmp_75_1_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_1_1) nounwind
  %p_int_vx_load_1_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_7_5, i64 %p_int_7_vx_56, i64 %p_int_vx_7_5, i64 %p_int_vx_7_5, i64 %p_int_vx_4_5, i64 %p_int_vx_7_5, i64 %p_int_vx_7_5, i64 %p_int_vx_7_5, i64 %p_int_vx_7_5, i64 %p_int_vx_7_5, i64 %p_int_vx_7_5, i64 %p_int_vx_7_5, i64 %p_int_vx_7_5, i64 %p_int_vx_7_5, i64 %p_int_vx_7_5, i64 %p_int_vx_7_5, i4 %i_4_1_0_t)
  %p_int_1_vx_2 = add nsw i64 %tmp_75_1_1, %p_int_vx_load_1_1_ph
  %p_int_7_vx_10 = select i1 %sel_tmp16, i64 %p_int_vx_7_5, i64 %p_int_1_vx_2
  %p_int_7_vx_11 = select i1 %sel_tmp14, i64 %p_int_vx_7_5, i64 %p_int_7_vx_10
  %p_int_7_vx_12 = select i1 %sel_tmp16, i64 %p_int_1_vx_2, i64 %p_int_vx_4_5
  %p_int_7_vx_13 = select i1 %sel_tmp14, i64 %p_int_vx_4_5, i64 %p_int_7_vx_12
  %p_int_7_vx_57 = select i1 %sel_tmp14, i64 %p_int_1_vx_2, i64 %p_int_7_vx_56
  %p_ay_7_load_1 = load double* @p_ay_7, align 8
  %p_ay_1_load_2 = load double* @p_ay_1, align 8
  %p_ay_4_load_2 = load double* @p_ay_4, align 8
  %sel_tmp20 = select i1 %sel_tmp14, double %p_ay_1_load_2, double %p_ay_7_load_1
  %p_ay_load_1_1_phi = select i1 %sel_tmp16, double %p_ay_4_load_2, double %sel_tmp20
  %tmp_77_1_1 = fmul double %p_ay_load_1_1_phi, 1.000000e-02
  %tmp_78_1_1 = fmul double %tmp_77_1_1, 1.000000e+16
  %tmp_79_1_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_1_1) nounwind
  %p_int_vy_load_1_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_7_5, i64 %p_int_7_vy_56, i64 %p_int_vy_7_5, i64 %p_int_vy_7_5, i64 %p_int_vy_4_5, i64 %p_int_vy_7_5, i64 %p_int_vy_7_5, i64 %p_int_vy_7_5, i64 %p_int_vy_7_5, i64 %p_int_vy_7_5, i64 %p_int_vy_7_5, i64 %p_int_vy_7_5, i64 %p_int_vy_7_5, i64 %p_int_vy_7_5, i64 %p_int_vy_7_5, i64 %p_int_vy_7_5, i4 %i_4_1_0_t)
  %p_int_1_vy_2 = add nsw i64 %tmp_79_1_1, %p_int_vy_load_1_1_ph
  %p_int_7_vy_10 = select i1 %sel_tmp16, i64 %p_int_vy_7_5, i64 %p_int_1_vy_2
  %p_int_7_vy_11 = select i1 %sel_tmp14, i64 %p_int_vy_7_5, i64 %p_int_7_vy_10
  %p_int_7_vy_12 = select i1 %sel_tmp16, i64 %p_int_1_vy_2, i64 %p_int_vy_4_5
  %p_int_7_vy_13 = select i1 %sel_tmp14, i64 %p_int_vy_4_5, i64 %p_int_7_vy_12
  %p_int_7_vy_57 = select i1 %sel_tmp14, i64 %p_int_1_vy_2, i64 %p_int_7_vy_56
  %p_az_7_load_1 = load double* @p_az_7, align 16
  %p_az_1_load_2 = load double* @p_az_1, align 16
  %p_az_4_load_2 = load double* @p_az_4, align 16
  %sel_tmp21 = select i1 %sel_tmp14, double %p_az_1_load_2, double %p_az_7_load_1
  %p_az_load_1_1_phi = select i1 %sel_tmp16, double %p_az_4_load_2, double %sel_tmp21
  %tmp_81_1_1 = fmul double %p_az_load_1_1_phi, 1.000000e-02
  %tmp_82_1_1 = fmul double %tmp_81_1_1, 1.000000e+16
  %tmp_83_1_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_1_1) nounwind
  %p_int_vz_load_1_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_7_5, i64 %p_int_7_vz_56, i64 %p_int_vz_7_5, i64 %p_int_vz_7_5, i64 %p_int_vz_4_5, i64 %p_int_vz_7_5, i64 %p_int_vz_7_5, i64 %p_int_vz_7_5, i64 %p_int_vz_7_5, i64 %p_int_vz_7_5, i64 %p_int_vz_7_5, i64 %p_int_vz_7_5, i64 %p_int_vz_7_5, i64 %p_int_vz_7_5, i64 %p_int_vz_7_5, i64 %p_int_vz_7_5, i4 %i_4_1_0_t)
  %p_int_1_vz_2 = add nsw i64 %tmp_83_1_1, %p_int_vz_load_1_1_ph
  %p_int_7_vz_10 = select i1 %sel_tmp16, i64 %p_int_vz_7_5, i64 %p_int_1_vz_2
  %p_int_7_vz_11 = select i1 %sel_tmp14, i64 %p_int_vz_7_5, i64 %p_int_7_vz_10
  %p_int_7_vz_12 = select i1 %sel_tmp16, i64 %p_int_1_vz_2, i64 %p_int_vz_4_5
  %p_int_7_vz_13 = select i1 %sel_tmp14, i64 %p_int_vz_4_5, i64 %p_int_7_vz_12
  %p_int_7_vz_57 = select i1 %sel_tmp14, i64 %p_int_1_vz_2, i64 %p_int_7_vz_56
  %i_4_1_1_t = add i4 %i_0_i_i_1, 2
  %p_ax_8_load_1 = load double* @p_ax_8, align 16
  %p_ax_2_load_2 = load double* @p_ax_2, align 16
  %p_ax_5_load_2 = load double* @p_ax_5, align 16
  %sel_tmp22 = select i1 %sel_tmp14, double %p_ax_2_load_2, double %p_ax_8_load_1
  %p_ax_load_1_2_phi = select i1 %sel_tmp16, double %p_ax_5_load_2, double %sel_tmp22
  %tmp_73_1_2 = fmul double %p_ax_load_1_2_phi, 1.000000e-02
  %tmp_74_1_2 = fmul double %tmp_73_1_2, 1.000000e+16
  %tmp_75_1_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_1_2) nounwind
  %p_int_vx_load_1_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_8_5, i64 %p_int_vx_8_5, i64 %p_int_8_vx_56, i64 %p_int_vx_8_5, i64 %p_int_vx_8_5, i64 %p_int_vx_5_5, i64 %p_int_vx_8_5, i64 %p_int_vx_8_5, i64 %p_int_vx_8_5, i64 %p_int_vx_8_5, i64 %p_int_vx_8_5, i64 %p_int_vx_8_5, i64 %p_int_vx_8_5, i64 %p_int_vx_8_5, i64 %p_int_vx_8_5, i64 %p_int_vx_8_5, i4 %i_4_1_1_t)
  %p_int_2_vx_2 = add nsw i64 %tmp_75_1_2, %p_int_vx_load_1_2_ph
  %p_int_8_vx_10 = select i1 %sel_tmp16, i64 %p_int_vx_8_5, i64 %p_int_2_vx_2
  %p_int_8_vx_11 = select i1 %sel_tmp14, i64 %p_int_vx_8_5, i64 %p_int_8_vx_10
  %p_int_8_vx_12 = select i1 %sel_tmp16, i64 %p_int_2_vx_2, i64 %p_int_vx_5_5
  %p_int_8_vx_13 = select i1 %sel_tmp14, i64 %p_int_vx_5_5, i64 %p_int_8_vx_12
  %p_int_8_vx_57 = select i1 %sel_tmp14, i64 %p_int_2_vx_2, i64 %p_int_8_vx_56
  %p_ay_8_load_1 = load double* @p_ay_8, align 8
  %p_ay_2_load_2 = load double* @p_ay_2, align 8
  %p_ay_5_load_2 = load double* @p_ay_5, align 8
  %sel_tmp23 = select i1 %sel_tmp14, double %p_ay_2_load_2, double %p_ay_8_load_1
  %p_ay_load_1_2_phi = select i1 %sel_tmp16, double %p_ay_5_load_2, double %sel_tmp23
  %tmp_77_1_2 = fmul double %p_ay_load_1_2_phi, 1.000000e-02
  %tmp_78_1_2 = fmul double %tmp_77_1_2, 1.000000e+16
  %tmp_79_1_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_1_2) nounwind
  %p_int_vy_load_1_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_8_5, i64 %p_int_vy_8_5, i64 %p_int_8_vy_56, i64 %p_int_vy_8_5, i64 %p_int_vy_8_5, i64 %p_int_vy_5_5, i64 %p_int_vy_8_5, i64 %p_int_vy_8_5, i64 %p_int_vy_8_5, i64 %p_int_vy_8_5, i64 %p_int_vy_8_5, i64 %p_int_vy_8_5, i64 %p_int_vy_8_5, i64 %p_int_vy_8_5, i64 %p_int_vy_8_5, i64 %p_int_vy_8_5, i4 %i_4_1_1_t)
  %p_int_2_vy_2 = add nsw i64 %tmp_79_1_2, %p_int_vy_load_1_2_ph
  %p_int_8_vy_10 = select i1 %sel_tmp16, i64 %p_int_vy_8_5, i64 %p_int_2_vy_2
  %p_int_8_vy_11 = select i1 %sel_tmp14, i64 %p_int_vy_8_5, i64 %p_int_8_vy_10
  %p_int_8_vy_12 = select i1 %sel_tmp16, i64 %p_int_2_vy_2, i64 %p_int_vy_5_5
  %p_int_8_vy_13 = select i1 %sel_tmp14, i64 %p_int_vy_5_5, i64 %p_int_8_vy_12
  %p_int_8_vy_57 = select i1 %sel_tmp14, i64 %p_int_2_vy_2, i64 %p_int_8_vy_56
  %p_az_8_load_1 = load double* @p_az_8, align 16
  %p_az_2_load_2 = load double* @p_az_2, align 16
  %p_az_5_load_2 = load double* @p_az_5, align 16
  %sel_tmp24 = select i1 %sel_tmp14, double %p_az_2_load_2, double %p_az_8_load_1
  %p_az_load_1_2_phi = select i1 %sel_tmp16, double %p_az_5_load_2, double %sel_tmp24
  %tmp_81_1_2 = fmul double %p_az_load_1_2_phi, 1.000000e-02
  %tmp_82_1_2 = fmul double %tmp_81_1_2, 1.000000e+16
  %tmp_83_1_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_1_2) nounwind
  %p_int_vz_load_1_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_8_5, i64 %p_int_vz_8_5, i64 %p_int_8_vz_56, i64 %p_int_vz_8_5, i64 %p_int_vz_8_5, i64 %p_int_vz_5_5, i64 %p_int_vz_8_5, i64 %p_int_vz_8_5, i64 %p_int_vz_8_5, i64 %p_int_vz_8_5, i64 %p_int_vz_8_5, i64 %p_int_vz_8_5, i64 %p_int_vz_8_5, i64 %p_int_vz_8_5, i64 %p_int_vz_8_5, i64 %p_int_vz_8_5, i4 %i_4_1_1_t)
  %p_int_2_vz_2 = add nsw i64 %tmp_83_1_2, %p_int_vz_load_1_2_ph
  %p_int_8_vz_10 = select i1 %sel_tmp16, i64 %p_int_vz_8_5, i64 %p_int_2_vz_2
  %p_int_8_vz_11 = select i1 %sel_tmp14, i64 %p_int_vz_8_5, i64 %p_int_8_vz_10
  %p_int_8_vz_12 = select i1 %sel_tmp16, i64 %p_int_2_vz_2, i64 %p_int_vz_5_5
  %p_int_8_vz_13 = select i1 %sel_tmp14, i64 %p_int_vz_5_5, i64 %p_int_8_vz_12
  %p_int_8_vz_57 = select i1 %sel_tmp14, i64 %p_int_2_vz_2, i64 %p_int_8_vz_56
  %i_4_1_2 = add i4 %i_0_i_i_1, 3
  br label %3

janus_step.exit.1:                                ; preds = %3
  %drift_ret3 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_2, i64 %p_int_1_x_2, i64 %p_int_2_x_2, i64 %p_int_3_x_2, i64 %p_int_4_x_2, i64 %p_int_5_x_2, i64 %p_int_6_x_2, i64 %p_int_7_x_2, i64 %p_int_8_x_2, i64 %p_int_0_y_2, i64 %p_int_1_y_2, i64 %p_int_2_y_2, i64 %p_int_3_y_2, i64 %p_int_4_y_2, i64 %p_int_5_y_2, i64 %p_int_6_y_2, i64 %p_int_7_y_2, i64 %p_int_8_y_2, i64 %p_int_0_z_2, i64 %p_int_1_z_2, i64 %p_int_2_z_2, i64 %p_int_3_z_2, i64 %p_int_4_z_2, i64 %p_int_5_z_2, i64 %p_int_6_z_2, i64 %p_int_7_z_2, i64 %p_int_8_z_2, i64 %p_int_6_vx_56, i64 %p_int_7_vx_56, i64 %p_int_8_vx_56, i64 %p_int_vx_3_5, i64 %p_int_vx_4_5, i64 %p_int_vx_5_5, i64 %p_int_vx_6_5, i64 %p_int_vx_7_5, i64 %p_int_vx_8_5, i64 %p_int_6_vy_56, i64 %p_int_7_vy_56, i64 %p_int_8_vy_56, i64 %p_int_vy_3_5, i64 %p_int_vy_4_5, i64 %p_int_vy_5_5, i64 %p_int_vy_6_5, i64 %p_int_vy_7_5, i64 %p_int_vy_8_5, i64 %p_int_6_vz_56, i64 %p_int_7_vz_56, i64 %p_int_8_vz_56, i64 %p_int_vz_3_5, i64 %p_int_vz_4_5, i64 %p_int_vz_5_5, i64 %p_int_vz_6_5, i64 %p_int_vz_7_5, i64 %p_int_vz_8_5)
  %p_int_0_x_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 0
  %p_int_1_x_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 1
  %p_int_2_x_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 2
  %p_int_3_x_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 3
  %p_int_4_x_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 4
  %p_int_5_x_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 5
  %p_int_6_x_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 6
  %p_int_7_x_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 7
  %p_int_8_x_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 8
  %p_int_0_y_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 9
  %p_int_1_y_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 10
  %p_int_2_y_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 11
  %p_int_3_y_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 12
  %p_int_4_y_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 13
  %p_int_5_y_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 14
  %p_int_6_y_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 15
  %p_int_7_y_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 16
  %p_int_8_y_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 17
  %p_int_0_z_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 18
  %p_int_1_z_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 19
  %p_int_2_z_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 20
  %p_int_3_z_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 21
  %p_int_4_z_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 22
  %p_int_5_z_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 23
  %p_int_6_z_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 24
  %p_int_7_z_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 25
  %p_int_8_z_3 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret3, 26
  call fastcc void @to_double(i64 %p_int_0_x_4, i64 %p_int_1_x_3, i64 %p_int_2_x_3, i64 %p_int_3_x_4, i64 %p_int_4_x_3, i64 %p_int_5_x_3, i64 %p_int_6_x_4, i64 %p_int_7_x_3, i64 %p_int_8_x_3, i64 %p_int_0_y_3, i64 %p_int_1_y_3, i64 %p_int_2_y_3, i64 %p_int_3_y_3, i64 %p_int_4_y_3, i64 %p_int_5_y_3, i64 %p_int_6_y_3, i64 %p_int_7_y_3, i64 %p_int_8_y_3, i64 %p_int_0_z_3, i64 %p_int_1_z_3, i64 %p_int_2_z_3, i64 %p_int_3_z_3, i64 %p_int_4_z_3, i64 %p_int_5_z_3, i64 %p_int_6_z_3, i64 %p_int_7_z_3, i64 %p_int_8_z_3, i64 %p_int_6_vx_56, i64 %p_int_7_vx_56, i64 %p_int_8_vx_56, i64 %p_int_vx_3_5, i64 %p_int_vx_4_5, i64 %p_int_vx_5_5, i64 %p_int_vx_6_5, i64 %p_int_vx_7_5, i64 %p_int_vx_8_5, i64 %p_int_6_vy_56, i64 %p_int_7_vy_56, i64 %p_int_8_vy_56, i64 %p_int_vy_3_5, i64 %p_int_vy_4_5, i64 %p_int_vy_5_5, i64 %p_int_vy_6_5, i64 %p_int_vy_7_5, i64 %p_int_vy_8_5, i64 %p_int_6_vz_56, i64 %p_int_7_vz_56, i64 %p_int_8_vz_56, i64 %p_int_vz_3_5, i64 %p_int_vz_4_5, i64 %p_int_vz_5_5, i64 %p_int_vz_6_5, i64 %p_int_vz_7_5, i64 %p_int_vz_8_5)
  %empty_16 = call i32 (...)* @_ssdm_op_SpecRegionEnd([7 x i8]* @p_str5, i32 %tmp_19)
  %tmp_21 = call i32 (...)* @_ssdm_op_SpecRegionBegin([7 x i8]* @p_str5)
  %drift_ret4 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_4, i64 %p_int_1_x_3, i64 %p_int_2_x_3, i64 %p_int_3_x_4, i64 %p_int_4_x_3, i64 %p_int_5_x_3, i64 %p_int_6_x_4, i64 %p_int_7_x_3, i64 %p_int_8_x_3, i64 %p_int_0_y_3, i64 %p_int_1_y_3, i64 %p_int_2_y_3, i64 %p_int_3_y_3, i64 %p_int_4_y_3, i64 %p_int_5_y_3, i64 %p_int_6_y_3, i64 %p_int_7_y_3, i64 %p_int_8_y_3, i64 %p_int_0_z_3, i64 %p_int_1_z_3, i64 %p_int_2_z_3, i64 %p_int_3_z_3, i64 %p_int_4_z_3, i64 %p_int_5_z_3, i64 %p_int_6_z_3, i64 %p_int_7_z_3, i64 %p_int_8_z_3, i64 %p_int_6_vx_56, i64 %p_int_7_vx_56, i64 %p_int_8_vx_56, i64 %p_int_vx_3_5, i64 %p_int_vx_4_5, i64 %p_int_vx_5_5, i64 %p_int_vx_6_5, i64 %p_int_vx_7_5, i64 %p_int_vx_8_5, i64 %p_int_6_vy_56, i64 %p_int_7_vy_56, i64 %p_int_8_vy_56, i64 %p_int_vy_3_5, i64 %p_int_vy_4_5, i64 %p_int_vy_5_5, i64 %p_int_vy_6_5, i64 %p_int_vy_7_5, i64 %p_int_vy_8_5, i64 %p_int_6_vz_56, i64 %p_int_7_vz_56, i64 %p_int_8_vz_56, i64 %p_int_vz_3_5, i64 %p_int_vz_4_5, i64 %p_int_vz_5_5, i64 %p_int_vz_6_5, i64 %p_int_vz_7_5, i64 %p_int_vz_8_5)
  %p_int_0_x_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 0
  %p_int_1_x_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 1
  %p_int_2_x_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 2
  %p_int_3_x_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 3
  %p_int_4_x_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 4
  %p_int_5_x_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 5
  %p_int_6_x_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 6
  %p_int_7_x_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 7
  %p_int_8_x_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 8
  %p_int_0_y_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 9
  %p_int_1_y_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 10
  %p_int_2_y_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 11
  %p_int_3_y_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 12
  %p_int_4_y_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 13
  %p_int_5_y_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 14
  %p_int_6_y_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 15
  %p_int_7_y_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 16
  %p_int_8_y_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 17
  %p_int_0_z_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 18
  %p_int_1_z_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 19
  %p_int_2_z_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 20
  %p_int_3_z_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 21
  %p_int_4_z_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 22
  %p_int_5_z_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 23
  %p_int_6_z_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 24
  %p_int_7_z_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 25
  %p_int_8_z_4 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret4, 26
  call fastcc void @to_double(i64 %p_int_0_x_5, i64 %p_int_1_x_4, i64 %p_int_2_x_4, i64 %p_int_3_x_5, i64 %p_int_4_x_4, i64 %p_int_5_x_4, i64 %p_int_6_x_5, i64 %p_int_7_x_4, i64 %p_int_8_x_4, i64 %p_int_0_y_4, i64 %p_int_1_y_4, i64 %p_int_2_y_4, i64 %p_int_3_y_4, i64 %p_int_4_y_4, i64 %p_int_5_y_4, i64 %p_int_6_y_4, i64 %p_int_7_y_4, i64 %p_int_8_y_4, i64 %p_int_0_z_4, i64 %p_int_1_z_4, i64 %p_int_2_z_4, i64 %p_int_3_z_4, i64 %p_int_4_z_4, i64 %p_int_5_z_4, i64 %p_int_6_z_4, i64 %p_int_7_z_4, i64 %p_int_8_z_4, i64 %p_int_6_vx_56, i64 %p_int_7_vx_56, i64 %p_int_8_vx_56, i64 %p_int_vx_3_5, i64 %p_int_vx_4_5, i64 %p_int_vx_5_5, i64 %p_int_vx_6_5, i64 %p_int_vx_7_5, i64 %p_int_vx_8_5, i64 %p_int_6_vy_56, i64 %p_int_7_vy_56, i64 %p_int_8_vy_56, i64 %p_int_vy_3_5, i64 %p_int_vy_4_5, i64 %p_int_vy_5_5, i64 %p_int_vy_6_5, i64 %p_int_vy_7_5, i64 %p_int_vy_8_5, i64 %p_int_6_vz_56, i64 %p_int_7_vz_56, i64 %p_int_8_vz_56, i64 %p_int_vz_3_5, i64 %p_int_vz_4_5, i64 %p_int_vz_5_5, i64 %p_int_vz_6_5, i64 %p_int_vz_7_5, i64 %p_int_vz_8_5)
  call fastcc void @gravity() nounwind
  br label %4

; <label>:4                                       ; preds = %_ifconv510, %janus_step.exit.1
  %p_int_vz_8_7 = phi i64 [ %p_int_vz_8_5, %janus_step.exit.1 ], [ %p_int_8_vz_15, %_ifconv510 ]
  %p_int_vz_7_7 = phi i64 [ %p_int_vz_7_5, %janus_step.exit.1 ], [ %p_int_7_vz_15, %_ifconv510 ]
  %p_int_vz_6_7 = phi i64 [ %p_int_vz_6_5, %janus_step.exit.1 ], [ %p_int_6_vz_15, %_ifconv510 ]
  %p_int_vz_5_7 = phi i64 [ %p_int_vz_5_5, %janus_step.exit.1 ], [ %p_int_8_vz_17, %_ifconv510 ]
  %p_int_vz_4_7 = phi i64 [ %p_int_vz_4_5, %janus_step.exit.1 ], [ %p_int_7_vz_17, %_ifconv510 ]
  %p_int_vz_3_7 = phi i64 [ %p_int_vz_3_5, %janus_step.exit.1 ], [ %p_int_6_vz_17, %_ifconv510 ]
  %p_int_8_vz_59 = phi i64 [ %p_int_8_vz_56, %janus_step.exit.1 ], [ %p_int_8_vz_60, %_ifconv510 ]
  %p_int_7_vz_59 = phi i64 [ %p_int_7_vz_56, %janus_step.exit.1 ], [ %p_int_7_vz_60, %_ifconv510 ]
  %p_int_6_vz_59 = phi i64 [ %p_int_6_vz_56, %janus_step.exit.1 ], [ %p_int_6_vz_60, %_ifconv510 ]
  %p_int_vy_8_7 = phi i64 [ %p_int_vy_8_5, %janus_step.exit.1 ], [ %p_int_8_vy_15, %_ifconv510 ]
  %p_int_vy_7_7 = phi i64 [ %p_int_vy_7_5, %janus_step.exit.1 ], [ %p_int_7_vy_15, %_ifconv510 ]
  %p_int_vy_6_7 = phi i64 [ %p_int_vy_6_5, %janus_step.exit.1 ], [ %p_int_6_vy_15, %_ifconv510 ]
  %p_int_vy_5_7 = phi i64 [ %p_int_vy_5_5, %janus_step.exit.1 ], [ %p_int_8_vy_17, %_ifconv510 ]
  %p_int_vy_4_7 = phi i64 [ %p_int_vy_4_5, %janus_step.exit.1 ], [ %p_int_7_vy_17, %_ifconv510 ]
  %p_int_vy_3_7 = phi i64 [ %p_int_vy_3_5, %janus_step.exit.1 ], [ %p_int_6_vy_17, %_ifconv510 ]
  %p_int_8_vy_59 = phi i64 [ %p_int_8_vy_56, %janus_step.exit.1 ], [ %p_int_8_vy_60, %_ifconv510 ]
  %p_int_7_vy_59 = phi i64 [ %p_int_7_vy_56, %janus_step.exit.1 ], [ %p_int_7_vy_60, %_ifconv510 ]
  %p_int_6_vy_59 = phi i64 [ %p_int_6_vy_56, %janus_step.exit.1 ], [ %p_int_6_vy_60, %_ifconv510 ]
  %p_int_vx_8_7 = phi i64 [ %p_int_vx_8_5, %janus_step.exit.1 ], [ %p_int_8_vx_15, %_ifconv510 ]
  %p_int_vx_7_7 = phi i64 [ %p_int_vx_7_5, %janus_step.exit.1 ], [ %p_int_7_vx_15, %_ifconv510 ]
  %p_int_vx_6_7 = phi i64 [ %p_int_vx_6_5, %janus_step.exit.1 ], [ %p_int_6_vx_15, %_ifconv510 ]
  %p_int_vx_5_7 = phi i64 [ %p_int_vx_5_5, %janus_step.exit.1 ], [ %p_int_8_vx_17, %_ifconv510 ]
  %p_int_vx_4_7 = phi i64 [ %p_int_vx_4_5, %janus_step.exit.1 ], [ %p_int_7_vx_17, %_ifconv510 ]
  %p_int_vx_3_7 = phi i64 [ %p_int_vx_3_5, %janus_step.exit.1 ], [ %p_int_6_vx_17, %_ifconv510 ]
  %p_int_8_vx_59 = phi i64 [ %p_int_8_vx_56, %janus_step.exit.1 ], [ %p_int_8_vx_60, %_ifconv510 ]
  %p_int_7_vx_59 = phi i64 [ %p_int_7_vx_56, %janus_step.exit.1 ], [ %p_int_7_vx_60, %_ifconv510 ]
  %p_int_6_vx_59 = phi i64 [ %p_int_6_vx_56, %janus_step.exit.1 ], [ %p_int_6_vx_60, %_ifconv510 ]
  %i_0_i_i_2 = phi i4 [ 0, %janus_step.exit.1 ], [ %i_4_2_2, %_ifconv510 ]
  %tmp_71_2 = icmp eq i4 %i_0_i_i_2, -7
  br i1 %tmp_71_2, label %janus_step.exit.2, label %_ifconv510

_ifconv510:                                       ; preds = %4
  %empty_17 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_24 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str7)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %p_ax_6_load_2 = load double* @p_ax_6, align 16
  %p_ax_0_load_2 = load double* @p_ax_0, align 16
  %p_ax_3_load_2 = load double* @p_ax_3, align 16
  %sel_tmp25 = icmp eq i4 %i_0_i_i_2, 0
  %sel_tmp26 = select i1 %sel_tmp25, double %p_ax_0_load_2, double %p_ax_6_load_2
  %sel_tmp27 = icmp eq i4 %i_0_i_i_2, 3
  %p_ax_load_2_0_phi = select i1 %sel_tmp27, double %p_ax_3_load_2, double %sel_tmp26
  %tmp_73_2 = fmul double %p_ax_load_2_0_phi, 1.000000e-02
  %tmp_74_2 = fmul double %tmp_73_2, 1.000000e+16
  %tmp_75_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_2) nounwind
  %p_int_vx_load_2_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vx_59, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i64 %p_int_vx_3_7, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i64 %p_int_vx_6_7, i4 %i_0_i_i_2)
  %p_int_0_vx_3 = add nsw i64 %tmp_75_2, %p_int_vx_load_2_0_ph
  %p_int_6_vx_14 = select i1 %sel_tmp27, i64 %p_int_vx_6_7, i64 %p_int_0_vx_3
  %p_int_6_vx_15 = select i1 %sel_tmp25, i64 %p_int_vx_6_7, i64 %p_int_6_vx_14
  %p_int_6_vx_16 = select i1 %sel_tmp27, i64 %p_int_0_vx_3, i64 %p_int_vx_3_7
  %p_int_6_vx_17 = select i1 %sel_tmp25, i64 %p_int_vx_3_7, i64 %p_int_6_vx_16
  %p_int_6_vx_60 = select i1 %sel_tmp25, i64 %p_int_0_vx_3, i64 %p_int_6_vx_59
  %p_ay_6_load_2 = load double* @p_ay_6, align 8
  %p_ay_0_load_2 = load double* @p_ay_0, align 8
  %p_ay_3_load_2 = load double* @p_ay_3, align 8
  %sel_tmp28 = select i1 %sel_tmp25, double %p_ay_0_load_2, double %p_ay_6_load_2
  %p_ay_load_2_0_phi = select i1 %sel_tmp27, double %p_ay_3_load_2, double %sel_tmp28
  %tmp_77_2 = fmul double %p_ay_load_2_0_phi, 1.000000e-02
  %tmp_78_2 = fmul double %tmp_77_2, 1.000000e+16
  %tmp_79_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_2) nounwind
  %p_int_vy_load_2_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vy_59, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i64 %p_int_vy_3_7, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i64 %p_int_vy_6_7, i4 %i_0_i_i_2)
  %p_int_0_vy_3 = add nsw i64 %tmp_79_2, %p_int_vy_load_2_0_ph
  %p_int_6_vy_14 = select i1 %sel_tmp27, i64 %p_int_vy_6_7, i64 %p_int_0_vy_3
  %p_int_6_vy_15 = select i1 %sel_tmp25, i64 %p_int_vy_6_7, i64 %p_int_6_vy_14
  %p_int_6_vy_16 = select i1 %sel_tmp27, i64 %p_int_0_vy_3, i64 %p_int_vy_3_7
  %p_int_6_vy_17 = select i1 %sel_tmp25, i64 %p_int_vy_3_7, i64 %p_int_6_vy_16
  %p_int_6_vy_60 = select i1 %sel_tmp25, i64 %p_int_0_vy_3, i64 %p_int_6_vy_59
  %p_az_6_load_2 = load double* @p_az_6, align 16
  %p_az_0_load_2 = load double* @p_az_0, align 16
  %p_az_3_load_2 = load double* @p_az_3, align 16
  %sel_tmp29 = select i1 %sel_tmp25, double %p_az_0_load_2, double %p_az_6_load_2
  %p_az_load_2_0_phi = select i1 %sel_tmp27, double %p_az_3_load_2, double %sel_tmp29
  %tmp_81_2 = fmul double %p_az_load_2_0_phi, 1.000000e-02
  %tmp_82_2 = fmul double %tmp_81_2, 1.000000e+16
  %tmp_83_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_2) nounwind
  %p_int_vz_load_2_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vz_59, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i64 %p_int_vz_3_7, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i64 %p_int_vz_6_7, i4 %i_0_i_i_2)
  %p_int_0_vz_3 = add nsw i64 %tmp_83_2, %p_int_vz_load_2_0_ph
  %p_int_6_vz_14 = select i1 %sel_tmp27, i64 %p_int_vz_6_7, i64 %p_int_0_vz_3
  %p_int_6_vz_15 = select i1 %sel_tmp25, i64 %p_int_vz_6_7, i64 %p_int_6_vz_14
  %p_int_6_vz_16 = select i1 %sel_tmp27, i64 %p_int_0_vz_3, i64 %p_int_vz_3_7
  %p_int_6_vz_17 = select i1 %sel_tmp25, i64 %p_int_vz_3_7, i64 %p_int_6_vz_16
  %p_int_6_vz_60 = select i1 %sel_tmp25, i64 %p_int_0_vz_3, i64 %p_int_6_vz_59
  %empty_18 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str7, i32 %tmp_24)
  %i_4_2_0_t = add i4 %i_0_i_i_2, 1
  %p_ax_7_load_2 = load double* @p_ax_7, align 16
  %p_ax_1_load_3 = load double* @p_ax_1, align 16
  %p_ax_4_load_3 = load double* @p_ax_4, align 16
  %sel_tmp30 = select i1 %sel_tmp25, double %p_ax_1_load_3, double %p_ax_7_load_2
  %p_ax_load_2_1_phi = select i1 %sel_tmp27, double %p_ax_4_load_3, double %sel_tmp30
  %tmp_73_2_1 = fmul double %p_ax_load_2_1_phi, 1.000000e-02
  %tmp_74_2_1 = fmul double %tmp_73_2_1, 1.000000e+16
  %tmp_75_2_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_2_1) nounwind
  %p_int_vx_load_2_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_7_7, i64 %p_int_7_vx_59, i64 %p_int_vx_7_7, i64 %p_int_vx_7_7, i64 %p_int_vx_4_7, i64 %p_int_vx_7_7, i64 %p_int_vx_7_7, i64 %p_int_vx_7_7, i64 %p_int_vx_7_7, i64 %p_int_vx_7_7, i64 %p_int_vx_7_7, i64 %p_int_vx_7_7, i64 %p_int_vx_7_7, i64 %p_int_vx_7_7, i64 %p_int_vx_7_7, i64 %p_int_vx_7_7, i4 %i_4_2_0_t)
  %p_int_1_vx_3 = add nsw i64 %tmp_75_2_1, %p_int_vx_load_2_1_ph
  %p_int_7_vx_14 = select i1 %sel_tmp27, i64 %p_int_vx_7_7, i64 %p_int_1_vx_3
  %p_int_7_vx_15 = select i1 %sel_tmp25, i64 %p_int_vx_7_7, i64 %p_int_7_vx_14
  %p_int_7_vx_16 = select i1 %sel_tmp27, i64 %p_int_1_vx_3, i64 %p_int_vx_4_7
  %p_int_7_vx_17 = select i1 %sel_tmp25, i64 %p_int_vx_4_7, i64 %p_int_7_vx_16
  %p_int_7_vx_60 = select i1 %sel_tmp25, i64 %p_int_1_vx_3, i64 %p_int_7_vx_59
  %p_ay_7_load_2 = load double* @p_ay_7, align 8
  %p_ay_1_load_3 = load double* @p_ay_1, align 8
  %p_ay_4_load_3 = load double* @p_ay_4, align 8
  %sel_tmp31 = select i1 %sel_tmp25, double %p_ay_1_load_3, double %p_ay_7_load_2
  %p_ay_load_2_1_phi = select i1 %sel_tmp27, double %p_ay_4_load_3, double %sel_tmp31
  %tmp_77_2_1 = fmul double %p_ay_load_2_1_phi, 1.000000e-02
  %tmp_78_2_1 = fmul double %tmp_77_2_1, 1.000000e+16
  %tmp_79_2_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_2_1) nounwind
  %p_int_vy_load_2_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_7_7, i64 %p_int_7_vy_59, i64 %p_int_vy_7_7, i64 %p_int_vy_7_7, i64 %p_int_vy_4_7, i64 %p_int_vy_7_7, i64 %p_int_vy_7_7, i64 %p_int_vy_7_7, i64 %p_int_vy_7_7, i64 %p_int_vy_7_7, i64 %p_int_vy_7_7, i64 %p_int_vy_7_7, i64 %p_int_vy_7_7, i64 %p_int_vy_7_7, i64 %p_int_vy_7_7, i64 %p_int_vy_7_7, i4 %i_4_2_0_t)
  %p_int_1_vy_3 = add nsw i64 %tmp_79_2_1, %p_int_vy_load_2_1_ph
  %p_int_7_vy_14 = select i1 %sel_tmp27, i64 %p_int_vy_7_7, i64 %p_int_1_vy_3
  %p_int_7_vy_15 = select i1 %sel_tmp25, i64 %p_int_vy_7_7, i64 %p_int_7_vy_14
  %p_int_7_vy_16 = select i1 %sel_tmp27, i64 %p_int_1_vy_3, i64 %p_int_vy_4_7
  %p_int_7_vy_17 = select i1 %sel_tmp25, i64 %p_int_vy_4_7, i64 %p_int_7_vy_16
  %p_int_7_vy_60 = select i1 %sel_tmp25, i64 %p_int_1_vy_3, i64 %p_int_7_vy_59
  %p_az_7_load_2 = load double* @p_az_7, align 16
  %p_az_1_load_3 = load double* @p_az_1, align 16
  %p_az_4_load_3 = load double* @p_az_4, align 16
  %sel_tmp32 = select i1 %sel_tmp25, double %p_az_1_load_3, double %p_az_7_load_2
  %p_az_load_2_1_phi = select i1 %sel_tmp27, double %p_az_4_load_3, double %sel_tmp32
  %tmp_81_2_1 = fmul double %p_az_load_2_1_phi, 1.000000e-02
  %tmp_82_2_1 = fmul double %tmp_81_2_1, 1.000000e+16
  %tmp_83_2_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_2_1) nounwind
  %p_int_vz_load_2_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_7_7, i64 %p_int_7_vz_59, i64 %p_int_vz_7_7, i64 %p_int_vz_7_7, i64 %p_int_vz_4_7, i64 %p_int_vz_7_7, i64 %p_int_vz_7_7, i64 %p_int_vz_7_7, i64 %p_int_vz_7_7, i64 %p_int_vz_7_7, i64 %p_int_vz_7_7, i64 %p_int_vz_7_7, i64 %p_int_vz_7_7, i64 %p_int_vz_7_7, i64 %p_int_vz_7_7, i64 %p_int_vz_7_7, i4 %i_4_2_0_t)
  %p_int_1_vz_3 = add nsw i64 %tmp_83_2_1, %p_int_vz_load_2_1_ph
  %p_int_7_vz_14 = select i1 %sel_tmp27, i64 %p_int_vz_7_7, i64 %p_int_1_vz_3
  %p_int_7_vz_15 = select i1 %sel_tmp25, i64 %p_int_vz_7_7, i64 %p_int_7_vz_14
  %p_int_7_vz_16 = select i1 %sel_tmp27, i64 %p_int_1_vz_3, i64 %p_int_vz_4_7
  %p_int_7_vz_17 = select i1 %sel_tmp25, i64 %p_int_vz_4_7, i64 %p_int_7_vz_16
  %p_int_7_vz_60 = select i1 %sel_tmp25, i64 %p_int_1_vz_3, i64 %p_int_7_vz_59
  %i_4_2_1_t = add i4 %i_0_i_i_2, 2
  %p_ax_8_load_2 = load double* @p_ax_8, align 16
  %p_ax_2_load_3 = load double* @p_ax_2, align 16
  %p_ax_5_load_3 = load double* @p_ax_5, align 16
  %sel_tmp33 = select i1 %sel_tmp25, double %p_ax_2_load_3, double %p_ax_8_load_2
  %p_ax_load_2_2_phi = select i1 %sel_tmp27, double %p_ax_5_load_3, double %sel_tmp33
  %tmp_73_2_2 = fmul double %p_ax_load_2_2_phi, 1.000000e-02
  %tmp_74_2_2 = fmul double %tmp_73_2_2, 1.000000e+16
  %tmp_75_2_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_2_2) nounwind
  %p_int_vx_load_2_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_8_7, i64 %p_int_vx_8_7, i64 %p_int_8_vx_59, i64 %p_int_vx_8_7, i64 %p_int_vx_8_7, i64 %p_int_vx_5_7, i64 %p_int_vx_8_7, i64 %p_int_vx_8_7, i64 %p_int_vx_8_7, i64 %p_int_vx_8_7, i64 %p_int_vx_8_7, i64 %p_int_vx_8_7, i64 %p_int_vx_8_7, i64 %p_int_vx_8_7, i64 %p_int_vx_8_7, i64 %p_int_vx_8_7, i4 %i_4_2_1_t)
  %p_int_2_vx_3 = add nsw i64 %tmp_75_2_2, %p_int_vx_load_2_2_ph
  %p_int_8_vx_14 = select i1 %sel_tmp27, i64 %p_int_vx_8_7, i64 %p_int_2_vx_3
  %p_int_8_vx_15 = select i1 %sel_tmp25, i64 %p_int_vx_8_7, i64 %p_int_8_vx_14
  %p_int_8_vx_16 = select i1 %sel_tmp27, i64 %p_int_2_vx_3, i64 %p_int_vx_5_7
  %p_int_8_vx_17 = select i1 %sel_tmp25, i64 %p_int_vx_5_7, i64 %p_int_8_vx_16
  %p_int_8_vx_60 = select i1 %sel_tmp25, i64 %p_int_2_vx_3, i64 %p_int_8_vx_59
  %p_ay_8_load_2 = load double* @p_ay_8, align 8
  %p_ay_2_load_3 = load double* @p_ay_2, align 8
  %p_ay_5_load_3 = load double* @p_ay_5, align 8
  %sel_tmp34 = select i1 %sel_tmp25, double %p_ay_2_load_3, double %p_ay_8_load_2
  %p_ay_load_2_2_phi = select i1 %sel_tmp27, double %p_ay_5_load_3, double %sel_tmp34
  %tmp_77_2_2 = fmul double %p_ay_load_2_2_phi, 1.000000e-02
  %tmp_78_2_2 = fmul double %tmp_77_2_2, 1.000000e+16
  %tmp_79_2_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_2_2) nounwind
  %p_int_vy_load_2_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_8_7, i64 %p_int_vy_8_7, i64 %p_int_8_vy_59, i64 %p_int_vy_8_7, i64 %p_int_vy_8_7, i64 %p_int_vy_5_7, i64 %p_int_vy_8_7, i64 %p_int_vy_8_7, i64 %p_int_vy_8_7, i64 %p_int_vy_8_7, i64 %p_int_vy_8_7, i64 %p_int_vy_8_7, i64 %p_int_vy_8_7, i64 %p_int_vy_8_7, i64 %p_int_vy_8_7, i64 %p_int_vy_8_7, i4 %i_4_2_1_t)
  %p_int_2_vy_3 = add nsw i64 %tmp_79_2_2, %p_int_vy_load_2_2_ph
  %p_int_8_vy_14 = select i1 %sel_tmp27, i64 %p_int_vy_8_7, i64 %p_int_2_vy_3
  %p_int_8_vy_15 = select i1 %sel_tmp25, i64 %p_int_vy_8_7, i64 %p_int_8_vy_14
  %p_int_8_vy_16 = select i1 %sel_tmp27, i64 %p_int_2_vy_3, i64 %p_int_vy_5_7
  %p_int_8_vy_17 = select i1 %sel_tmp25, i64 %p_int_vy_5_7, i64 %p_int_8_vy_16
  %p_int_8_vy_60 = select i1 %sel_tmp25, i64 %p_int_2_vy_3, i64 %p_int_8_vy_59
  %p_az_8_load_2 = load double* @p_az_8, align 16
  %p_az_2_load_3 = load double* @p_az_2, align 16
  %p_az_5_load_3 = load double* @p_az_5, align 16
  %sel_tmp35 = select i1 %sel_tmp25, double %p_az_2_load_3, double %p_az_8_load_2
  %p_az_load_2_2_phi = select i1 %sel_tmp27, double %p_az_5_load_3, double %sel_tmp35
  %tmp_81_2_2 = fmul double %p_az_load_2_2_phi, 1.000000e-02
  %tmp_82_2_2 = fmul double %tmp_81_2_2, 1.000000e+16
  %tmp_83_2_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_2_2) nounwind
  %p_int_vz_load_2_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_8_7, i64 %p_int_vz_8_7, i64 %p_int_8_vz_59, i64 %p_int_vz_8_7, i64 %p_int_vz_8_7, i64 %p_int_vz_5_7, i64 %p_int_vz_8_7, i64 %p_int_vz_8_7, i64 %p_int_vz_8_7, i64 %p_int_vz_8_7, i64 %p_int_vz_8_7, i64 %p_int_vz_8_7, i64 %p_int_vz_8_7, i64 %p_int_vz_8_7, i64 %p_int_vz_8_7, i64 %p_int_vz_8_7, i4 %i_4_2_1_t)
  %p_int_2_vz_3 = add nsw i64 %tmp_83_2_2, %p_int_vz_load_2_2_ph
  %p_int_8_vz_14 = select i1 %sel_tmp27, i64 %p_int_vz_8_7, i64 %p_int_2_vz_3
  %p_int_8_vz_15 = select i1 %sel_tmp25, i64 %p_int_vz_8_7, i64 %p_int_8_vz_14
  %p_int_8_vz_16 = select i1 %sel_tmp27, i64 %p_int_2_vz_3, i64 %p_int_vz_5_7
  %p_int_8_vz_17 = select i1 %sel_tmp25, i64 %p_int_vz_5_7, i64 %p_int_8_vz_16
  %p_int_8_vz_60 = select i1 %sel_tmp25, i64 %p_int_2_vz_3, i64 %p_int_8_vz_59
  %i_4_2_2 = add i4 %i_0_i_i_2, 3
  br label %4

janus_step.exit.2:                                ; preds = %4
  %drift_ret5 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_5, i64 %p_int_1_x_4, i64 %p_int_2_x_4, i64 %p_int_3_x_5, i64 %p_int_4_x_4, i64 %p_int_5_x_4, i64 %p_int_6_x_5, i64 %p_int_7_x_4, i64 %p_int_8_x_4, i64 %p_int_0_y_4, i64 %p_int_1_y_4, i64 %p_int_2_y_4, i64 %p_int_3_y_4, i64 %p_int_4_y_4, i64 %p_int_5_y_4, i64 %p_int_6_y_4, i64 %p_int_7_y_4, i64 %p_int_8_y_4, i64 %p_int_0_z_4, i64 %p_int_1_z_4, i64 %p_int_2_z_4, i64 %p_int_3_z_4, i64 %p_int_4_z_4, i64 %p_int_5_z_4, i64 %p_int_6_z_4, i64 %p_int_7_z_4, i64 %p_int_8_z_4, i64 %p_int_6_vx_59, i64 %p_int_7_vx_59, i64 %p_int_8_vx_59, i64 %p_int_vx_3_7, i64 %p_int_vx_4_7, i64 %p_int_vx_5_7, i64 %p_int_vx_6_7, i64 %p_int_vx_7_7, i64 %p_int_vx_8_7, i64 %p_int_6_vy_59, i64 %p_int_7_vy_59, i64 %p_int_8_vy_59, i64 %p_int_vy_3_7, i64 %p_int_vy_4_7, i64 %p_int_vy_5_7, i64 %p_int_vy_6_7, i64 %p_int_vy_7_7, i64 %p_int_vy_8_7, i64 %p_int_6_vz_59, i64 %p_int_7_vz_59, i64 %p_int_8_vz_59, i64 %p_int_vz_3_7, i64 %p_int_vz_4_7, i64 %p_int_vz_5_7, i64 %p_int_vz_6_7, i64 %p_int_vz_7_7, i64 %p_int_vz_8_7)
  %p_int_0_x_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 0
  %p_int_1_x_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 1
  %p_int_2_x_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 2
  %p_int_3_x_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 3
  %p_int_4_x_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 4
  %p_int_5_x_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 5
  %p_int_6_x_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 6
  %p_int_7_x_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 7
  %p_int_8_x_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 8
  %p_int_0_y_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 9
  %p_int_1_y_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 10
  %p_int_2_y_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 11
  %p_int_3_y_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 12
  %p_int_4_y_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 13
  %p_int_5_y_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 14
  %p_int_6_y_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 15
  %p_int_7_y_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 16
  %p_int_8_y_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 17
  %p_int_0_z_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 18
  %p_int_1_z_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 19
  %p_int_2_z_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 20
  %p_int_3_z_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 21
  %p_int_4_z_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 22
  %p_int_5_z_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 23
  %p_int_6_z_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 24
  %p_int_7_z_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 25
  %p_int_8_z_5 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret5, 26
  call fastcc void @to_double(i64 %p_int_0_x_6, i64 %p_int_1_x_5, i64 %p_int_2_x_5, i64 %p_int_3_x_6, i64 %p_int_4_x_5, i64 %p_int_5_x_5, i64 %p_int_6_x_6, i64 %p_int_7_x_5, i64 %p_int_8_x_5, i64 %p_int_0_y_5, i64 %p_int_1_y_5, i64 %p_int_2_y_5, i64 %p_int_3_y_5, i64 %p_int_4_y_5, i64 %p_int_5_y_5, i64 %p_int_6_y_5, i64 %p_int_7_y_5, i64 %p_int_8_y_5, i64 %p_int_0_z_5, i64 %p_int_1_z_5, i64 %p_int_2_z_5, i64 %p_int_3_z_5, i64 %p_int_4_z_5, i64 %p_int_5_z_5, i64 %p_int_6_z_5, i64 %p_int_7_z_5, i64 %p_int_8_z_5, i64 %p_int_6_vx_59, i64 %p_int_7_vx_59, i64 %p_int_8_vx_59, i64 %p_int_vx_3_7, i64 %p_int_vx_4_7, i64 %p_int_vx_5_7, i64 %p_int_vx_6_7, i64 %p_int_vx_7_7, i64 %p_int_vx_8_7, i64 %p_int_6_vy_59, i64 %p_int_7_vy_59, i64 %p_int_8_vy_59, i64 %p_int_vy_3_7, i64 %p_int_vy_4_7, i64 %p_int_vy_5_7, i64 %p_int_vy_6_7, i64 %p_int_vy_7_7, i64 %p_int_vy_8_7, i64 %p_int_6_vz_59, i64 %p_int_7_vz_59, i64 %p_int_8_vz_59, i64 %p_int_vz_3_7, i64 %p_int_vz_4_7, i64 %p_int_vz_5_7, i64 %p_int_vz_6_7, i64 %p_int_vz_7_7, i64 %p_int_vz_8_7)
  %empty_19 = call i32 (...)* @_ssdm_op_SpecRegionEnd([7 x i8]* @p_str5, i32 %tmp_21)
  %tmp_23 = call i32 (...)* @_ssdm_op_SpecRegionBegin([7 x i8]* @p_str5)
  %drift_ret6 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_6, i64 %p_int_1_x_5, i64 %p_int_2_x_5, i64 %p_int_3_x_6, i64 %p_int_4_x_5, i64 %p_int_5_x_5, i64 %p_int_6_x_6, i64 %p_int_7_x_5, i64 %p_int_8_x_5, i64 %p_int_0_y_5, i64 %p_int_1_y_5, i64 %p_int_2_y_5, i64 %p_int_3_y_5, i64 %p_int_4_y_5, i64 %p_int_5_y_5, i64 %p_int_6_y_5, i64 %p_int_7_y_5, i64 %p_int_8_y_5, i64 %p_int_0_z_5, i64 %p_int_1_z_5, i64 %p_int_2_z_5, i64 %p_int_3_z_5, i64 %p_int_4_z_5, i64 %p_int_5_z_5, i64 %p_int_6_z_5, i64 %p_int_7_z_5, i64 %p_int_8_z_5, i64 %p_int_6_vx_59, i64 %p_int_7_vx_59, i64 %p_int_8_vx_59, i64 %p_int_vx_3_7, i64 %p_int_vx_4_7, i64 %p_int_vx_5_7, i64 %p_int_vx_6_7, i64 %p_int_vx_7_7, i64 %p_int_vx_8_7, i64 %p_int_6_vy_59, i64 %p_int_7_vy_59, i64 %p_int_8_vy_59, i64 %p_int_vy_3_7, i64 %p_int_vy_4_7, i64 %p_int_vy_5_7, i64 %p_int_vy_6_7, i64 %p_int_vy_7_7, i64 %p_int_vy_8_7, i64 %p_int_6_vz_59, i64 %p_int_7_vz_59, i64 %p_int_8_vz_59, i64 %p_int_vz_3_7, i64 %p_int_vz_4_7, i64 %p_int_vz_5_7, i64 %p_int_vz_6_7, i64 %p_int_vz_7_7, i64 %p_int_vz_8_7)
  %p_int_0_x_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 0
  %p_int_1_x_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 1
  %p_int_2_x_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 2
  %p_int_3_x_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 3
  %p_int_4_x_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 4
  %p_int_5_x_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 5
  %p_int_6_x_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 6
  %p_int_7_x_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 7
  %p_int_8_x_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 8
  %p_int_0_y_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 9
  %p_int_1_y_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 10
  %p_int_2_y_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 11
  %p_int_3_y_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 12
  %p_int_4_y_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 13
  %p_int_5_y_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 14
  %p_int_6_y_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 15
  %p_int_7_y_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 16
  %p_int_8_y_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 17
  %p_int_0_z_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 18
  %p_int_1_z_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 19
  %p_int_2_z_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 20
  %p_int_3_z_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 21
  %p_int_4_z_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 22
  %p_int_5_z_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 23
  %p_int_6_z_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 24
  %p_int_7_z_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 25
  %p_int_8_z_6 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret6, 26
  call fastcc void @to_double(i64 %p_int_0_x_7, i64 %p_int_1_x_6, i64 %p_int_2_x_6, i64 %p_int_3_x_7, i64 %p_int_4_x_6, i64 %p_int_5_x_6, i64 %p_int_6_x_7, i64 %p_int_7_x_6, i64 %p_int_8_x_6, i64 %p_int_0_y_6, i64 %p_int_1_y_6, i64 %p_int_2_y_6, i64 %p_int_3_y_6, i64 %p_int_4_y_6, i64 %p_int_5_y_6, i64 %p_int_6_y_6, i64 %p_int_7_y_6, i64 %p_int_8_y_6, i64 %p_int_0_z_6, i64 %p_int_1_z_6, i64 %p_int_2_z_6, i64 %p_int_3_z_6, i64 %p_int_4_z_6, i64 %p_int_5_z_6, i64 %p_int_6_z_6, i64 %p_int_7_z_6, i64 %p_int_8_z_6, i64 %p_int_6_vx_59, i64 %p_int_7_vx_59, i64 %p_int_8_vx_59, i64 %p_int_vx_3_7, i64 %p_int_vx_4_7, i64 %p_int_vx_5_7, i64 %p_int_vx_6_7, i64 %p_int_vx_7_7, i64 %p_int_vx_8_7, i64 %p_int_6_vy_59, i64 %p_int_7_vy_59, i64 %p_int_8_vy_59, i64 %p_int_vy_3_7, i64 %p_int_vy_4_7, i64 %p_int_vy_5_7, i64 %p_int_vy_6_7, i64 %p_int_vy_7_7, i64 %p_int_vy_8_7, i64 %p_int_6_vz_59, i64 %p_int_7_vz_59, i64 %p_int_8_vz_59, i64 %p_int_vz_3_7, i64 %p_int_vz_4_7, i64 %p_int_vz_5_7, i64 %p_int_vz_6_7, i64 %p_int_vz_7_7, i64 %p_int_vz_8_7)
  call fastcc void @gravity() nounwind
  br label %5

; <label>:5                                       ; preds = %_ifconv655, %janus_step.exit.2
  %p_int_vz_8_9 = phi i64 [ %p_int_vz_8_7, %janus_step.exit.2 ], [ %p_int_8_vz_19, %_ifconv655 ]
  %p_int_vz_7_9 = phi i64 [ %p_int_vz_7_7, %janus_step.exit.2 ], [ %p_int_7_vz_19, %_ifconv655 ]
  %p_int_vz_6_9 = phi i64 [ %p_int_vz_6_7, %janus_step.exit.2 ], [ %p_int_6_vz_19, %_ifconv655 ]
  %p_int_vz_5_9 = phi i64 [ %p_int_vz_5_7, %janus_step.exit.2 ], [ %p_int_8_vz_21, %_ifconv655 ]
  %p_int_vz_4_9 = phi i64 [ %p_int_vz_4_7, %janus_step.exit.2 ], [ %p_int_7_vz_21, %_ifconv655 ]
  %p_int_vz_3_9 = phi i64 [ %p_int_vz_3_7, %janus_step.exit.2 ], [ %p_int_6_vz_21, %_ifconv655 ]
  %p_int_8_vz_62 = phi i64 [ %p_int_8_vz_59, %janus_step.exit.2 ], [ %p_int_8_vz_63, %_ifconv655 ]
  %p_int_7_vz_62 = phi i64 [ %p_int_7_vz_59, %janus_step.exit.2 ], [ %p_int_7_vz_63, %_ifconv655 ]
  %p_int_6_vz_62 = phi i64 [ %p_int_6_vz_59, %janus_step.exit.2 ], [ %p_int_6_vz_63, %_ifconv655 ]
  %p_int_vy_8_9 = phi i64 [ %p_int_vy_8_7, %janus_step.exit.2 ], [ %p_int_8_vy_19, %_ifconv655 ]
  %p_int_vy_7_9 = phi i64 [ %p_int_vy_7_7, %janus_step.exit.2 ], [ %p_int_7_vy_19, %_ifconv655 ]
  %p_int_vy_6_9 = phi i64 [ %p_int_vy_6_7, %janus_step.exit.2 ], [ %p_int_6_vy_19, %_ifconv655 ]
  %p_int_vy_5_9 = phi i64 [ %p_int_vy_5_7, %janus_step.exit.2 ], [ %p_int_8_vy_21, %_ifconv655 ]
  %p_int_vy_4_9 = phi i64 [ %p_int_vy_4_7, %janus_step.exit.2 ], [ %p_int_7_vy_21, %_ifconv655 ]
  %p_int_vy_3_9 = phi i64 [ %p_int_vy_3_7, %janus_step.exit.2 ], [ %p_int_6_vy_21, %_ifconv655 ]
  %p_int_8_vy_62 = phi i64 [ %p_int_8_vy_59, %janus_step.exit.2 ], [ %p_int_8_vy_63, %_ifconv655 ]
  %p_int_7_vy_62 = phi i64 [ %p_int_7_vy_59, %janus_step.exit.2 ], [ %p_int_7_vy_63, %_ifconv655 ]
  %p_int_6_vy_62 = phi i64 [ %p_int_6_vy_59, %janus_step.exit.2 ], [ %p_int_6_vy_63, %_ifconv655 ]
  %p_int_vx_8_9 = phi i64 [ %p_int_vx_8_7, %janus_step.exit.2 ], [ %p_int_8_vx_19, %_ifconv655 ]
  %p_int_vx_7_9 = phi i64 [ %p_int_vx_7_7, %janus_step.exit.2 ], [ %p_int_7_vx_19, %_ifconv655 ]
  %p_int_vx_6_9 = phi i64 [ %p_int_vx_6_7, %janus_step.exit.2 ], [ %p_int_6_vx_19, %_ifconv655 ]
  %p_int_vx_5_9 = phi i64 [ %p_int_vx_5_7, %janus_step.exit.2 ], [ %p_int_8_vx_21, %_ifconv655 ]
  %p_int_vx_4_9 = phi i64 [ %p_int_vx_4_7, %janus_step.exit.2 ], [ %p_int_7_vx_21, %_ifconv655 ]
  %p_int_vx_3_9 = phi i64 [ %p_int_vx_3_7, %janus_step.exit.2 ], [ %p_int_6_vx_21, %_ifconv655 ]
  %p_int_8_vx_62 = phi i64 [ %p_int_8_vx_59, %janus_step.exit.2 ], [ %p_int_8_vx_63, %_ifconv655 ]
  %p_int_7_vx_62 = phi i64 [ %p_int_7_vx_59, %janus_step.exit.2 ], [ %p_int_7_vx_63, %_ifconv655 ]
  %p_int_6_vx_62 = phi i64 [ %p_int_6_vx_59, %janus_step.exit.2 ], [ %p_int_6_vx_63, %_ifconv655 ]
  %i_0_i_i_3 = phi i4 [ 0, %janus_step.exit.2 ], [ %i_4_3_2, %_ifconv655 ]
  %tmp_71_3 = icmp eq i4 %i_0_i_i_3, -7
  br i1 %tmp_71_3, label %janus_step.exit.3, label %_ifconv655

_ifconv655:                                       ; preds = %5
  %empty_20 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_25 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str7)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %p_ax_6_load_3 = load double* @p_ax_6, align 16
  %p_ax_0_load_3 = load double* @p_ax_0, align 16
  %p_ax_3_load_3 = load double* @p_ax_3, align 16
  %sel_tmp36 = icmp eq i4 %i_0_i_i_3, 0
  %sel_tmp37 = select i1 %sel_tmp36, double %p_ax_0_load_3, double %p_ax_6_load_3
  %sel_tmp38 = icmp eq i4 %i_0_i_i_3, 3
  %p_ax_load_3_0_phi = select i1 %sel_tmp38, double %p_ax_3_load_3, double %sel_tmp37
  %tmp_73_3 = fmul double %p_ax_load_3_0_phi, 1.000000e-02
  %tmp_74_3 = fmul double %tmp_73_3, 1.000000e+16
  %tmp_75_3 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_3) nounwind
  %p_int_vx_load_3_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vx_62, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i64 %p_int_vx_3_9, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i64 %p_int_vx_6_9, i4 %i_0_i_i_3)
  %p_int_0_vx_4 = add nsw i64 %tmp_75_3, %p_int_vx_load_3_0_ph
  %p_int_6_vx_18 = select i1 %sel_tmp38, i64 %p_int_vx_6_9, i64 %p_int_0_vx_4
  %p_int_6_vx_19 = select i1 %sel_tmp36, i64 %p_int_vx_6_9, i64 %p_int_6_vx_18
  %p_int_6_vx_20 = select i1 %sel_tmp38, i64 %p_int_0_vx_4, i64 %p_int_vx_3_9
  %p_int_6_vx_21 = select i1 %sel_tmp36, i64 %p_int_vx_3_9, i64 %p_int_6_vx_20
  %p_int_6_vx_63 = select i1 %sel_tmp36, i64 %p_int_0_vx_4, i64 %p_int_6_vx_62
  %p_ay_6_load_3 = load double* @p_ay_6, align 8
  %p_ay_0_load_3 = load double* @p_ay_0, align 8
  %p_ay_3_load_3 = load double* @p_ay_3, align 8
  %sel_tmp39 = select i1 %sel_tmp36, double %p_ay_0_load_3, double %p_ay_6_load_3
  %p_ay_load_3_0_phi = select i1 %sel_tmp38, double %p_ay_3_load_3, double %sel_tmp39
  %tmp_77_3 = fmul double %p_ay_load_3_0_phi, 1.000000e-02
  %tmp_78_3 = fmul double %tmp_77_3, 1.000000e+16
  %tmp_79_3 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_3) nounwind
  %p_int_vy_load_3_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vy_62, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i64 %p_int_vy_3_9, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i64 %p_int_vy_6_9, i4 %i_0_i_i_3)
  %p_int_0_vy_4 = add nsw i64 %tmp_79_3, %p_int_vy_load_3_0_ph
  %p_int_6_vy_18 = select i1 %sel_tmp38, i64 %p_int_vy_6_9, i64 %p_int_0_vy_4
  %p_int_6_vy_19 = select i1 %sel_tmp36, i64 %p_int_vy_6_9, i64 %p_int_6_vy_18
  %p_int_6_vy_20 = select i1 %sel_tmp38, i64 %p_int_0_vy_4, i64 %p_int_vy_3_9
  %p_int_6_vy_21 = select i1 %sel_tmp36, i64 %p_int_vy_3_9, i64 %p_int_6_vy_20
  %p_int_6_vy_63 = select i1 %sel_tmp36, i64 %p_int_0_vy_4, i64 %p_int_6_vy_62
  %p_az_6_load_3 = load double* @p_az_6, align 16
  %p_az_0_load_3 = load double* @p_az_0, align 16
  %p_az_3_load_3 = load double* @p_az_3, align 16
  %sel_tmp40 = select i1 %sel_tmp36, double %p_az_0_load_3, double %p_az_6_load_3
  %p_az_load_3_0_phi = select i1 %sel_tmp38, double %p_az_3_load_3, double %sel_tmp40
  %tmp_81_3 = fmul double %p_az_load_3_0_phi, 1.000000e-02
  %tmp_82_3 = fmul double %tmp_81_3, 1.000000e+16
  %tmp_83_3 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_3) nounwind
  %p_int_vz_load_3_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vz_62, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i64 %p_int_vz_3_9, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i64 %p_int_vz_6_9, i4 %i_0_i_i_3)
  %p_int_0_vz_4 = add nsw i64 %tmp_83_3, %p_int_vz_load_3_0_ph
  %p_int_6_vz_18 = select i1 %sel_tmp38, i64 %p_int_vz_6_9, i64 %p_int_0_vz_4
  %p_int_6_vz_19 = select i1 %sel_tmp36, i64 %p_int_vz_6_9, i64 %p_int_6_vz_18
  %p_int_6_vz_20 = select i1 %sel_tmp38, i64 %p_int_0_vz_4, i64 %p_int_vz_3_9
  %p_int_6_vz_21 = select i1 %sel_tmp36, i64 %p_int_vz_3_9, i64 %p_int_6_vz_20
  %p_int_6_vz_63 = select i1 %sel_tmp36, i64 %p_int_0_vz_4, i64 %p_int_6_vz_62
  %empty_21 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str7, i32 %tmp_25)
  %i_4_3_0_t = add i4 %i_0_i_i_3, 1
  %p_ax_7_load_3 = load double* @p_ax_7, align 16
  %p_ax_1_load_4 = load double* @p_ax_1, align 16
  %p_ax_4_load_4 = load double* @p_ax_4, align 16
  %sel_tmp41 = select i1 %sel_tmp36, double %p_ax_1_load_4, double %p_ax_7_load_3
  %p_ax_load_3_1_phi = select i1 %sel_tmp38, double %p_ax_4_load_4, double %sel_tmp41
  %tmp_73_3_1 = fmul double %p_ax_load_3_1_phi, 1.000000e-02
  %tmp_74_3_1 = fmul double %tmp_73_3_1, 1.000000e+16
  %tmp_75_3_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_3_1) nounwind
  %p_int_vx_load_3_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_7_9, i64 %p_int_7_vx_62, i64 %p_int_vx_7_9, i64 %p_int_vx_7_9, i64 %p_int_vx_4_9, i64 %p_int_vx_7_9, i64 %p_int_vx_7_9, i64 %p_int_vx_7_9, i64 %p_int_vx_7_9, i64 %p_int_vx_7_9, i64 %p_int_vx_7_9, i64 %p_int_vx_7_9, i64 %p_int_vx_7_9, i64 %p_int_vx_7_9, i64 %p_int_vx_7_9, i64 %p_int_vx_7_9, i4 %i_4_3_0_t)
  %p_int_1_vx_4 = add nsw i64 %tmp_75_3_1, %p_int_vx_load_3_1_ph
  %p_int_7_vx_18 = select i1 %sel_tmp38, i64 %p_int_vx_7_9, i64 %p_int_1_vx_4
  %p_int_7_vx_19 = select i1 %sel_tmp36, i64 %p_int_vx_7_9, i64 %p_int_7_vx_18
  %p_int_7_vx_20 = select i1 %sel_tmp38, i64 %p_int_1_vx_4, i64 %p_int_vx_4_9
  %p_int_7_vx_21 = select i1 %sel_tmp36, i64 %p_int_vx_4_9, i64 %p_int_7_vx_20
  %p_int_7_vx_63 = select i1 %sel_tmp36, i64 %p_int_1_vx_4, i64 %p_int_7_vx_62
  %p_ay_7_load_3 = load double* @p_ay_7, align 8
  %p_ay_1_load_4 = load double* @p_ay_1, align 8
  %p_ay_4_load_4 = load double* @p_ay_4, align 8
  %sel_tmp42 = select i1 %sel_tmp36, double %p_ay_1_load_4, double %p_ay_7_load_3
  %p_ay_load_3_1_phi = select i1 %sel_tmp38, double %p_ay_4_load_4, double %sel_tmp42
  %tmp_77_3_1 = fmul double %p_ay_load_3_1_phi, 1.000000e-02
  %tmp_78_3_1 = fmul double %tmp_77_3_1, 1.000000e+16
  %tmp_79_3_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_3_1) nounwind
  %p_int_vy_load_3_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_7_9, i64 %p_int_7_vy_62, i64 %p_int_vy_7_9, i64 %p_int_vy_7_9, i64 %p_int_vy_4_9, i64 %p_int_vy_7_9, i64 %p_int_vy_7_9, i64 %p_int_vy_7_9, i64 %p_int_vy_7_9, i64 %p_int_vy_7_9, i64 %p_int_vy_7_9, i64 %p_int_vy_7_9, i64 %p_int_vy_7_9, i64 %p_int_vy_7_9, i64 %p_int_vy_7_9, i64 %p_int_vy_7_9, i4 %i_4_3_0_t)
  %p_int_1_vy_4 = add nsw i64 %tmp_79_3_1, %p_int_vy_load_3_1_ph
  %p_int_7_vy_18 = select i1 %sel_tmp38, i64 %p_int_vy_7_9, i64 %p_int_1_vy_4
  %p_int_7_vy_19 = select i1 %sel_tmp36, i64 %p_int_vy_7_9, i64 %p_int_7_vy_18
  %p_int_7_vy_20 = select i1 %sel_tmp38, i64 %p_int_1_vy_4, i64 %p_int_vy_4_9
  %p_int_7_vy_21 = select i1 %sel_tmp36, i64 %p_int_vy_4_9, i64 %p_int_7_vy_20
  %p_int_7_vy_63 = select i1 %sel_tmp36, i64 %p_int_1_vy_4, i64 %p_int_7_vy_62
  %p_az_7_load_3 = load double* @p_az_7, align 16
  %p_az_1_load_4 = load double* @p_az_1, align 16
  %p_az_4_load_4 = load double* @p_az_4, align 16
  %sel_tmp43 = select i1 %sel_tmp36, double %p_az_1_load_4, double %p_az_7_load_3
  %p_az_load_3_1_phi = select i1 %sel_tmp38, double %p_az_4_load_4, double %sel_tmp43
  %tmp_81_3_1 = fmul double %p_az_load_3_1_phi, 1.000000e-02
  %tmp_82_3_1 = fmul double %tmp_81_3_1, 1.000000e+16
  %tmp_83_3_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_3_1) nounwind
  %p_int_vz_load_3_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_7_9, i64 %p_int_7_vz_62, i64 %p_int_vz_7_9, i64 %p_int_vz_7_9, i64 %p_int_vz_4_9, i64 %p_int_vz_7_9, i64 %p_int_vz_7_9, i64 %p_int_vz_7_9, i64 %p_int_vz_7_9, i64 %p_int_vz_7_9, i64 %p_int_vz_7_9, i64 %p_int_vz_7_9, i64 %p_int_vz_7_9, i64 %p_int_vz_7_9, i64 %p_int_vz_7_9, i64 %p_int_vz_7_9, i4 %i_4_3_0_t)
  %p_int_1_vz_4 = add nsw i64 %tmp_83_3_1, %p_int_vz_load_3_1_ph
  %p_int_7_vz_18 = select i1 %sel_tmp38, i64 %p_int_vz_7_9, i64 %p_int_1_vz_4
  %p_int_7_vz_19 = select i1 %sel_tmp36, i64 %p_int_vz_7_9, i64 %p_int_7_vz_18
  %p_int_7_vz_20 = select i1 %sel_tmp38, i64 %p_int_1_vz_4, i64 %p_int_vz_4_9
  %p_int_7_vz_21 = select i1 %sel_tmp36, i64 %p_int_vz_4_9, i64 %p_int_7_vz_20
  %p_int_7_vz_63 = select i1 %sel_tmp36, i64 %p_int_1_vz_4, i64 %p_int_7_vz_62
  %i_4_3_1_t = add i4 %i_0_i_i_3, 2
  %p_ax_8_load_3 = load double* @p_ax_8, align 16
  %p_ax_2_load_4 = load double* @p_ax_2, align 16
  %p_ax_5_load_4 = load double* @p_ax_5, align 16
  %sel_tmp44 = select i1 %sel_tmp36, double %p_ax_2_load_4, double %p_ax_8_load_3
  %p_ax_load_3_2_phi = select i1 %sel_tmp38, double %p_ax_5_load_4, double %sel_tmp44
  %tmp_73_3_2 = fmul double %p_ax_load_3_2_phi, 1.000000e-02
  %tmp_74_3_2 = fmul double %tmp_73_3_2, 1.000000e+16
  %tmp_75_3_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_3_2) nounwind
  %p_int_vx_load_3_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_8_9, i64 %p_int_vx_8_9, i64 %p_int_8_vx_62, i64 %p_int_vx_8_9, i64 %p_int_vx_8_9, i64 %p_int_vx_5_9, i64 %p_int_vx_8_9, i64 %p_int_vx_8_9, i64 %p_int_vx_8_9, i64 %p_int_vx_8_9, i64 %p_int_vx_8_9, i64 %p_int_vx_8_9, i64 %p_int_vx_8_9, i64 %p_int_vx_8_9, i64 %p_int_vx_8_9, i64 %p_int_vx_8_9, i4 %i_4_3_1_t)
  %p_int_2_vx_4 = add nsw i64 %tmp_75_3_2, %p_int_vx_load_3_2_ph
  %p_int_8_vx_18 = select i1 %sel_tmp38, i64 %p_int_vx_8_9, i64 %p_int_2_vx_4
  %p_int_8_vx_19 = select i1 %sel_tmp36, i64 %p_int_vx_8_9, i64 %p_int_8_vx_18
  %p_int_8_vx_20 = select i1 %sel_tmp38, i64 %p_int_2_vx_4, i64 %p_int_vx_5_9
  %p_int_8_vx_21 = select i1 %sel_tmp36, i64 %p_int_vx_5_9, i64 %p_int_8_vx_20
  %p_int_8_vx_63 = select i1 %sel_tmp36, i64 %p_int_2_vx_4, i64 %p_int_8_vx_62
  %p_ay_8_load_3 = load double* @p_ay_8, align 8
  %p_ay_2_load_4 = load double* @p_ay_2, align 8
  %p_ay_5_load_4 = load double* @p_ay_5, align 8
  %sel_tmp45 = select i1 %sel_tmp36, double %p_ay_2_load_4, double %p_ay_8_load_3
  %p_ay_load_3_2_phi = select i1 %sel_tmp38, double %p_ay_5_load_4, double %sel_tmp45
  %tmp_77_3_2 = fmul double %p_ay_load_3_2_phi, 1.000000e-02
  %tmp_78_3_2 = fmul double %tmp_77_3_2, 1.000000e+16
  %tmp_79_3_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_3_2) nounwind
  %p_int_vy_load_3_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_8_9, i64 %p_int_vy_8_9, i64 %p_int_8_vy_62, i64 %p_int_vy_8_9, i64 %p_int_vy_8_9, i64 %p_int_vy_5_9, i64 %p_int_vy_8_9, i64 %p_int_vy_8_9, i64 %p_int_vy_8_9, i64 %p_int_vy_8_9, i64 %p_int_vy_8_9, i64 %p_int_vy_8_9, i64 %p_int_vy_8_9, i64 %p_int_vy_8_9, i64 %p_int_vy_8_9, i64 %p_int_vy_8_9, i4 %i_4_3_1_t)
  %p_int_2_vy_4 = add nsw i64 %tmp_79_3_2, %p_int_vy_load_3_2_ph
  %p_int_8_vy_18 = select i1 %sel_tmp38, i64 %p_int_vy_8_9, i64 %p_int_2_vy_4
  %p_int_8_vy_19 = select i1 %sel_tmp36, i64 %p_int_vy_8_9, i64 %p_int_8_vy_18
  %p_int_8_vy_20 = select i1 %sel_tmp38, i64 %p_int_2_vy_4, i64 %p_int_vy_5_9
  %p_int_8_vy_21 = select i1 %sel_tmp36, i64 %p_int_vy_5_9, i64 %p_int_8_vy_20
  %p_int_8_vy_63 = select i1 %sel_tmp36, i64 %p_int_2_vy_4, i64 %p_int_8_vy_62
  %p_az_8_load_3 = load double* @p_az_8, align 16
  %p_az_2_load_4 = load double* @p_az_2, align 16
  %p_az_5_load_4 = load double* @p_az_5, align 16
  %sel_tmp46 = select i1 %sel_tmp36, double %p_az_2_load_4, double %p_az_8_load_3
  %p_az_load_3_2_phi = select i1 %sel_tmp38, double %p_az_5_load_4, double %sel_tmp46
  %tmp_81_3_2 = fmul double %p_az_load_3_2_phi, 1.000000e-02
  %tmp_82_3_2 = fmul double %tmp_81_3_2, 1.000000e+16
  %tmp_83_3_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_3_2) nounwind
  %p_int_vz_load_3_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_8_9, i64 %p_int_vz_8_9, i64 %p_int_8_vz_62, i64 %p_int_vz_8_9, i64 %p_int_vz_8_9, i64 %p_int_vz_5_9, i64 %p_int_vz_8_9, i64 %p_int_vz_8_9, i64 %p_int_vz_8_9, i64 %p_int_vz_8_9, i64 %p_int_vz_8_9, i64 %p_int_vz_8_9, i64 %p_int_vz_8_9, i64 %p_int_vz_8_9, i64 %p_int_vz_8_9, i64 %p_int_vz_8_9, i4 %i_4_3_1_t)
  %p_int_2_vz_4 = add nsw i64 %tmp_83_3_2, %p_int_vz_load_3_2_ph
  %p_int_8_vz_18 = select i1 %sel_tmp38, i64 %p_int_vz_8_9, i64 %p_int_2_vz_4
  %p_int_8_vz_19 = select i1 %sel_tmp36, i64 %p_int_vz_8_9, i64 %p_int_8_vz_18
  %p_int_8_vz_20 = select i1 %sel_tmp38, i64 %p_int_2_vz_4, i64 %p_int_vz_5_9
  %p_int_8_vz_21 = select i1 %sel_tmp36, i64 %p_int_vz_5_9, i64 %p_int_8_vz_20
  %p_int_8_vz_63 = select i1 %sel_tmp36, i64 %p_int_2_vz_4, i64 %p_int_8_vz_62
  %i_4_3_2 = add i4 %i_0_i_i_3, 3
  br label %5

janus_step.exit.3:                                ; preds = %5
  %drift_ret7 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_7, i64 %p_int_1_x_6, i64 %p_int_2_x_6, i64 %p_int_3_x_7, i64 %p_int_4_x_6, i64 %p_int_5_x_6, i64 %p_int_6_x_7, i64 %p_int_7_x_6, i64 %p_int_8_x_6, i64 %p_int_0_y_6, i64 %p_int_1_y_6, i64 %p_int_2_y_6, i64 %p_int_3_y_6, i64 %p_int_4_y_6, i64 %p_int_5_y_6, i64 %p_int_6_y_6, i64 %p_int_7_y_6, i64 %p_int_8_y_6, i64 %p_int_0_z_6, i64 %p_int_1_z_6, i64 %p_int_2_z_6, i64 %p_int_3_z_6, i64 %p_int_4_z_6, i64 %p_int_5_z_6, i64 %p_int_6_z_6, i64 %p_int_7_z_6, i64 %p_int_8_z_6, i64 %p_int_6_vx_62, i64 %p_int_7_vx_62, i64 %p_int_8_vx_62, i64 %p_int_vx_3_9, i64 %p_int_vx_4_9, i64 %p_int_vx_5_9, i64 %p_int_vx_6_9, i64 %p_int_vx_7_9, i64 %p_int_vx_8_9, i64 %p_int_6_vy_62, i64 %p_int_7_vy_62, i64 %p_int_8_vy_62, i64 %p_int_vy_3_9, i64 %p_int_vy_4_9, i64 %p_int_vy_5_9, i64 %p_int_vy_6_9, i64 %p_int_vy_7_9, i64 %p_int_vy_8_9, i64 %p_int_6_vz_62, i64 %p_int_7_vz_62, i64 %p_int_8_vz_62, i64 %p_int_vz_3_9, i64 %p_int_vz_4_9, i64 %p_int_vz_5_9, i64 %p_int_vz_6_9, i64 %p_int_vz_7_9, i64 %p_int_vz_8_9)
  %p_int_0_x_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 0
  %p_int_1_x_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 1
  %p_int_2_x_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 2
  %p_int_3_x_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 3
  %p_int_4_x_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 4
  %p_int_5_x_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 5
  %p_int_6_x_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 6
  %p_int_7_x_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 7
  %p_int_8_x_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 8
  %p_int_0_y_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 9
  %p_int_1_y_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 10
  %p_int_2_y_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 11
  %p_int_3_y_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 12
  %p_int_4_y_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 13
  %p_int_5_y_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 14
  %p_int_6_y_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 15
  %p_int_7_y_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 16
  %p_int_8_y_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 17
  %p_int_0_z_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 18
  %p_int_1_z_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 19
  %p_int_2_z_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 20
  %p_int_3_z_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 21
  %p_int_4_z_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 22
  %p_int_5_z_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 23
  %p_int_6_z_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 24
  %p_int_7_z_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 25
  %p_int_8_z_7 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret7, 26
  call fastcc void @to_double(i64 %p_int_0_x_8, i64 %p_int_1_x_7, i64 %p_int_2_x_7, i64 %p_int_3_x_8, i64 %p_int_4_x_7, i64 %p_int_5_x_7, i64 %p_int_6_x_8, i64 %p_int_7_x_7, i64 %p_int_8_x_7, i64 %p_int_0_y_8, i64 %p_int_1_y_7, i64 %p_int_2_y_7, i64 %p_int_3_y_8, i64 %p_int_4_y_7, i64 %p_int_5_y_7, i64 %p_int_6_y_8, i64 %p_int_7_y_7, i64 %p_int_8_y_7, i64 %p_int_0_z_7, i64 %p_int_1_z_7, i64 %p_int_2_z_7, i64 %p_int_3_z_7, i64 %p_int_4_z_7, i64 %p_int_5_z_7, i64 %p_int_6_z_7, i64 %p_int_7_z_7, i64 %p_int_8_z_7, i64 %p_int_6_vx_62, i64 %p_int_7_vx_62, i64 %p_int_8_vx_62, i64 %p_int_vx_3_9, i64 %p_int_vx_4_9, i64 %p_int_vx_5_9, i64 %p_int_vx_6_9, i64 %p_int_vx_7_9, i64 %p_int_vx_8_9, i64 %p_int_6_vy_62, i64 %p_int_7_vy_62, i64 %p_int_8_vy_62, i64 %p_int_vy_3_9, i64 %p_int_vy_4_9, i64 %p_int_vy_5_9, i64 %p_int_vy_6_9, i64 %p_int_vy_7_9, i64 %p_int_vy_8_9, i64 %p_int_6_vz_62, i64 %p_int_7_vz_62, i64 %p_int_8_vz_62, i64 %p_int_vz_3_9, i64 %p_int_vz_4_9, i64 %p_int_vz_5_9, i64 %p_int_vz_6_9, i64 %p_int_vz_7_9, i64 %p_int_vz_8_9)
  %empty_22 = call i32 (...)* @_ssdm_op_SpecRegionEnd([7 x i8]* @p_str5, i32 %tmp_23)
  %exitcond_4 = icmp eq i32 %t, 6280
  br i1 %exitcond_4, label %burst.wr.header.preheader, label %7

burst.wr.header.preheader:                        ; preds = %janus_step.exit.3
  %result_x_wr_req = call i1 @_ssdm_op_WriteReq.m_axi.doubleP(double* %result_x, i32 6)
  %result_y_wr_req = call i1 @_ssdm_op_WriteReq.m_axi.doubleP(double* %result_y, i32 6)
  %result_z_wr_req = call i1 @_ssdm_op_WriteReq.m_axi.doubleP(double* %result_z, i32 6)
  %result_vx_wr_req = call i1 @_ssdm_op_WriteReq.m_axi.doubleP(double* %result_vx, i32 6)
  %result_vy_wr_req = call i1 @_ssdm_op_WriteReq.m_axi.doubleP(double* %result_vy, i32 6)
  %result_vz_wr_req = call i1 @_ssdm_op_WriteReq.m_axi.doubleP(double* %result_vz, i32 6)
  %result_ax_wr_req = call i1 @_ssdm_op_WriteReq.m_axi.doubleP(double* %result_ax, i32 6)
  %result_ay_wr_req = call i1 @_ssdm_op_WriteReq.m_axi.doubleP(double* %result_ay, i32 6)
  %result_az_wr_req = call i1 @_ssdm_op_WriteReq.m_axi.doubleP(double* %result_az, i32 6)
  %result_m_wr_req = call i1 @_ssdm_op_WriteReq.m_axi.doubleP(double* %result_m, i32 6)
  br label %burst.wr.header

; <label>:6                                       ; preds = %7, %_ifconv800
  %p_int_vz_8_s = phi i64 [ %p_int_vz_8_9, %7 ], [ %p_int_8_vz_23, %_ifconv800 ]
  %p_int_vz_7_s = phi i64 [ %p_int_vz_7_9, %7 ], [ %p_int_7_vz_23, %_ifconv800 ]
  %p_int_vz_6_s = phi i64 [ %p_int_vz_6_9, %7 ], [ %p_int_6_vz_23, %_ifconv800 ]
  %p_int_vz_5_s = phi i64 [ %p_int_vz_5_9, %7 ], [ %p_int_8_vz_25, %_ifconv800 ]
  %p_int_vz_4_s = phi i64 [ %p_int_vz_4_9, %7 ], [ %p_int_7_vz_25, %_ifconv800 ]
  %p_int_vz_3_s = phi i64 [ %p_int_vz_3_9, %7 ], [ %p_int_6_vz_25, %_ifconv800 ]
  %p_int_8_vz_65 = phi i64 [ %p_int_8_vz_62, %7 ], [ %p_int_8_vz_66, %_ifconv800 ]
  %p_int_7_vz_65 = phi i64 [ %p_int_7_vz_62, %7 ], [ %p_int_7_vz_66, %_ifconv800 ]
  %p_int_6_vz_65 = phi i64 [ %p_int_6_vz_62, %7 ], [ %p_int_6_vz_66, %_ifconv800 ]
  %p_int_vy_8_s = phi i64 [ %p_int_vy_8_9, %7 ], [ %p_int_8_vy_23, %_ifconv800 ]
  %p_int_vy_7_s = phi i64 [ %p_int_vy_7_9, %7 ], [ %p_int_7_vy_23, %_ifconv800 ]
  %p_int_vy_6_s = phi i64 [ %p_int_vy_6_9, %7 ], [ %p_int_6_vy_23, %_ifconv800 ]
  %p_int_vy_5_s = phi i64 [ %p_int_vy_5_9, %7 ], [ %p_int_8_vy_25, %_ifconv800 ]
  %p_int_vy_4_s = phi i64 [ %p_int_vy_4_9, %7 ], [ %p_int_7_vy_25, %_ifconv800 ]
  %p_int_vy_3_s = phi i64 [ %p_int_vy_3_9, %7 ], [ %p_int_6_vy_25, %_ifconv800 ]
  %p_int_8_vy_65 = phi i64 [ %p_int_8_vy_62, %7 ], [ %p_int_8_vy_66, %_ifconv800 ]
  %p_int_7_vy_65 = phi i64 [ %p_int_7_vy_62, %7 ], [ %p_int_7_vy_66, %_ifconv800 ]
  %p_int_6_vy_65 = phi i64 [ %p_int_6_vy_62, %7 ], [ %p_int_6_vy_66, %_ifconv800 ]
  %p_int_vx_8_s = phi i64 [ %p_int_vx_8_9, %7 ], [ %p_int_8_vx_23, %_ifconv800 ]
  %p_int_vx_7_s = phi i64 [ %p_int_vx_7_9, %7 ], [ %p_int_7_vx_23, %_ifconv800 ]
  %p_int_vx_6_s = phi i64 [ %p_int_vx_6_9, %7 ], [ %p_int_6_vx_23, %_ifconv800 ]
  %p_int_vx_5_s = phi i64 [ %p_int_vx_5_9, %7 ], [ %p_int_8_vx_25, %_ifconv800 ]
  %p_int_vx_4_s = phi i64 [ %p_int_vx_4_9, %7 ], [ %p_int_7_vx_25, %_ifconv800 ]
  %p_int_vx_3_s = phi i64 [ %p_int_vx_3_9, %7 ], [ %p_int_6_vx_25, %_ifconv800 ]
  %p_int_8_vx_65 = phi i64 [ %p_int_8_vx_62, %7 ], [ %p_int_8_vx_66, %_ifconv800 ]
  %p_int_7_vx_65 = phi i64 [ %p_int_7_vx_62, %7 ], [ %p_int_7_vx_66, %_ifconv800 ]
  %p_int_6_vx_65 = phi i64 [ %p_int_6_vx_62, %7 ], [ %p_int_6_vx_66, %_ifconv800 ]
  %i_0_i_i_4 = phi i4 [ 0, %7 ], [ %i_4_4_2, %_ifconv800 ]
  %tmp_71_4 = icmp eq i4 %i_0_i_i_4, -7
  br i1 %tmp_71_4, label %janus_step.exit.4, label %_ifconv800

_ifconv800:                                       ; preds = %6
  %empty_23 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_29 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str7)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %p_ax_6_load_4 = load double* @p_ax_6, align 16
  %p_ax_0_load_4 = load double* @p_ax_0, align 16
  %p_ax_3_load_4 = load double* @p_ax_3, align 16
  %sel_tmp92 = icmp eq i4 %i_0_i_i_4, 0
  %sel_tmp93 = select i1 %sel_tmp92, double %p_ax_0_load_4, double %p_ax_6_load_4
  %sel_tmp94 = icmp eq i4 %i_0_i_i_4, 3
  %p_ax_load_4_0_phi = select i1 %sel_tmp94, double %p_ax_3_load_4, double %sel_tmp93
  %tmp_73_4 = fmul double %p_ax_load_4_0_phi, 1.000000e-02
  %tmp_74_4 = fmul double %tmp_73_4, 1.000000e+16
  %tmp_75_4 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_4) nounwind
  %p_int_vx_load_4_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vx_65, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i64 %p_int_vx_3_s, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i64 %p_int_vx_6_s, i4 %i_0_i_i_4)
  %p_int_0_vx_5 = add nsw i64 %tmp_75_4, %p_int_vx_load_4_0_ph
  %p_int_6_vx_22 = select i1 %sel_tmp94, i64 %p_int_vx_6_s, i64 %p_int_0_vx_5
  %p_int_6_vx_23 = select i1 %sel_tmp92, i64 %p_int_vx_6_s, i64 %p_int_6_vx_22
  %p_int_6_vx_24 = select i1 %sel_tmp94, i64 %p_int_0_vx_5, i64 %p_int_vx_3_s
  %p_int_6_vx_25 = select i1 %sel_tmp92, i64 %p_int_vx_3_s, i64 %p_int_6_vx_24
  %p_int_6_vx_66 = select i1 %sel_tmp92, i64 %p_int_0_vx_5, i64 %p_int_6_vx_65
  %p_ay_6_load_4 = load double* @p_ay_6, align 8
  %p_ay_0_load_4 = load double* @p_ay_0, align 8
  %p_ay_3_load_4 = load double* @p_ay_3, align 8
  %sel_tmp95 = select i1 %sel_tmp92, double %p_ay_0_load_4, double %p_ay_6_load_4
  %p_ay_load_4_0_phi = select i1 %sel_tmp94, double %p_ay_3_load_4, double %sel_tmp95
  %tmp_77_4 = fmul double %p_ay_load_4_0_phi, 1.000000e-02
  %tmp_78_4 = fmul double %tmp_77_4, 1.000000e+16
  %tmp_79_4 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_4) nounwind
  %p_int_vy_load_4_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vy_65, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i64 %p_int_vy_3_s, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i64 %p_int_vy_6_s, i4 %i_0_i_i_4)
  %p_int_0_vy_5 = add nsw i64 %tmp_79_4, %p_int_vy_load_4_0_ph
  %p_int_6_vy_22 = select i1 %sel_tmp94, i64 %p_int_vy_6_s, i64 %p_int_0_vy_5
  %p_int_6_vy_23 = select i1 %sel_tmp92, i64 %p_int_vy_6_s, i64 %p_int_6_vy_22
  %p_int_6_vy_24 = select i1 %sel_tmp94, i64 %p_int_0_vy_5, i64 %p_int_vy_3_s
  %p_int_6_vy_25 = select i1 %sel_tmp92, i64 %p_int_vy_3_s, i64 %p_int_6_vy_24
  %p_int_6_vy_66 = select i1 %sel_tmp92, i64 %p_int_0_vy_5, i64 %p_int_6_vy_65
  %p_az_6_load_4 = load double* @p_az_6, align 16
  %p_az_0_load_4 = load double* @p_az_0, align 16
  %p_az_3_load_4 = load double* @p_az_3, align 16
  %sel_tmp96 = select i1 %sel_tmp92, double %p_az_0_load_4, double %p_az_6_load_4
  %p_az_load_4_0_phi = select i1 %sel_tmp94, double %p_az_3_load_4, double %sel_tmp96
  %tmp_81_4 = fmul double %p_az_load_4_0_phi, 1.000000e-02
  %tmp_82_4 = fmul double %tmp_81_4, 1.000000e+16
  %tmp_83_4 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_4) nounwind
  %p_int_vz_load_4_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vz_65, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i64 %p_int_vz_3_s, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i64 %p_int_vz_6_s, i4 %i_0_i_i_4)
  %p_int_0_vz_5 = add nsw i64 %tmp_83_4, %p_int_vz_load_4_0_ph
  %p_int_6_vz_22 = select i1 %sel_tmp94, i64 %p_int_vz_6_s, i64 %p_int_0_vz_5
  %p_int_6_vz_23 = select i1 %sel_tmp92, i64 %p_int_vz_6_s, i64 %p_int_6_vz_22
  %p_int_6_vz_24 = select i1 %sel_tmp94, i64 %p_int_0_vz_5, i64 %p_int_vz_3_s
  %p_int_6_vz_25 = select i1 %sel_tmp92, i64 %p_int_vz_3_s, i64 %p_int_6_vz_24
  %p_int_6_vz_66 = select i1 %sel_tmp92, i64 %p_int_0_vz_5, i64 %p_int_6_vz_65
  %empty_24 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str7, i32 %tmp_29)
  %i_4_4_0_t = add i4 %i_0_i_i_4, 1
  %p_ax_7_load_4 = load double* @p_ax_7, align 16
  %p_ax_1_load_5 = load double* @p_ax_1, align 16
  %p_ax_4_load_5 = load double* @p_ax_4, align 16
  %sel_tmp97 = select i1 %sel_tmp92, double %p_ax_1_load_5, double %p_ax_7_load_4
  %p_ax_load_4_1_phi = select i1 %sel_tmp94, double %p_ax_4_load_5, double %sel_tmp97
  %tmp_73_4_1 = fmul double %p_ax_load_4_1_phi, 1.000000e-02
  %tmp_74_4_1 = fmul double %tmp_73_4_1, 1.000000e+16
  %tmp_75_4_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_4_1) nounwind
  %p_int_vx_load_4_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_7_s, i64 %p_int_7_vx_65, i64 %p_int_vx_7_s, i64 %p_int_vx_7_s, i64 %p_int_vx_4_s, i64 %p_int_vx_7_s, i64 %p_int_vx_7_s, i64 %p_int_vx_7_s, i64 %p_int_vx_7_s, i64 %p_int_vx_7_s, i64 %p_int_vx_7_s, i64 %p_int_vx_7_s, i64 %p_int_vx_7_s, i64 %p_int_vx_7_s, i64 %p_int_vx_7_s, i64 %p_int_vx_7_s, i4 %i_4_4_0_t)
  %p_int_1_vx_5 = add nsw i64 %tmp_75_4_1, %p_int_vx_load_4_1_ph
  %p_int_7_vx_22 = select i1 %sel_tmp94, i64 %p_int_vx_7_s, i64 %p_int_1_vx_5
  %p_int_7_vx_23 = select i1 %sel_tmp92, i64 %p_int_vx_7_s, i64 %p_int_7_vx_22
  %p_int_7_vx_24 = select i1 %sel_tmp94, i64 %p_int_1_vx_5, i64 %p_int_vx_4_s
  %p_int_7_vx_25 = select i1 %sel_tmp92, i64 %p_int_vx_4_s, i64 %p_int_7_vx_24
  %p_int_7_vx_66 = select i1 %sel_tmp92, i64 %p_int_1_vx_5, i64 %p_int_7_vx_65
  %p_ay_7_load_4 = load double* @p_ay_7, align 8
  %p_ay_1_load_5 = load double* @p_ay_1, align 8
  %p_ay_4_load_5 = load double* @p_ay_4, align 8
  %sel_tmp98 = select i1 %sel_tmp92, double %p_ay_1_load_5, double %p_ay_7_load_4
  %p_ay_load_4_1_phi = select i1 %sel_tmp94, double %p_ay_4_load_5, double %sel_tmp98
  %tmp_77_4_1 = fmul double %p_ay_load_4_1_phi, 1.000000e-02
  %tmp_78_4_1 = fmul double %tmp_77_4_1, 1.000000e+16
  %tmp_79_4_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_4_1) nounwind
  %p_int_vy_load_4_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_7_s, i64 %p_int_7_vy_65, i64 %p_int_vy_7_s, i64 %p_int_vy_7_s, i64 %p_int_vy_4_s, i64 %p_int_vy_7_s, i64 %p_int_vy_7_s, i64 %p_int_vy_7_s, i64 %p_int_vy_7_s, i64 %p_int_vy_7_s, i64 %p_int_vy_7_s, i64 %p_int_vy_7_s, i64 %p_int_vy_7_s, i64 %p_int_vy_7_s, i64 %p_int_vy_7_s, i64 %p_int_vy_7_s, i4 %i_4_4_0_t)
  %p_int_1_vy_5 = add nsw i64 %tmp_79_4_1, %p_int_vy_load_4_1_ph
  %p_int_7_vy_22 = select i1 %sel_tmp94, i64 %p_int_vy_7_s, i64 %p_int_1_vy_5
  %p_int_7_vy_23 = select i1 %sel_tmp92, i64 %p_int_vy_7_s, i64 %p_int_7_vy_22
  %p_int_7_vy_24 = select i1 %sel_tmp94, i64 %p_int_1_vy_5, i64 %p_int_vy_4_s
  %p_int_7_vy_25 = select i1 %sel_tmp92, i64 %p_int_vy_4_s, i64 %p_int_7_vy_24
  %p_int_7_vy_66 = select i1 %sel_tmp92, i64 %p_int_1_vy_5, i64 %p_int_7_vy_65
  %p_az_7_load_4 = load double* @p_az_7, align 16
  %p_az_1_load_5 = load double* @p_az_1, align 16
  %p_az_4_load_5 = load double* @p_az_4, align 16
  %sel_tmp99 = select i1 %sel_tmp92, double %p_az_1_load_5, double %p_az_7_load_4
  %p_az_load_4_1_phi = select i1 %sel_tmp94, double %p_az_4_load_5, double %sel_tmp99
  %tmp_81_4_1 = fmul double %p_az_load_4_1_phi, 1.000000e-02
  %tmp_82_4_1 = fmul double %tmp_81_4_1, 1.000000e+16
  %tmp_83_4_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_4_1) nounwind
  %p_int_vz_load_4_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_7_s, i64 %p_int_7_vz_65, i64 %p_int_vz_7_s, i64 %p_int_vz_7_s, i64 %p_int_vz_4_s, i64 %p_int_vz_7_s, i64 %p_int_vz_7_s, i64 %p_int_vz_7_s, i64 %p_int_vz_7_s, i64 %p_int_vz_7_s, i64 %p_int_vz_7_s, i64 %p_int_vz_7_s, i64 %p_int_vz_7_s, i64 %p_int_vz_7_s, i64 %p_int_vz_7_s, i64 %p_int_vz_7_s, i4 %i_4_4_0_t)
  %p_int_1_vz_5 = add nsw i64 %tmp_83_4_1, %p_int_vz_load_4_1_ph
  %p_int_7_vz_22 = select i1 %sel_tmp94, i64 %p_int_vz_7_s, i64 %p_int_1_vz_5
  %p_int_7_vz_23 = select i1 %sel_tmp92, i64 %p_int_vz_7_s, i64 %p_int_7_vz_22
  %p_int_7_vz_24 = select i1 %sel_tmp94, i64 %p_int_1_vz_5, i64 %p_int_vz_4_s
  %p_int_7_vz_25 = select i1 %sel_tmp92, i64 %p_int_vz_4_s, i64 %p_int_7_vz_24
  %p_int_7_vz_66 = select i1 %sel_tmp92, i64 %p_int_1_vz_5, i64 %p_int_7_vz_65
  %i_4_4_1_t = add i4 %i_0_i_i_4, 2
  %p_ax_8_load_4 = load double* @p_ax_8, align 16
  %p_ax_2_load_5 = load double* @p_ax_2, align 16
  %p_ax_5_load_5 = load double* @p_ax_5, align 16
  %sel_tmp100 = select i1 %sel_tmp92, double %p_ax_2_load_5, double %p_ax_8_load_4
  %p_ax_load_4_2_phi = select i1 %sel_tmp94, double %p_ax_5_load_5, double %sel_tmp100
  %tmp_73_4_2 = fmul double %p_ax_load_4_2_phi, 1.000000e-02
  %tmp_74_4_2 = fmul double %tmp_73_4_2, 1.000000e+16
  %tmp_75_4_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_4_2) nounwind
  %p_int_vx_load_4_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_8_s, i64 %p_int_vx_8_s, i64 %p_int_8_vx_65, i64 %p_int_vx_8_s, i64 %p_int_vx_8_s, i64 %p_int_vx_5_s, i64 %p_int_vx_8_s, i64 %p_int_vx_8_s, i64 %p_int_vx_8_s, i64 %p_int_vx_8_s, i64 %p_int_vx_8_s, i64 %p_int_vx_8_s, i64 %p_int_vx_8_s, i64 %p_int_vx_8_s, i64 %p_int_vx_8_s, i64 %p_int_vx_8_s, i4 %i_4_4_1_t)
  %p_int_2_vx_5 = add nsw i64 %tmp_75_4_2, %p_int_vx_load_4_2_ph
  %p_int_8_vx_22 = select i1 %sel_tmp94, i64 %p_int_vx_8_s, i64 %p_int_2_vx_5
  %p_int_8_vx_23 = select i1 %sel_tmp92, i64 %p_int_vx_8_s, i64 %p_int_8_vx_22
  %p_int_8_vx_24 = select i1 %sel_tmp94, i64 %p_int_2_vx_5, i64 %p_int_vx_5_s
  %p_int_8_vx_25 = select i1 %sel_tmp92, i64 %p_int_vx_5_s, i64 %p_int_8_vx_24
  %p_int_8_vx_66 = select i1 %sel_tmp92, i64 %p_int_2_vx_5, i64 %p_int_8_vx_65
  %p_ay_8_load_4 = load double* @p_ay_8, align 8
  %p_ay_2_load_5 = load double* @p_ay_2, align 8
  %p_ay_5_load_5 = load double* @p_ay_5, align 8
  %sel_tmp101 = select i1 %sel_tmp92, double %p_ay_2_load_5, double %p_ay_8_load_4
  %p_ay_load_4_2_phi = select i1 %sel_tmp94, double %p_ay_5_load_5, double %sel_tmp101
  %tmp_77_4_2 = fmul double %p_ay_load_4_2_phi, 1.000000e-02
  %tmp_78_4_2 = fmul double %tmp_77_4_2, 1.000000e+16
  %tmp_79_4_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_4_2) nounwind
  %p_int_vy_load_4_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_8_s, i64 %p_int_vy_8_s, i64 %p_int_8_vy_65, i64 %p_int_vy_8_s, i64 %p_int_vy_8_s, i64 %p_int_vy_5_s, i64 %p_int_vy_8_s, i64 %p_int_vy_8_s, i64 %p_int_vy_8_s, i64 %p_int_vy_8_s, i64 %p_int_vy_8_s, i64 %p_int_vy_8_s, i64 %p_int_vy_8_s, i64 %p_int_vy_8_s, i64 %p_int_vy_8_s, i64 %p_int_vy_8_s, i4 %i_4_4_1_t)
  %p_int_2_vy_5 = add nsw i64 %tmp_79_4_2, %p_int_vy_load_4_2_ph
  %p_int_8_vy_22 = select i1 %sel_tmp94, i64 %p_int_vy_8_s, i64 %p_int_2_vy_5
  %p_int_8_vy_23 = select i1 %sel_tmp92, i64 %p_int_vy_8_s, i64 %p_int_8_vy_22
  %p_int_8_vy_24 = select i1 %sel_tmp94, i64 %p_int_2_vy_5, i64 %p_int_vy_5_s
  %p_int_8_vy_25 = select i1 %sel_tmp92, i64 %p_int_vy_5_s, i64 %p_int_8_vy_24
  %p_int_8_vy_66 = select i1 %sel_tmp92, i64 %p_int_2_vy_5, i64 %p_int_8_vy_65
  %p_az_8_load_4 = load double* @p_az_8, align 16
  %p_az_2_load_5 = load double* @p_az_2, align 16
  %p_az_5_load_5 = load double* @p_az_5, align 16
  %sel_tmp102 = select i1 %sel_tmp92, double %p_az_2_load_5, double %p_az_8_load_4
  %p_az_load_4_2_phi = select i1 %sel_tmp94, double %p_az_5_load_5, double %sel_tmp102
  %tmp_81_4_2 = fmul double %p_az_load_4_2_phi, 1.000000e-02
  %tmp_82_4_2 = fmul double %tmp_81_4_2, 1.000000e+16
  %tmp_83_4_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_4_2) nounwind
  %p_int_vz_load_4_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_8_s, i64 %p_int_vz_8_s, i64 %p_int_8_vz_65, i64 %p_int_vz_8_s, i64 %p_int_vz_8_s, i64 %p_int_vz_5_s, i64 %p_int_vz_8_s, i64 %p_int_vz_8_s, i64 %p_int_vz_8_s, i64 %p_int_vz_8_s, i64 %p_int_vz_8_s, i64 %p_int_vz_8_s, i64 %p_int_vz_8_s, i64 %p_int_vz_8_s, i64 %p_int_vz_8_s, i64 %p_int_vz_8_s, i4 %i_4_4_1_t)
  %p_int_2_vz_5 = add nsw i64 %tmp_83_4_2, %p_int_vz_load_4_2_ph
  %p_int_8_vz_22 = select i1 %sel_tmp94, i64 %p_int_vz_8_s, i64 %p_int_2_vz_5
  %p_int_8_vz_23 = select i1 %sel_tmp92, i64 %p_int_vz_8_s, i64 %p_int_8_vz_22
  %p_int_8_vz_24 = select i1 %sel_tmp94, i64 %p_int_2_vz_5, i64 %p_int_vz_5_s
  %p_int_8_vz_25 = select i1 %sel_tmp92, i64 %p_int_vz_5_s, i64 %p_int_8_vz_24
  %p_int_8_vz_66 = select i1 %sel_tmp92, i64 %p_int_2_vz_5, i64 %p_int_8_vz_65
  %i_4_4_2 = add i4 %i_0_i_i_4, 3
  br label %6

janus_step.exit.4:                                ; preds = %6
  %drift_ret9 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_9, i64 %p_int_1_x_8, i64 %p_int_2_x_8, i64 %p_int_3_x_9, i64 %p_int_4_x_8, i64 %p_int_5_x_8, i64 %p_int_6_x_9, i64 %p_int_7_x_8, i64 %p_int_8_x_8, i64 %p_int_0_y_9, i64 %p_int_1_y_8, i64 %p_int_2_y_8, i64 %p_int_3_y_9, i64 %p_int_4_y_8, i64 %p_int_5_y_8, i64 %p_int_6_y_9, i64 %p_int_7_y_8, i64 %p_int_8_y_8, i64 %p_int_0_z_8, i64 %p_int_1_z_8, i64 %p_int_2_z_8, i64 %p_int_3_z_8, i64 %p_int_4_z_8, i64 %p_int_5_z_8, i64 %p_int_6_z_8, i64 %p_int_7_z_8, i64 %p_int_8_z_8, i64 %p_int_6_vx_65, i64 %p_int_7_vx_65, i64 %p_int_8_vx_65, i64 %p_int_vx_3_s, i64 %p_int_vx_4_s, i64 %p_int_vx_5_s, i64 %p_int_vx_6_s, i64 %p_int_vx_7_s, i64 %p_int_vx_8_s, i64 %p_int_6_vy_65, i64 %p_int_7_vy_65, i64 %p_int_8_vy_65, i64 %p_int_vy_3_s, i64 %p_int_vy_4_s, i64 %p_int_vy_5_s, i64 %p_int_vy_6_s, i64 %p_int_vy_7_s, i64 %p_int_vy_8_s, i64 %p_int_6_vz_65, i64 %p_int_7_vz_65, i64 %p_int_8_vz_65, i64 %p_int_vz_3_s, i64 %p_int_vz_4_s, i64 %p_int_vz_5_s, i64 %p_int_vz_6_s, i64 %p_int_vz_7_s, i64 %p_int_vz_8_s)
  %p_int_0_x_10 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 0
  %p_int_1_x_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 1
  %p_int_2_x_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 2
  %p_int_3_x_10 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 3
  %p_int_4_x_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 4
  %p_int_5_x_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 5
  %p_int_6_x_28 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 6
  %p_int_7_x_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 7
  %p_int_8_x_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 8
  %p_int_0_y_10 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 9
  %p_int_1_y_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 10
  %p_int_2_y_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 11
  %p_int_3_y_10 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 12
  %p_int_4_y_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 13
  %p_int_5_y_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 14
  %p_int_6_y_28 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 15
  %p_int_7_y_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 16
  %p_int_8_y_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 17
  %p_int_0_z_10 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 18
  %p_int_1_z_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 19
  %p_int_2_z_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 20
  %p_int_3_z_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 21
  %p_int_4_z_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 22
  %p_int_5_z_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 23
  %p_int_6_z_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 24
  %p_int_7_z_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 25
  %p_int_8_z_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret9, 26
  call fastcc void @to_double(i64 %p_int_0_x_10, i64 %p_int_1_x_9, i64 %p_int_2_x_9, i64 %p_int_3_x_10, i64 %p_int_4_x_9, i64 %p_int_5_x_9, i64 %p_int_6_x_28, i64 %p_int_7_x_9, i64 %p_int_8_x_9, i64 %p_int_0_y_10, i64 %p_int_1_y_9, i64 %p_int_2_y_9, i64 %p_int_3_y_10, i64 %p_int_4_y_9, i64 %p_int_5_y_9, i64 %p_int_6_y_28, i64 %p_int_7_y_9, i64 %p_int_8_y_9, i64 %p_int_0_z_10, i64 %p_int_1_z_9, i64 %p_int_2_z_9, i64 %p_int_3_z_9, i64 %p_int_4_z_9, i64 %p_int_5_z_9, i64 %p_int_6_z_9, i64 %p_int_7_z_9, i64 %p_int_8_z_9, i64 %p_int_6_vx_65, i64 %p_int_7_vx_65, i64 %p_int_8_vx_65, i64 %p_int_vx_3_s, i64 %p_int_vx_4_s, i64 %p_int_vx_5_s, i64 %p_int_vx_6_s, i64 %p_int_vx_7_s, i64 %p_int_vx_8_s, i64 %p_int_6_vy_65, i64 %p_int_7_vy_65, i64 %p_int_8_vy_65, i64 %p_int_vy_3_s, i64 %p_int_vy_4_s, i64 %p_int_vy_5_s, i64 %p_int_vy_6_s, i64 %p_int_vy_7_s, i64 %p_int_vy_8_s, i64 %p_int_6_vz_65, i64 %p_int_7_vz_65, i64 %p_int_8_vz_65, i64 %p_int_vz_3_s, i64 %p_int_vz_4_s, i64 %p_int_vz_5_s, i64 %p_int_vz_6_s, i64 %p_int_vz_7_s, i64 %p_int_vz_8_s)
  %empty_25 = call i32 (...)* @_ssdm_op_SpecRegionEnd([7 x i8]* @p_str5, i32 %tmp_26)
  %tmp_28 = call i32 (...)* @_ssdm_op_SpecRegionBegin([7 x i8]* @p_str5)
  %drift_ret10 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_10, i64 %p_int_1_x_9, i64 %p_int_2_x_9, i64 %p_int_3_x_10, i64 %p_int_4_x_9, i64 %p_int_5_x_9, i64 %p_int_6_x_28, i64 %p_int_7_x_9, i64 %p_int_8_x_9, i64 %p_int_0_y_10, i64 %p_int_1_y_9, i64 %p_int_2_y_9, i64 %p_int_3_y_10, i64 %p_int_4_y_9, i64 %p_int_5_y_9, i64 %p_int_6_y_28, i64 %p_int_7_y_9, i64 %p_int_8_y_9, i64 %p_int_0_z_10, i64 %p_int_1_z_9, i64 %p_int_2_z_9, i64 %p_int_3_z_9, i64 %p_int_4_z_9, i64 %p_int_5_z_9, i64 %p_int_6_z_9, i64 %p_int_7_z_9, i64 %p_int_8_z_9, i64 %p_int_6_vx_65, i64 %p_int_7_vx_65, i64 %p_int_8_vx_65, i64 %p_int_vx_3_s, i64 %p_int_vx_4_s, i64 %p_int_vx_5_s, i64 %p_int_vx_6_s, i64 %p_int_vx_7_s, i64 %p_int_vx_8_s, i64 %p_int_6_vy_65, i64 %p_int_7_vy_65, i64 %p_int_8_vy_65, i64 %p_int_vy_3_s, i64 %p_int_vy_4_s, i64 %p_int_vy_5_s, i64 %p_int_vy_6_s, i64 %p_int_vy_7_s, i64 %p_int_vy_8_s, i64 %p_int_6_vz_65, i64 %p_int_7_vz_65, i64 %p_int_8_vz_65, i64 %p_int_vz_3_s, i64 %p_int_vz_4_s, i64 %p_int_vz_5_s, i64 %p_int_vz_6_s, i64 %p_int_vz_7_s, i64 %p_int_vz_8_s)
  %p_int_0_x_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 0
  %p_int_1_x_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 1
  %p_int_2_x_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 2
  %p_int_3_x_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 3
  %p_int_4_x_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 4
  %p_int_5_x_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 5
  %p_int_6_x_29 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 6
  %p_int_7_x_28 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 7
  %p_int_8_x_28 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 8
  %p_int_0_y_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 9
  %p_int_1_y_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 10
  %p_int_2_y_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 11
  %p_int_3_y_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 12
  %p_int_4_y_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 13
  %p_int_5_y_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 14
  %p_int_6_y_29 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 15
  %p_int_7_y_28 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 16
  %p_int_8_y_28 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 17
  %p_int_0_z_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 18
  %p_int_1_z_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 19
  %p_int_2_z_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 20
  %p_int_3_z_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 21
  %p_int_4_z_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 22
  %p_int_5_z_11 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 23
  %p_int_6_z_28 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 24
  %p_int_7_z_28 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 25
  %p_int_8_z_28 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret10, 26
  call fastcc void @to_double(i64 %p_int_0_x_11, i64 %p_int_1_x_11, i64 %p_int_2_x_11, i64 %p_int_3_x_11, i64 %p_int_4_x_11, i64 %p_int_5_x_11, i64 %p_int_6_x_29, i64 %p_int_7_x_28, i64 %p_int_8_x_28, i64 %p_int_0_y_11, i64 %p_int_1_y_11, i64 %p_int_2_y_11, i64 %p_int_3_y_11, i64 %p_int_4_y_11, i64 %p_int_5_y_11, i64 %p_int_6_y_29, i64 %p_int_7_y_28, i64 %p_int_8_y_28, i64 %p_int_0_z_11, i64 %p_int_1_z_11, i64 %p_int_2_z_11, i64 %p_int_3_z_11, i64 %p_int_4_z_11, i64 %p_int_5_z_11, i64 %p_int_6_z_28, i64 %p_int_7_z_28, i64 %p_int_8_z_28, i64 %p_int_6_vx_65, i64 %p_int_7_vx_65, i64 %p_int_8_vx_65, i64 %p_int_vx_3_s, i64 %p_int_vx_4_s, i64 %p_int_vx_5_s, i64 %p_int_vx_6_s, i64 %p_int_vx_7_s, i64 %p_int_vx_8_s, i64 %p_int_6_vy_65, i64 %p_int_7_vy_65, i64 %p_int_8_vy_65, i64 %p_int_vy_3_s, i64 %p_int_vy_4_s, i64 %p_int_vy_5_s, i64 %p_int_vy_6_s, i64 %p_int_vy_7_s, i64 %p_int_vy_8_s, i64 %p_int_6_vz_65, i64 %p_int_7_vz_65, i64 %p_int_8_vz_65, i64 %p_int_vz_3_s, i64 %p_int_vz_4_s, i64 %p_int_vz_5_s, i64 %p_int_vz_6_s, i64 %p_int_vz_7_s, i64 %p_int_vz_8_s)
  call fastcc void @gravity() nounwind
  br label %8

; <label>:7                                       ; preds = %janus_step.exit.3
  %tmp_26 = call i32 (...)* @_ssdm_op_SpecRegionBegin([7 x i8]* @p_str5)
  %drift_ret8 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_8, i64 %p_int_1_x_7, i64 %p_int_2_x_7, i64 %p_int_3_x_8, i64 %p_int_4_x_7, i64 %p_int_5_x_7, i64 %p_int_6_x_8, i64 %p_int_7_x_7, i64 %p_int_8_x_7, i64 %p_int_0_y_8, i64 %p_int_1_y_7, i64 %p_int_2_y_7, i64 %p_int_3_y_8, i64 %p_int_4_y_7, i64 %p_int_5_y_7, i64 %p_int_6_y_8, i64 %p_int_7_y_7, i64 %p_int_8_y_7, i64 %p_int_0_z_7, i64 %p_int_1_z_7, i64 %p_int_2_z_7, i64 %p_int_3_z_7, i64 %p_int_4_z_7, i64 %p_int_5_z_7, i64 %p_int_6_z_7, i64 %p_int_7_z_7, i64 %p_int_8_z_7, i64 %p_int_6_vx_62, i64 %p_int_7_vx_62, i64 %p_int_8_vx_62, i64 %p_int_vx_3_9, i64 %p_int_vx_4_9, i64 %p_int_vx_5_9, i64 %p_int_vx_6_9, i64 %p_int_vx_7_9, i64 %p_int_vx_8_9, i64 %p_int_6_vy_62, i64 %p_int_7_vy_62, i64 %p_int_8_vy_62, i64 %p_int_vy_3_9, i64 %p_int_vy_4_9, i64 %p_int_vy_5_9, i64 %p_int_vy_6_9, i64 %p_int_vy_7_9, i64 %p_int_vy_8_9, i64 %p_int_6_vz_62, i64 %p_int_7_vz_62, i64 %p_int_8_vz_62, i64 %p_int_vz_3_9, i64 %p_int_vz_4_9, i64 %p_int_vz_5_9, i64 %p_int_vz_6_9, i64 %p_int_vz_7_9, i64 %p_int_vz_8_9)
  %p_int_0_x_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 0
  %p_int_1_x_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 1
  %p_int_2_x_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 2
  %p_int_3_x_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 3
  %p_int_4_x_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 4
  %p_int_5_x_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 5
  %p_int_6_x_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 6
  %p_int_7_x_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 7
  %p_int_8_x_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 8
  %p_int_0_y_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 9
  %p_int_1_y_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 10
  %p_int_2_y_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 11
  %p_int_3_y_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 12
  %p_int_4_y_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 13
  %p_int_5_y_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 14
  %p_int_6_y_9 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 15
  %p_int_7_y_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 16
  %p_int_8_y_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 17
  %p_int_0_z_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 18
  %p_int_1_z_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 19
  %p_int_2_z_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 20
  %p_int_3_z_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 21
  %p_int_4_z_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 22
  %p_int_5_z_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 23
  %p_int_6_z_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 24
  %p_int_7_z_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 25
  %p_int_8_z_8 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret8, 26
  call fastcc void @to_double(i64 %p_int_0_x_9, i64 %p_int_1_x_8, i64 %p_int_2_x_8, i64 %p_int_3_x_9, i64 %p_int_4_x_8, i64 %p_int_5_x_8, i64 %p_int_6_x_9, i64 %p_int_7_x_8, i64 %p_int_8_x_8, i64 %p_int_0_y_9, i64 %p_int_1_y_8, i64 %p_int_2_y_8, i64 %p_int_3_y_9, i64 %p_int_4_y_8, i64 %p_int_5_y_8, i64 %p_int_6_y_9, i64 %p_int_7_y_8, i64 %p_int_8_y_8, i64 %p_int_0_z_8, i64 %p_int_1_z_8, i64 %p_int_2_z_8, i64 %p_int_3_z_8, i64 %p_int_4_z_8, i64 %p_int_5_z_8, i64 %p_int_6_z_8, i64 %p_int_7_z_8, i64 %p_int_8_z_8, i64 %p_int_6_vx_62, i64 %p_int_7_vx_62, i64 %p_int_8_vx_62, i64 %p_int_vx_3_9, i64 %p_int_vx_4_9, i64 %p_int_vx_5_9, i64 %p_int_vx_6_9, i64 %p_int_vx_7_9, i64 %p_int_vx_8_9, i64 %p_int_6_vy_62, i64 %p_int_7_vy_62, i64 %p_int_8_vy_62, i64 %p_int_vy_3_9, i64 %p_int_vy_4_9, i64 %p_int_vy_5_9, i64 %p_int_vy_6_9, i64 %p_int_vy_7_9, i64 %p_int_vy_8_9, i64 %p_int_6_vz_62, i64 %p_int_7_vz_62, i64 %p_int_8_vz_62, i64 %p_int_vz_3_9, i64 %p_int_vz_4_9, i64 %p_int_vz_5_9, i64 %p_int_vz_6_9, i64 %p_int_vz_7_9, i64 %p_int_vz_8_9)
  call fastcc void @gravity() nounwind
  br label %6

; <label>:8                                       ; preds = %_ifconv945, %janus_step.exit.4
  %p_int_vz_8_6 = phi i64 [ %p_int_vz_8_s, %janus_step.exit.4 ], [ %p_int_8_vz_27, %_ifconv945 ]
  %p_int_vz_7_6 = phi i64 [ %p_int_vz_7_s, %janus_step.exit.4 ], [ %p_int_7_vz_27, %_ifconv945 ]
  %p_int_vz_6_6 = phi i64 [ %p_int_vz_6_s, %janus_step.exit.4 ], [ %p_int_6_vz_27, %_ifconv945 ]
  %p_int_vz_5_6 = phi i64 [ %p_int_vz_5_s, %janus_step.exit.4 ], [ %p_int_8_vz_29, %_ifconv945 ]
  %p_int_vz_4_6 = phi i64 [ %p_int_vz_4_s, %janus_step.exit.4 ], [ %p_int_7_vz_29, %_ifconv945 ]
  %p_int_vz_3_6 = phi i64 [ %p_int_vz_3_s, %janus_step.exit.4 ], [ %p_int_6_vz_29, %_ifconv945 ]
  %p_int_8_vz_68 = phi i64 [ %p_int_8_vz_65, %janus_step.exit.4 ], [ %p_int_8_vz_69, %_ifconv945 ]
  %p_int_7_vz_68 = phi i64 [ %p_int_7_vz_65, %janus_step.exit.4 ], [ %p_int_7_vz_69, %_ifconv945 ]
  %p_int_6_vz_68 = phi i64 [ %p_int_6_vz_65, %janus_step.exit.4 ], [ %p_int_6_vz_69, %_ifconv945 ]
  %p_int_vy_8_6 = phi i64 [ %p_int_vy_8_s, %janus_step.exit.4 ], [ %p_int_8_vy_27, %_ifconv945 ]
  %p_int_vy_7_6 = phi i64 [ %p_int_vy_7_s, %janus_step.exit.4 ], [ %p_int_7_vy_27, %_ifconv945 ]
  %p_int_vy_6_6 = phi i64 [ %p_int_vy_6_s, %janus_step.exit.4 ], [ %p_int_6_vy_27, %_ifconv945 ]
  %p_int_vy_5_6 = phi i64 [ %p_int_vy_5_s, %janus_step.exit.4 ], [ %p_int_8_vy_29, %_ifconv945 ]
  %p_int_vy_4_6 = phi i64 [ %p_int_vy_4_s, %janus_step.exit.4 ], [ %p_int_7_vy_29, %_ifconv945 ]
  %p_int_vy_3_6 = phi i64 [ %p_int_vy_3_s, %janus_step.exit.4 ], [ %p_int_6_vy_29, %_ifconv945 ]
  %p_int_8_vy_68 = phi i64 [ %p_int_8_vy_65, %janus_step.exit.4 ], [ %p_int_8_vy_69, %_ifconv945 ]
  %p_int_7_vy_68 = phi i64 [ %p_int_7_vy_65, %janus_step.exit.4 ], [ %p_int_7_vy_69, %_ifconv945 ]
  %p_int_6_vy_68 = phi i64 [ %p_int_6_vy_65, %janus_step.exit.4 ], [ %p_int_6_vy_69, %_ifconv945 ]
  %p_int_vx_8_6 = phi i64 [ %p_int_vx_8_s, %janus_step.exit.4 ], [ %p_int_8_vx_27, %_ifconv945 ]
  %p_int_vx_7_6 = phi i64 [ %p_int_vx_7_s, %janus_step.exit.4 ], [ %p_int_7_vx_27, %_ifconv945 ]
  %p_int_vx_6_6 = phi i64 [ %p_int_vx_6_s, %janus_step.exit.4 ], [ %p_int_6_vx_27, %_ifconv945 ]
  %p_int_vx_5_6 = phi i64 [ %p_int_vx_5_s, %janus_step.exit.4 ], [ %p_int_8_vx_29, %_ifconv945 ]
  %p_int_vx_4_6 = phi i64 [ %p_int_vx_4_s, %janus_step.exit.4 ], [ %p_int_7_vx_29, %_ifconv945 ]
  %p_int_vx_3_6 = phi i64 [ %p_int_vx_3_s, %janus_step.exit.4 ], [ %p_int_6_vx_29, %_ifconv945 ]
  %p_int_8_vx_68 = phi i64 [ %p_int_8_vx_65, %janus_step.exit.4 ], [ %p_int_8_vx_69, %_ifconv945 ]
  %p_int_7_vx_68 = phi i64 [ %p_int_7_vx_65, %janus_step.exit.4 ], [ %p_int_7_vx_69, %_ifconv945 ]
  %p_int_6_vx_68 = phi i64 [ %p_int_6_vx_65, %janus_step.exit.4 ], [ %p_int_6_vx_69, %_ifconv945 ]
  %i_0_i_i_5 = phi i4 [ 0, %janus_step.exit.4 ], [ %i_4_5_2, %_ifconv945 ]
  %tmp_71_5 = icmp eq i4 %i_0_i_i_5, -7
  br i1 %tmp_71_5, label %janus_step.exit.5, label %_ifconv945

_ifconv945:                                       ; preds = %8
  %empty_26 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_31 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str7)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %p_ax_6_load_5 = load double* @p_ax_6, align 16
  %p_ax_0_load_5 = load double* @p_ax_0, align 16
  %p_ax_3_load_5 = load double* @p_ax_3, align 16
  %sel_tmp103 = icmp eq i4 %i_0_i_i_5, 0
  %sel_tmp104 = select i1 %sel_tmp103, double %p_ax_0_load_5, double %p_ax_6_load_5
  %sel_tmp105 = icmp eq i4 %i_0_i_i_5, 3
  %p_ax_load_5_0_phi = select i1 %sel_tmp105, double %p_ax_3_load_5, double %sel_tmp104
  %tmp_73_5 = fmul double %p_ax_load_5_0_phi, 1.000000e-02
  %tmp_74_5 = fmul double %tmp_73_5, 1.000000e+16
  %tmp_75_5 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_5) nounwind
  %p_int_vx_load_5_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vx_68, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i64 %p_int_vx_3_6, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i64 %p_int_vx_6_6, i4 %i_0_i_i_5)
  %p_int_0_vx_6 = add nsw i64 %tmp_75_5, %p_int_vx_load_5_0_ph
  %p_int_6_vx_26 = select i1 %sel_tmp105, i64 %p_int_vx_6_6, i64 %p_int_0_vx_6
  %p_int_6_vx_27 = select i1 %sel_tmp103, i64 %p_int_vx_6_6, i64 %p_int_6_vx_26
  %p_int_6_vx_28 = select i1 %sel_tmp105, i64 %p_int_0_vx_6, i64 %p_int_vx_3_6
  %p_int_6_vx_29 = select i1 %sel_tmp103, i64 %p_int_vx_3_6, i64 %p_int_6_vx_28
  %p_int_6_vx_69 = select i1 %sel_tmp103, i64 %p_int_0_vx_6, i64 %p_int_6_vx_68
  %p_ay_6_load_5 = load double* @p_ay_6, align 8
  %p_ay_0_load_5 = load double* @p_ay_0, align 8
  %p_ay_3_load_5 = load double* @p_ay_3, align 8
  %sel_tmp106 = select i1 %sel_tmp103, double %p_ay_0_load_5, double %p_ay_6_load_5
  %p_ay_load_5_0_phi = select i1 %sel_tmp105, double %p_ay_3_load_5, double %sel_tmp106
  %tmp_77_5 = fmul double %p_ay_load_5_0_phi, 1.000000e-02
  %tmp_78_5 = fmul double %tmp_77_5, 1.000000e+16
  %tmp_79_5 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_5) nounwind
  %p_int_vy_load_5_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vy_68, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i64 %p_int_vy_3_6, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i64 %p_int_vy_6_6, i4 %i_0_i_i_5)
  %p_int_0_vy_6 = add nsw i64 %tmp_79_5, %p_int_vy_load_5_0_ph
  %p_int_6_vy_26 = select i1 %sel_tmp105, i64 %p_int_vy_6_6, i64 %p_int_0_vy_6
  %p_int_6_vy_27 = select i1 %sel_tmp103, i64 %p_int_vy_6_6, i64 %p_int_6_vy_26
  %p_int_6_vy_28 = select i1 %sel_tmp105, i64 %p_int_0_vy_6, i64 %p_int_vy_3_6
  %p_int_6_vy_29 = select i1 %sel_tmp103, i64 %p_int_vy_3_6, i64 %p_int_6_vy_28
  %p_int_6_vy_69 = select i1 %sel_tmp103, i64 %p_int_0_vy_6, i64 %p_int_6_vy_68
  %p_az_6_load_5 = load double* @p_az_6, align 16
  %p_az_0_load_5 = load double* @p_az_0, align 16
  %p_az_3_load_5 = load double* @p_az_3, align 16
  %sel_tmp107 = select i1 %sel_tmp103, double %p_az_0_load_5, double %p_az_6_load_5
  %p_az_load_5_0_phi = select i1 %sel_tmp105, double %p_az_3_load_5, double %sel_tmp107
  %tmp_81_5 = fmul double %p_az_load_5_0_phi, 1.000000e-02
  %tmp_82_5 = fmul double %tmp_81_5, 1.000000e+16
  %tmp_83_5 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_5) nounwind
  %p_int_vz_load_5_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vz_68, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i64 %p_int_vz_3_6, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i64 %p_int_vz_6_6, i4 %i_0_i_i_5)
  %p_int_0_vz_6 = add nsw i64 %tmp_83_5, %p_int_vz_load_5_0_ph
  %p_int_6_vz_26 = select i1 %sel_tmp105, i64 %p_int_vz_6_6, i64 %p_int_0_vz_6
  %p_int_6_vz_27 = select i1 %sel_tmp103, i64 %p_int_vz_6_6, i64 %p_int_6_vz_26
  %p_int_6_vz_28 = select i1 %sel_tmp105, i64 %p_int_0_vz_6, i64 %p_int_vz_3_6
  %p_int_6_vz_29 = select i1 %sel_tmp103, i64 %p_int_vz_3_6, i64 %p_int_6_vz_28
  %p_int_6_vz_69 = select i1 %sel_tmp103, i64 %p_int_0_vz_6, i64 %p_int_6_vz_68
  %empty_27 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str7, i32 %tmp_31)
  %i_4_5_0_t = add i4 %i_0_i_i_5, 1
  %p_ax_7_load_5 = load double* @p_ax_7, align 16
  %p_ax_1_load_6 = load double* @p_ax_1, align 16
  %p_ax_4_load_6 = load double* @p_ax_4, align 16
  %sel_tmp108 = select i1 %sel_tmp103, double %p_ax_1_load_6, double %p_ax_7_load_5
  %p_ax_load_5_1_phi = select i1 %sel_tmp105, double %p_ax_4_load_6, double %sel_tmp108
  %tmp_73_5_1 = fmul double %p_ax_load_5_1_phi, 1.000000e-02
  %tmp_74_5_1 = fmul double %tmp_73_5_1, 1.000000e+16
  %tmp_75_5_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_5_1) nounwind
  %p_int_vx_load_5_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_7_6, i64 %p_int_7_vx_68, i64 %p_int_vx_7_6, i64 %p_int_vx_7_6, i64 %p_int_vx_4_6, i64 %p_int_vx_7_6, i64 %p_int_vx_7_6, i64 %p_int_vx_7_6, i64 %p_int_vx_7_6, i64 %p_int_vx_7_6, i64 %p_int_vx_7_6, i64 %p_int_vx_7_6, i64 %p_int_vx_7_6, i64 %p_int_vx_7_6, i64 %p_int_vx_7_6, i64 %p_int_vx_7_6, i4 %i_4_5_0_t)
  %p_int_1_vx_6 = add nsw i64 %tmp_75_5_1, %p_int_vx_load_5_1_ph
  %p_int_7_vx_26 = select i1 %sel_tmp105, i64 %p_int_vx_7_6, i64 %p_int_1_vx_6
  %p_int_7_vx_27 = select i1 %sel_tmp103, i64 %p_int_vx_7_6, i64 %p_int_7_vx_26
  %p_int_7_vx_28 = select i1 %sel_tmp105, i64 %p_int_1_vx_6, i64 %p_int_vx_4_6
  %p_int_7_vx_29 = select i1 %sel_tmp103, i64 %p_int_vx_4_6, i64 %p_int_7_vx_28
  %p_int_7_vx_69 = select i1 %sel_tmp103, i64 %p_int_1_vx_6, i64 %p_int_7_vx_68
  %p_ay_7_load_5 = load double* @p_ay_7, align 8
  %p_ay_1_load_6 = load double* @p_ay_1, align 8
  %p_ay_4_load_6 = load double* @p_ay_4, align 8
  %sel_tmp109 = select i1 %sel_tmp103, double %p_ay_1_load_6, double %p_ay_7_load_5
  %p_ay_load_5_1_phi = select i1 %sel_tmp105, double %p_ay_4_load_6, double %sel_tmp109
  %tmp_77_5_1 = fmul double %p_ay_load_5_1_phi, 1.000000e-02
  %tmp_78_5_1 = fmul double %tmp_77_5_1, 1.000000e+16
  %tmp_79_5_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_5_1) nounwind
  %p_int_vy_load_5_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_7_6, i64 %p_int_7_vy_68, i64 %p_int_vy_7_6, i64 %p_int_vy_7_6, i64 %p_int_vy_4_6, i64 %p_int_vy_7_6, i64 %p_int_vy_7_6, i64 %p_int_vy_7_6, i64 %p_int_vy_7_6, i64 %p_int_vy_7_6, i64 %p_int_vy_7_6, i64 %p_int_vy_7_6, i64 %p_int_vy_7_6, i64 %p_int_vy_7_6, i64 %p_int_vy_7_6, i64 %p_int_vy_7_6, i4 %i_4_5_0_t)
  %p_int_1_vy_6 = add nsw i64 %tmp_79_5_1, %p_int_vy_load_5_1_ph
  %p_int_7_vy_26 = select i1 %sel_tmp105, i64 %p_int_vy_7_6, i64 %p_int_1_vy_6
  %p_int_7_vy_27 = select i1 %sel_tmp103, i64 %p_int_vy_7_6, i64 %p_int_7_vy_26
  %p_int_7_vy_28 = select i1 %sel_tmp105, i64 %p_int_1_vy_6, i64 %p_int_vy_4_6
  %p_int_7_vy_29 = select i1 %sel_tmp103, i64 %p_int_vy_4_6, i64 %p_int_7_vy_28
  %p_int_7_vy_69 = select i1 %sel_tmp103, i64 %p_int_1_vy_6, i64 %p_int_7_vy_68
  %p_az_7_load_5 = load double* @p_az_7, align 16
  %p_az_1_load_6 = load double* @p_az_1, align 16
  %p_az_4_load_6 = load double* @p_az_4, align 16
  %sel_tmp110 = select i1 %sel_tmp103, double %p_az_1_load_6, double %p_az_7_load_5
  %p_az_load_5_1_phi = select i1 %sel_tmp105, double %p_az_4_load_6, double %sel_tmp110
  %tmp_81_5_1 = fmul double %p_az_load_5_1_phi, 1.000000e-02
  %tmp_82_5_1 = fmul double %tmp_81_5_1, 1.000000e+16
  %tmp_83_5_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_5_1) nounwind
  %p_int_vz_load_5_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_7_6, i64 %p_int_7_vz_68, i64 %p_int_vz_7_6, i64 %p_int_vz_7_6, i64 %p_int_vz_4_6, i64 %p_int_vz_7_6, i64 %p_int_vz_7_6, i64 %p_int_vz_7_6, i64 %p_int_vz_7_6, i64 %p_int_vz_7_6, i64 %p_int_vz_7_6, i64 %p_int_vz_7_6, i64 %p_int_vz_7_6, i64 %p_int_vz_7_6, i64 %p_int_vz_7_6, i64 %p_int_vz_7_6, i4 %i_4_5_0_t)
  %p_int_1_vz_6 = add nsw i64 %tmp_83_5_1, %p_int_vz_load_5_1_ph
  %p_int_7_vz_26 = select i1 %sel_tmp105, i64 %p_int_vz_7_6, i64 %p_int_1_vz_6
  %p_int_7_vz_27 = select i1 %sel_tmp103, i64 %p_int_vz_7_6, i64 %p_int_7_vz_26
  %p_int_7_vz_28 = select i1 %sel_tmp105, i64 %p_int_1_vz_6, i64 %p_int_vz_4_6
  %p_int_7_vz_29 = select i1 %sel_tmp103, i64 %p_int_vz_4_6, i64 %p_int_7_vz_28
  %p_int_7_vz_69 = select i1 %sel_tmp103, i64 %p_int_1_vz_6, i64 %p_int_7_vz_68
  %i_4_5_1_t = add i4 %i_0_i_i_5, 2
  %p_ax_8_load_5 = load double* @p_ax_8, align 16
  %p_ax_2_load_6 = load double* @p_ax_2, align 16
  %p_ax_5_load_6 = load double* @p_ax_5, align 16
  %sel_tmp111 = select i1 %sel_tmp103, double %p_ax_2_load_6, double %p_ax_8_load_5
  %p_ax_load_5_2_phi = select i1 %sel_tmp105, double %p_ax_5_load_6, double %sel_tmp111
  %tmp_73_5_2 = fmul double %p_ax_load_5_2_phi, 1.000000e-02
  %tmp_74_5_2 = fmul double %tmp_73_5_2, 1.000000e+16
  %tmp_75_5_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_5_2) nounwind
  %p_int_vx_load_5_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_8_6, i64 %p_int_vx_8_6, i64 %p_int_8_vx_68, i64 %p_int_vx_8_6, i64 %p_int_vx_8_6, i64 %p_int_vx_5_6, i64 %p_int_vx_8_6, i64 %p_int_vx_8_6, i64 %p_int_vx_8_6, i64 %p_int_vx_8_6, i64 %p_int_vx_8_6, i64 %p_int_vx_8_6, i64 %p_int_vx_8_6, i64 %p_int_vx_8_6, i64 %p_int_vx_8_6, i64 %p_int_vx_8_6, i4 %i_4_5_1_t)
  %p_int_2_vx_6 = add nsw i64 %tmp_75_5_2, %p_int_vx_load_5_2_ph
  %p_int_8_vx_26 = select i1 %sel_tmp105, i64 %p_int_vx_8_6, i64 %p_int_2_vx_6
  %p_int_8_vx_27 = select i1 %sel_tmp103, i64 %p_int_vx_8_6, i64 %p_int_8_vx_26
  %p_int_8_vx_28 = select i1 %sel_tmp105, i64 %p_int_2_vx_6, i64 %p_int_vx_5_6
  %p_int_8_vx_29 = select i1 %sel_tmp103, i64 %p_int_vx_5_6, i64 %p_int_8_vx_28
  %p_int_8_vx_69 = select i1 %sel_tmp103, i64 %p_int_2_vx_6, i64 %p_int_8_vx_68
  %p_ay_8_load_5 = load double* @p_ay_8, align 8
  %p_ay_2_load_6 = load double* @p_ay_2, align 8
  %p_ay_5_load_6 = load double* @p_ay_5, align 8
  %sel_tmp112 = select i1 %sel_tmp103, double %p_ay_2_load_6, double %p_ay_8_load_5
  %p_ay_load_5_2_phi = select i1 %sel_tmp105, double %p_ay_5_load_6, double %sel_tmp112
  %tmp_77_5_2 = fmul double %p_ay_load_5_2_phi, 1.000000e-02
  %tmp_78_5_2 = fmul double %tmp_77_5_2, 1.000000e+16
  %tmp_79_5_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_5_2) nounwind
  %p_int_vy_load_5_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_8_6, i64 %p_int_vy_8_6, i64 %p_int_8_vy_68, i64 %p_int_vy_8_6, i64 %p_int_vy_8_6, i64 %p_int_vy_5_6, i64 %p_int_vy_8_6, i64 %p_int_vy_8_6, i64 %p_int_vy_8_6, i64 %p_int_vy_8_6, i64 %p_int_vy_8_6, i64 %p_int_vy_8_6, i64 %p_int_vy_8_6, i64 %p_int_vy_8_6, i64 %p_int_vy_8_6, i64 %p_int_vy_8_6, i4 %i_4_5_1_t)
  %p_int_2_vy_6 = add nsw i64 %tmp_79_5_2, %p_int_vy_load_5_2_ph
  %p_int_8_vy_26 = select i1 %sel_tmp105, i64 %p_int_vy_8_6, i64 %p_int_2_vy_6
  %p_int_8_vy_27 = select i1 %sel_tmp103, i64 %p_int_vy_8_6, i64 %p_int_8_vy_26
  %p_int_8_vy_28 = select i1 %sel_tmp105, i64 %p_int_2_vy_6, i64 %p_int_vy_5_6
  %p_int_8_vy_29 = select i1 %sel_tmp103, i64 %p_int_vy_5_6, i64 %p_int_8_vy_28
  %p_int_8_vy_69 = select i1 %sel_tmp103, i64 %p_int_2_vy_6, i64 %p_int_8_vy_68
  %p_az_8_load_5 = load double* @p_az_8, align 16
  %p_az_2_load_6 = load double* @p_az_2, align 16
  %p_az_5_load_6 = load double* @p_az_5, align 16
  %sel_tmp113 = select i1 %sel_tmp103, double %p_az_2_load_6, double %p_az_8_load_5
  %p_az_load_5_2_phi = select i1 %sel_tmp105, double %p_az_5_load_6, double %sel_tmp113
  %tmp_81_5_2 = fmul double %p_az_load_5_2_phi, 1.000000e-02
  %tmp_82_5_2 = fmul double %tmp_81_5_2, 1.000000e+16
  %tmp_83_5_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_5_2) nounwind
  %p_int_vz_load_5_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_8_6, i64 %p_int_vz_8_6, i64 %p_int_8_vz_68, i64 %p_int_vz_8_6, i64 %p_int_vz_8_6, i64 %p_int_vz_5_6, i64 %p_int_vz_8_6, i64 %p_int_vz_8_6, i64 %p_int_vz_8_6, i64 %p_int_vz_8_6, i64 %p_int_vz_8_6, i64 %p_int_vz_8_6, i64 %p_int_vz_8_6, i64 %p_int_vz_8_6, i64 %p_int_vz_8_6, i64 %p_int_vz_8_6, i4 %i_4_5_1_t)
  %p_int_2_vz_6 = add nsw i64 %tmp_83_5_2, %p_int_vz_load_5_2_ph
  %p_int_8_vz_26 = select i1 %sel_tmp105, i64 %p_int_vz_8_6, i64 %p_int_2_vz_6
  %p_int_8_vz_27 = select i1 %sel_tmp103, i64 %p_int_vz_8_6, i64 %p_int_8_vz_26
  %p_int_8_vz_28 = select i1 %sel_tmp105, i64 %p_int_2_vz_6, i64 %p_int_vz_5_6
  %p_int_8_vz_29 = select i1 %sel_tmp103, i64 %p_int_vz_5_6, i64 %p_int_8_vz_28
  %p_int_8_vz_69 = select i1 %sel_tmp103, i64 %p_int_2_vz_6, i64 %p_int_8_vz_68
  %i_4_5_2 = add i4 %i_0_i_i_5, 3
  br label %8

janus_step.exit.5:                                ; preds = %8
  %drift_ret11 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_11, i64 %p_int_1_x_11, i64 %p_int_2_x_11, i64 %p_int_3_x_11, i64 %p_int_4_x_11, i64 %p_int_5_x_11, i64 %p_int_6_x_29, i64 %p_int_7_x_28, i64 %p_int_8_x_28, i64 %p_int_0_y_11, i64 %p_int_1_y_11, i64 %p_int_2_y_11, i64 %p_int_3_y_11, i64 %p_int_4_y_11, i64 %p_int_5_y_11, i64 %p_int_6_y_29, i64 %p_int_7_y_28, i64 %p_int_8_y_28, i64 %p_int_0_z_11, i64 %p_int_1_z_11, i64 %p_int_2_z_11, i64 %p_int_3_z_11, i64 %p_int_4_z_11, i64 %p_int_5_z_11, i64 %p_int_6_z_28, i64 %p_int_7_z_28, i64 %p_int_8_z_28, i64 %p_int_6_vx_68, i64 %p_int_7_vx_68, i64 %p_int_8_vx_68, i64 %p_int_vx_3_6, i64 %p_int_vx_4_6, i64 %p_int_vx_5_6, i64 %p_int_vx_6_6, i64 %p_int_vx_7_6, i64 %p_int_vx_8_6, i64 %p_int_6_vy_68, i64 %p_int_7_vy_68, i64 %p_int_8_vy_68, i64 %p_int_vy_3_6, i64 %p_int_vy_4_6, i64 %p_int_vy_5_6, i64 %p_int_vy_6_6, i64 %p_int_vy_7_6, i64 %p_int_vy_8_6, i64 %p_int_6_vz_68, i64 %p_int_7_vz_68, i64 %p_int_8_vz_68, i64 %p_int_vz_3_6, i64 %p_int_vz_4_6, i64 %p_int_vz_5_6, i64 %p_int_vz_6_6, i64 %p_int_vz_7_6, i64 %p_int_vz_8_6)
  %p_int_0_x_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 0
  %p_int_1_x_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 1
  %p_int_2_x_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 2
  %p_int_3_x_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 3
  %p_int_4_x_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 4
  %p_int_5_x_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 5
  %p_int_6_x_30 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 6
  %p_int_7_x_29 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 7
  %p_int_8_x_29 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 8
  %p_int_0_y_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 9
  %p_int_1_y_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 10
  %p_int_2_y_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 11
  %p_int_3_y_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 12
  %p_int_4_y_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 13
  %p_int_5_y_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 14
  %p_int_6_y_30 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 15
  %p_int_7_y_29 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 16
  %p_int_8_y_29 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 17
  %p_int_0_z_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 18
  %p_int_1_z_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 19
  %p_int_2_z_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 20
  %p_int_3_z_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 21
  %p_int_4_z_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 22
  %p_int_5_z_12 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 23
  %p_int_6_z_29 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 24
  %p_int_7_z_29 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 25
  %p_int_8_z_29 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret11, 26
  call fastcc void @to_double(i64 %p_int_0_x_12, i64 %p_int_1_x_12, i64 %p_int_2_x_12, i64 %p_int_3_x_12, i64 %p_int_4_x_12, i64 %p_int_5_x_12, i64 %p_int_6_x_30, i64 %p_int_7_x_29, i64 %p_int_8_x_29, i64 %p_int_0_y_12, i64 %p_int_1_y_12, i64 %p_int_2_y_12, i64 %p_int_3_y_12, i64 %p_int_4_y_12, i64 %p_int_5_y_12, i64 %p_int_6_y_30, i64 %p_int_7_y_29, i64 %p_int_8_y_29, i64 %p_int_0_z_12, i64 %p_int_1_z_12, i64 %p_int_2_z_12, i64 %p_int_3_z_12, i64 %p_int_4_z_12, i64 %p_int_5_z_12, i64 %p_int_6_z_29, i64 %p_int_7_z_29, i64 %p_int_8_z_29, i64 %p_int_6_vx_68, i64 %p_int_7_vx_68, i64 %p_int_8_vx_68, i64 %p_int_vx_3_6, i64 %p_int_vx_4_6, i64 %p_int_vx_5_6, i64 %p_int_vx_6_6, i64 %p_int_vx_7_6, i64 %p_int_vx_8_6, i64 %p_int_6_vy_68, i64 %p_int_7_vy_68, i64 %p_int_8_vy_68, i64 %p_int_vy_3_6, i64 %p_int_vy_4_6, i64 %p_int_vy_5_6, i64 %p_int_vy_6_6, i64 %p_int_vy_7_6, i64 %p_int_vy_8_6, i64 %p_int_6_vz_68, i64 %p_int_7_vz_68, i64 %p_int_8_vz_68, i64 %p_int_vz_3_6, i64 %p_int_vz_4_6, i64 %p_int_vz_5_6, i64 %p_int_vz_6_6, i64 %p_int_vz_7_6, i64 %p_int_vz_8_6)
  %empty_28 = call i32 (...)* @_ssdm_op_SpecRegionEnd([7 x i8]* @p_str5, i32 %tmp_28)
  %tmp_30 = call i32 (...)* @_ssdm_op_SpecRegionBegin([7 x i8]* @p_str5)
  %drift_ret12 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_12, i64 %p_int_1_x_12, i64 %p_int_2_x_12, i64 %p_int_3_x_12, i64 %p_int_4_x_12, i64 %p_int_5_x_12, i64 %p_int_6_x_30, i64 %p_int_7_x_29, i64 %p_int_8_x_29, i64 %p_int_0_y_12, i64 %p_int_1_y_12, i64 %p_int_2_y_12, i64 %p_int_3_y_12, i64 %p_int_4_y_12, i64 %p_int_5_y_12, i64 %p_int_6_y_30, i64 %p_int_7_y_29, i64 %p_int_8_y_29, i64 %p_int_0_z_12, i64 %p_int_1_z_12, i64 %p_int_2_z_12, i64 %p_int_3_z_12, i64 %p_int_4_z_12, i64 %p_int_5_z_12, i64 %p_int_6_z_29, i64 %p_int_7_z_29, i64 %p_int_8_z_29, i64 %p_int_6_vx_68, i64 %p_int_7_vx_68, i64 %p_int_8_vx_68, i64 %p_int_vx_3_6, i64 %p_int_vx_4_6, i64 %p_int_vx_5_6, i64 %p_int_vx_6_6, i64 %p_int_vx_7_6, i64 %p_int_vx_8_6, i64 %p_int_6_vy_68, i64 %p_int_7_vy_68, i64 %p_int_8_vy_68, i64 %p_int_vy_3_6, i64 %p_int_vy_4_6, i64 %p_int_vy_5_6, i64 %p_int_vy_6_6, i64 %p_int_vy_7_6, i64 %p_int_vy_8_6, i64 %p_int_6_vz_68, i64 %p_int_7_vz_68, i64 %p_int_8_vz_68, i64 %p_int_vz_3_6, i64 %p_int_vz_4_6, i64 %p_int_vz_5_6, i64 %p_int_vz_6_6, i64 %p_int_vz_7_6, i64 %p_int_vz_8_6)
  %p_int_0_x_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 0
  %p_int_1_x_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 1
  %p_int_2_x_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 2
  %p_int_3_x_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 3
  %p_int_4_x_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 4
  %p_int_5_x_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 5
  %p_int_6_x_31 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 6
  %p_int_7_x_30 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 7
  %p_int_8_x_30 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 8
  %p_int_0_y_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 9
  %p_int_1_y_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 10
  %p_int_2_y_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 11
  %p_int_3_y_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 12
  %p_int_4_y_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 13
  %p_int_5_y_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 14
  %p_int_6_y_31 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 15
  %p_int_7_y_30 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 16
  %p_int_8_y_30 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 17
  %p_int_0_z_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 18
  %p_int_1_z_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 19
  %p_int_2_z_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 20
  %p_int_3_z_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 21
  %p_int_4_z_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 22
  %p_int_5_z_13 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 23
  %p_int_6_z_30 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 24
  %p_int_7_z_30 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 25
  %p_int_8_z_30 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret12, 26
  call fastcc void @to_double(i64 %p_int_0_x_13, i64 %p_int_1_x_13, i64 %p_int_2_x_13, i64 %p_int_3_x_13, i64 %p_int_4_x_13, i64 %p_int_5_x_13, i64 %p_int_6_x_31, i64 %p_int_7_x_30, i64 %p_int_8_x_30, i64 %p_int_0_y_13, i64 %p_int_1_y_13, i64 %p_int_2_y_13, i64 %p_int_3_y_13, i64 %p_int_4_y_13, i64 %p_int_5_y_13, i64 %p_int_6_y_31, i64 %p_int_7_y_30, i64 %p_int_8_y_30, i64 %p_int_0_z_13, i64 %p_int_1_z_13, i64 %p_int_2_z_13, i64 %p_int_3_z_13, i64 %p_int_4_z_13, i64 %p_int_5_z_13, i64 %p_int_6_z_30, i64 %p_int_7_z_30, i64 %p_int_8_z_30, i64 %p_int_6_vx_68, i64 %p_int_7_vx_68, i64 %p_int_8_vx_68, i64 %p_int_vx_3_6, i64 %p_int_vx_4_6, i64 %p_int_vx_5_6, i64 %p_int_vx_6_6, i64 %p_int_vx_7_6, i64 %p_int_vx_8_6, i64 %p_int_6_vy_68, i64 %p_int_7_vy_68, i64 %p_int_8_vy_68, i64 %p_int_vy_3_6, i64 %p_int_vy_4_6, i64 %p_int_vy_5_6, i64 %p_int_vy_6_6, i64 %p_int_vy_7_6, i64 %p_int_vy_8_6, i64 %p_int_6_vz_68, i64 %p_int_7_vz_68, i64 %p_int_8_vz_68, i64 %p_int_vz_3_6, i64 %p_int_vz_4_6, i64 %p_int_vz_5_6, i64 %p_int_vz_6_6, i64 %p_int_vz_7_6, i64 %p_int_vz_8_6)
  call fastcc void @gravity() nounwind
  br label %9

; <label>:9                                       ; preds = %_ifconv1090, %janus_step.exit.5
  %p_int_vz_8_1 = phi i64 [ %p_int_vz_8_6, %janus_step.exit.5 ], [ %p_int_8_vz_31, %_ifconv1090 ]
  %p_int_vz_7_1 = phi i64 [ %p_int_vz_7_6, %janus_step.exit.5 ], [ %p_int_7_vz_31, %_ifconv1090 ]
  %p_int_vz_6_1 = phi i64 [ %p_int_vz_6_6, %janus_step.exit.5 ], [ %p_int_6_vz_31, %_ifconv1090 ]
  %p_int_vz_5_1 = phi i64 [ %p_int_vz_5_6, %janus_step.exit.5 ], [ %p_int_8_vz_33, %_ifconv1090 ]
  %p_int_vz_4_1 = phi i64 [ %p_int_vz_4_6, %janus_step.exit.5 ], [ %p_int_7_vz_33, %_ifconv1090 ]
  %p_int_vz_3_1 = phi i64 [ %p_int_vz_3_6, %janus_step.exit.5 ], [ %p_int_6_vz_33, %_ifconv1090 ]
  %p_int_8_vz_71 = phi i64 [ %p_int_8_vz_68, %janus_step.exit.5 ], [ %p_int_8_vz_72, %_ifconv1090 ]
  %p_int_7_vz_71 = phi i64 [ %p_int_7_vz_68, %janus_step.exit.5 ], [ %p_int_7_vz_72, %_ifconv1090 ]
  %p_int_6_vz_71 = phi i64 [ %p_int_6_vz_68, %janus_step.exit.5 ], [ %p_int_6_vz_72, %_ifconv1090 ]
  %p_int_vy_8_1 = phi i64 [ %p_int_vy_8_6, %janus_step.exit.5 ], [ %p_int_8_vy_31, %_ifconv1090 ]
  %p_int_vy_7_1 = phi i64 [ %p_int_vy_7_6, %janus_step.exit.5 ], [ %p_int_7_vy_31, %_ifconv1090 ]
  %p_int_vy_6_1 = phi i64 [ %p_int_vy_6_6, %janus_step.exit.5 ], [ %p_int_6_vy_31, %_ifconv1090 ]
  %p_int_vy_5_1 = phi i64 [ %p_int_vy_5_6, %janus_step.exit.5 ], [ %p_int_8_vy_33, %_ifconv1090 ]
  %p_int_vy_4_1 = phi i64 [ %p_int_vy_4_6, %janus_step.exit.5 ], [ %p_int_7_vy_33, %_ifconv1090 ]
  %p_int_vy_3_1 = phi i64 [ %p_int_vy_3_6, %janus_step.exit.5 ], [ %p_int_6_vy_33, %_ifconv1090 ]
  %p_int_8_vy_71 = phi i64 [ %p_int_8_vy_68, %janus_step.exit.5 ], [ %p_int_8_vy_72, %_ifconv1090 ]
  %p_int_7_vy_71 = phi i64 [ %p_int_7_vy_68, %janus_step.exit.5 ], [ %p_int_7_vy_72, %_ifconv1090 ]
  %p_int_6_vy_71 = phi i64 [ %p_int_6_vy_68, %janus_step.exit.5 ], [ %p_int_6_vy_72, %_ifconv1090 ]
  %p_int_vx_8_1 = phi i64 [ %p_int_vx_8_6, %janus_step.exit.5 ], [ %p_int_8_vx_31, %_ifconv1090 ]
  %p_int_vx_7_1 = phi i64 [ %p_int_vx_7_6, %janus_step.exit.5 ], [ %p_int_7_vx_31, %_ifconv1090 ]
  %p_int_vx_6_1 = phi i64 [ %p_int_vx_6_6, %janus_step.exit.5 ], [ %p_int_6_vx_31, %_ifconv1090 ]
  %p_int_vx_5_1 = phi i64 [ %p_int_vx_5_6, %janus_step.exit.5 ], [ %p_int_8_vx_33, %_ifconv1090 ]
  %p_int_vx_4_1 = phi i64 [ %p_int_vx_4_6, %janus_step.exit.5 ], [ %p_int_7_vx_33, %_ifconv1090 ]
  %p_int_vx_3_1 = phi i64 [ %p_int_vx_3_6, %janus_step.exit.5 ], [ %p_int_6_vx_33, %_ifconv1090 ]
  %p_int_8_vx_71 = phi i64 [ %p_int_8_vx_68, %janus_step.exit.5 ], [ %p_int_8_vx_72, %_ifconv1090 ]
  %p_int_7_vx_71 = phi i64 [ %p_int_7_vx_68, %janus_step.exit.5 ], [ %p_int_7_vx_72, %_ifconv1090 ]
  %p_int_6_vx_71 = phi i64 [ %p_int_6_vx_68, %janus_step.exit.5 ], [ %p_int_6_vx_72, %_ifconv1090 ]
  %i_0_i_i_6 = phi i4 [ 0, %janus_step.exit.5 ], [ %i_4_6_2, %_ifconv1090 ]
  %tmp_71_6 = icmp eq i4 %i_0_i_i_6, -7
  br i1 %tmp_71_6, label %janus_step.exit.6, label %_ifconv1090

_ifconv1090:                                      ; preds = %9
  %empty_29 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_33 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str7)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %p_ax_6_load_6 = load double* @p_ax_6, align 16
  %p_ax_0_load_6 = load double* @p_ax_0, align 16
  %p_ax_3_load_6 = load double* @p_ax_3, align 16
  %sel_tmp114 = icmp eq i4 %i_0_i_i_6, 0
  %sel_tmp115 = select i1 %sel_tmp114, double %p_ax_0_load_6, double %p_ax_6_load_6
  %sel_tmp116 = icmp eq i4 %i_0_i_i_6, 3
  %p_ax_load_6_0_phi = select i1 %sel_tmp116, double %p_ax_3_load_6, double %sel_tmp115
  %tmp_73_6 = fmul double %p_ax_load_6_0_phi, 1.000000e-02
  %tmp_74_6 = fmul double %tmp_73_6, 1.000000e+16
  %tmp_75_6 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_6) nounwind
  %p_int_vx_load_6_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vx_71, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i64 %p_int_vx_3_1, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i64 %p_int_vx_6_1, i4 %i_0_i_i_6)
  %p_int_0_vx_7 = add nsw i64 %tmp_75_6, %p_int_vx_load_6_0_ph
  %p_int_6_vx_30 = select i1 %sel_tmp116, i64 %p_int_vx_6_1, i64 %p_int_0_vx_7
  %p_int_6_vx_31 = select i1 %sel_tmp114, i64 %p_int_vx_6_1, i64 %p_int_6_vx_30
  %p_int_6_vx_32 = select i1 %sel_tmp116, i64 %p_int_0_vx_7, i64 %p_int_vx_3_1
  %p_int_6_vx_33 = select i1 %sel_tmp114, i64 %p_int_vx_3_1, i64 %p_int_6_vx_32
  %p_int_6_vx_72 = select i1 %sel_tmp114, i64 %p_int_0_vx_7, i64 %p_int_6_vx_71
  %p_ay_6_load_6 = load double* @p_ay_6, align 8
  %p_ay_0_load_6 = load double* @p_ay_0, align 8
  %p_ay_3_load_6 = load double* @p_ay_3, align 8
  %sel_tmp117 = select i1 %sel_tmp114, double %p_ay_0_load_6, double %p_ay_6_load_6
  %p_ay_load_6_0_phi = select i1 %sel_tmp116, double %p_ay_3_load_6, double %sel_tmp117
  %tmp_77_6 = fmul double %p_ay_load_6_0_phi, 1.000000e-02
  %tmp_78_6 = fmul double %tmp_77_6, 1.000000e+16
  %tmp_79_6 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_6) nounwind
  %p_int_vy_load_6_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vy_71, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i64 %p_int_vy_3_1, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i64 %p_int_vy_6_1, i4 %i_0_i_i_6)
  %p_int_0_vy_7 = add nsw i64 %tmp_79_6, %p_int_vy_load_6_0_ph
  %p_int_6_vy_30 = select i1 %sel_tmp116, i64 %p_int_vy_6_1, i64 %p_int_0_vy_7
  %p_int_6_vy_31 = select i1 %sel_tmp114, i64 %p_int_vy_6_1, i64 %p_int_6_vy_30
  %p_int_6_vy_32 = select i1 %sel_tmp116, i64 %p_int_0_vy_7, i64 %p_int_vy_3_1
  %p_int_6_vy_33 = select i1 %sel_tmp114, i64 %p_int_vy_3_1, i64 %p_int_6_vy_32
  %p_int_6_vy_72 = select i1 %sel_tmp114, i64 %p_int_0_vy_7, i64 %p_int_6_vy_71
  %p_az_6_load_6 = load double* @p_az_6, align 16
  %p_az_0_load_7 = load double* @p_az_0, align 16
  %p_az_3_load_7 = load double* @p_az_3, align 16
  %sel_tmp118 = select i1 %sel_tmp114, double %p_az_0_load_7, double %p_az_6_load_6
  %p_az_load_6_0_phi = select i1 %sel_tmp116, double %p_az_3_load_7, double %sel_tmp118
  %tmp_81_6 = fmul double %p_az_load_6_0_phi, 1.000000e-02
  %tmp_82_6 = fmul double %tmp_81_6, 1.000000e+16
  %tmp_83_6 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_6) nounwind
  %p_int_vz_load_6_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vz_71, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i64 %p_int_vz_3_1, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i64 %p_int_vz_6_1, i4 %i_0_i_i_6)
  %p_int_0_vz_7 = add nsw i64 %tmp_83_6, %p_int_vz_load_6_0_ph
  %p_int_6_vz_30 = select i1 %sel_tmp116, i64 %p_int_vz_6_1, i64 %p_int_0_vz_7
  %p_int_6_vz_31 = select i1 %sel_tmp114, i64 %p_int_vz_6_1, i64 %p_int_6_vz_30
  %p_int_6_vz_32 = select i1 %sel_tmp116, i64 %p_int_0_vz_7, i64 %p_int_vz_3_1
  %p_int_6_vz_33 = select i1 %sel_tmp114, i64 %p_int_vz_3_1, i64 %p_int_6_vz_32
  %p_int_6_vz_72 = select i1 %sel_tmp114, i64 %p_int_0_vz_7, i64 %p_int_6_vz_71
  %empty_30 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str7, i32 %tmp_33)
  %i_4_6_0_t = add i4 %i_0_i_i_6, 1
  %p_ax_7_load_6 = load double* @p_ax_7, align 16
  %p_ax_1_load_7 = load double* @p_ax_1, align 16
  %p_ax_4_load_7 = load double* @p_ax_4, align 16
  %sel_tmp119 = select i1 %sel_tmp114, double %p_ax_1_load_7, double %p_ax_7_load_6
  %p_ax_load_6_1_phi = select i1 %sel_tmp116, double %p_ax_4_load_7, double %sel_tmp119
  %tmp_73_6_1 = fmul double %p_ax_load_6_1_phi, 1.000000e-02
  %tmp_74_6_1 = fmul double %tmp_73_6_1, 1.000000e+16
  %tmp_75_6_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_6_1) nounwind
  %p_int_vx_load_6_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_7_1, i64 %p_int_7_vx_71, i64 %p_int_vx_7_1, i64 %p_int_vx_7_1, i64 %p_int_vx_4_1, i64 %p_int_vx_7_1, i64 %p_int_vx_7_1, i64 %p_int_vx_7_1, i64 %p_int_vx_7_1, i64 %p_int_vx_7_1, i64 %p_int_vx_7_1, i64 %p_int_vx_7_1, i64 %p_int_vx_7_1, i64 %p_int_vx_7_1, i64 %p_int_vx_7_1, i64 %p_int_vx_7_1, i4 %i_4_6_0_t)
  %p_int_1_vx_7 = add nsw i64 %tmp_75_6_1, %p_int_vx_load_6_1_ph
  %p_int_7_vx_30 = select i1 %sel_tmp116, i64 %p_int_vx_7_1, i64 %p_int_1_vx_7
  %p_int_7_vx_31 = select i1 %sel_tmp114, i64 %p_int_vx_7_1, i64 %p_int_7_vx_30
  %p_int_7_vx_32 = select i1 %sel_tmp116, i64 %p_int_1_vx_7, i64 %p_int_vx_4_1
  %p_int_7_vx_33 = select i1 %sel_tmp114, i64 %p_int_vx_4_1, i64 %p_int_7_vx_32
  %p_int_7_vx_72 = select i1 %sel_tmp114, i64 %p_int_1_vx_7, i64 %p_int_7_vx_71
  %p_ay_7_load_6 = load double* @p_ay_7, align 8
  %p_ay_1_load_7 = load double* @p_ay_1, align 8
  %p_ay_4_load_7 = load double* @p_ay_4, align 8
  %sel_tmp120 = select i1 %sel_tmp114, double %p_ay_1_load_7, double %p_ay_7_load_6
  %p_ay_load_6_1_phi = select i1 %sel_tmp116, double %p_ay_4_load_7, double %sel_tmp120
  %tmp_77_6_1 = fmul double %p_ay_load_6_1_phi, 1.000000e-02
  %tmp_78_6_1 = fmul double %tmp_77_6_1, 1.000000e+16
  %tmp_79_6_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_6_1) nounwind
  %p_int_vy_load_6_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_7_1, i64 %p_int_7_vy_71, i64 %p_int_vy_7_1, i64 %p_int_vy_7_1, i64 %p_int_vy_4_1, i64 %p_int_vy_7_1, i64 %p_int_vy_7_1, i64 %p_int_vy_7_1, i64 %p_int_vy_7_1, i64 %p_int_vy_7_1, i64 %p_int_vy_7_1, i64 %p_int_vy_7_1, i64 %p_int_vy_7_1, i64 %p_int_vy_7_1, i64 %p_int_vy_7_1, i64 %p_int_vy_7_1, i4 %i_4_6_0_t)
  %p_int_1_vy_7 = add nsw i64 %tmp_79_6_1, %p_int_vy_load_6_1_ph
  %p_int_7_vy_30 = select i1 %sel_tmp116, i64 %p_int_vy_7_1, i64 %p_int_1_vy_7
  %p_int_7_vy_31 = select i1 %sel_tmp114, i64 %p_int_vy_7_1, i64 %p_int_7_vy_30
  %p_int_7_vy_32 = select i1 %sel_tmp116, i64 %p_int_1_vy_7, i64 %p_int_vy_4_1
  %p_int_7_vy_33 = select i1 %sel_tmp114, i64 %p_int_vy_4_1, i64 %p_int_7_vy_32
  %p_int_7_vy_72 = select i1 %sel_tmp114, i64 %p_int_1_vy_7, i64 %p_int_7_vy_71
  %p_az_7_load_6 = load double* @p_az_7, align 16
  %p_az_1_load_7 = load double* @p_az_1, align 16
  %p_az_4_load_7 = load double* @p_az_4, align 16
  %sel_tmp121 = select i1 %sel_tmp114, double %p_az_1_load_7, double %p_az_7_load_6
  %p_az_load_6_1_phi = select i1 %sel_tmp116, double %p_az_4_load_7, double %sel_tmp121
  %tmp_81_6_1 = fmul double %p_az_load_6_1_phi, 1.000000e-02
  %tmp_82_6_1 = fmul double %tmp_81_6_1, 1.000000e+16
  %tmp_83_6_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_6_1) nounwind
  %p_int_vz_load_6_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_7_1, i64 %p_int_7_vz_71, i64 %p_int_vz_7_1, i64 %p_int_vz_7_1, i64 %p_int_vz_4_1, i64 %p_int_vz_7_1, i64 %p_int_vz_7_1, i64 %p_int_vz_7_1, i64 %p_int_vz_7_1, i64 %p_int_vz_7_1, i64 %p_int_vz_7_1, i64 %p_int_vz_7_1, i64 %p_int_vz_7_1, i64 %p_int_vz_7_1, i64 %p_int_vz_7_1, i64 %p_int_vz_7_1, i4 %i_4_6_0_t)
  %p_int_1_vz_7 = add nsw i64 %tmp_83_6_1, %p_int_vz_load_6_1_ph
  %p_int_7_vz_30 = select i1 %sel_tmp116, i64 %p_int_vz_7_1, i64 %p_int_1_vz_7
  %p_int_7_vz_31 = select i1 %sel_tmp114, i64 %p_int_vz_7_1, i64 %p_int_7_vz_30
  %p_int_7_vz_32 = select i1 %sel_tmp116, i64 %p_int_1_vz_7, i64 %p_int_vz_4_1
  %p_int_7_vz_33 = select i1 %sel_tmp114, i64 %p_int_vz_4_1, i64 %p_int_7_vz_32
  %p_int_7_vz_72 = select i1 %sel_tmp114, i64 %p_int_1_vz_7, i64 %p_int_7_vz_71
  %i_4_6_1_t = add i4 %i_0_i_i_6, 2
  %p_ax_8_load_6 = load double* @p_ax_8, align 16
  %p_ax_2_load_7 = load double* @p_ax_2, align 16
  %p_ax_5_load_7 = load double* @p_ax_5, align 16
  %sel_tmp122 = select i1 %sel_tmp114, double %p_ax_2_load_7, double %p_ax_8_load_6
  %p_ax_load_6_2_phi = select i1 %sel_tmp116, double %p_ax_5_load_7, double %sel_tmp122
  %tmp_73_6_2 = fmul double %p_ax_load_6_2_phi, 1.000000e-02
  %tmp_74_6_2 = fmul double %tmp_73_6_2, 1.000000e+16
  %tmp_75_6_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_6_2) nounwind
  %p_int_vx_load_6_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_8_1, i64 %p_int_vx_8_1, i64 %p_int_8_vx_71, i64 %p_int_vx_8_1, i64 %p_int_vx_8_1, i64 %p_int_vx_5_1, i64 %p_int_vx_8_1, i64 %p_int_vx_8_1, i64 %p_int_vx_8_1, i64 %p_int_vx_8_1, i64 %p_int_vx_8_1, i64 %p_int_vx_8_1, i64 %p_int_vx_8_1, i64 %p_int_vx_8_1, i64 %p_int_vx_8_1, i64 %p_int_vx_8_1, i4 %i_4_6_1_t)
  %p_int_2_vx_7 = add nsw i64 %tmp_75_6_2, %p_int_vx_load_6_2_ph
  %p_int_8_vx_30 = select i1 %sel_tmp116, i64 %p_int_vx_8_1, i64 %p_int_2_vx_7
  %p_int_8_vx_31 = select i1 %sel_tmp114, i64 %p_int_vx_8_1, i64 %p_int_8_vx_30
  %p_int_8_vx_32 = select i1 %sel_tmp116, i64 %p_int_2_vx_7, i64 %p_int_vx_5_1
  %p_int_8_vx_33 = select i1 %sel_tmp114, i64 %p_int_vx_5_1, i64 %p_int_8_vx_32
  %p_int_8_vx_72 = select i1 %sel_tmp114, i64 %p_int_2_vx_7, i64 %p_int_8_vx_71
  %p_ay_8_load_6 = load double* @p_ay_8, align 8
  %p_ay_2_load_7 = load double* @p_ay_2, align 8
  %p_ay_5_load_7 = load double* @p_ay_5, align 8
  %sel_tmp123 = select i1 %sel_tmp114, double %p_ay_2_load_7, double %p_ay_8_load_6
  %p_ay_load_6_2_phi = select i1 %sel_tmp116, double %p_ay_5_load_7, double %sel_tmp123
  %tmp_77_6_2 = fmul double %p_ay_load_6_2_phi, 1.000000e-02
  %tmp_78_6_2 = fmul double %tmp_77_6_2, 1.000000e+16
  %tmp_79_6_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_6_2) nounwind
  %p_int_vy_load_6_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_8_1, i64 %p_int_vy_8_1, i64 %p_int_8_vy_71, i64 %p_int_vy_8_1, i64 %p_int_vy_8_1, i64 %p_int_vy_5_1, i64 %p_int_vy_8_1, i64 %p_int_vy_8_1, i64 %p_int_vy_8_1, i64 %p_int_vy_8_1, i64 %p_int_vy_8_1, i64 %p_int_vy_8_1, i64 %p_int_vy_8_1, i64 %p_int_vy_8_1, i64 %p_int_vy_8_1, i64 %p_int_vy_8_1, i4 %i_4_6_1_t)
  %p_int_2_vy_7 = add nsw i64 %tmp_79_6_2, %p_int_vy_load_6_2_ph
  %p_int_8_vy_30 = select i1 %sel_tmp116, i64 %p_int_vy_8_1, i64 %p_int_2_vy_7
  %p_int_8_vy_31 = select i1 %sel_tmp114, i64 %p_int_vy_8_1, i64 %p_int_8_vy_30
  %p_int_8_vy_32 = select i1 %sel_tmp116, i64 %p_int_2_vy_7, i64 %p_int_vy_5_1
  %p_int_8_vy_33 = select i1 %sel_tmp114, i64 %p_int_vy_5_1, i64 %p_int_8_vy_32
  %p_int_8_vy_72 = select i1 %sel_tmp114, i64 %p_int_2_vy_7, i64 %p_int_8_vy_71
  %p_az_8_load_6 = load double* @p_az_8, align 16
  %p_az_2_load_7 = load double* @p_az_2, align 16
  %p_az_5_load_7 = load double* @p_az_5, align 16
  %sel_tmp124 = select i1 %sel_tmp114, double %p_az_2_load_7, double %p_az_8_load_6
  %p_az_load_6_2_phi = select i1 %sel_tmp116, double %p_az_5_load_7, double %sel_tmp124
  %tmp_81_6_2 = fmul double %p_az_load_6_2_phi, 1.000000e-02
  %tmp_82_6_2 = fmul double %tmp_81_6_2, 1.000000e+16
  %tmp_83_6_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_6_2) nounwind
  %p_int_vz_load_6_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_8_1, i64 %p_int_vz_8_1, i64 %p_int_8_vz_71, i64 %p_int_vz_8_1, i64 %p_int_vz_8_1, i64 %p_int_vz_5_1, i64 %p_int_vz_8_1, i64 %p_int_vz_8_1, i64 %p_int_vz_8_1, i64 %p_int_vz_8_1, i64 %p_int_vz_8_1, i64 %p_int_vz_8_1, i64 %p_int_vz_8_1, i64 %p_int_vz_8_1, i64 %p_int_vz_8_1, i64 %p_int_vz_8_1, i4 %i_4_6_1_t)
  %p_int_2_vz_7 = add nsw i64 %tmp_83_6_2, %p_int_vz_load_6_2_ph
  %p_int_8_vz_30 = select i1 %sel_tmp116, i64 %p_int_vz_8_1, i64 %p_int_2_vz_7
  %p_int_8_vz_31 = select i1 %sel_tmp114, i64 %p_int_vz_8_1, i64 %p_int_8_vz_30
  %p_int_8_vz_32 = select i1 %sel_tmp116, i64 %p_int_2_vz_7, i64 %p_int_vz_5_1
  %p_int_8_vz_33 = select i1 %sel_tmp114, i64 %p_int_vz_5_1, i64 %p_int_8_vz_32
  %p_int_8_vz_72 = select i1 %sel_tmp114, i64 %p_int_2_vz_7, i64 %p_int_8_vz_71
  %i_4_6_2 = add i4 %i_0_i_i_6, 3
  br label %9

janus_step.exit.6:                                ; preds = %9
  %drift_ret13 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_13, i64 %p_int_1_x_13, i64 %p_int_2_x_13, i64 %p_int_3_x_13, i64 %p_int_4_x_13, i64 %p_int_5_x_13, i64 %p_int_6_x_31, i64 %p_int_7_x_30, i64 %p_int_8_x_30, i64 %p_int_0_y_13, i64 %p_int_1_y_13, i64 %p_int_2_y_13, i64 %p_int_3_y_13, i64 %p_int_4_y_13, i64 %p_int_5_y_13, i64 %p_int_6_y_31, i64 %p_int_7_y_30, i64 %p_int_8_y_30, i64 %p_int_0_z_13, i64 %p_int_1_z_13, i64 %p_int_2_z_13, i64 %p_int_3_z_13, i64 %p_int_4_z_13, i64 %p_int_5_z_13, i64 %p_int_6_z_30, i64 %p_int_7_z_30, i64 %p_int_8_z_30, i64 %p_int_6_vx_71, i64 %p_int_7_vx_71, i64 %p_int_8_vx_71, i64 %p_int_vx_3_1, i64 %p_int_vx_4_1, i64 %p_int_vx_5_1, i64 %p_int_vx_6_1, i64 %p_int_vx_7_1, i64 %p_int_vx_8_1, i64 %p_int_6_vy_71, i64 %p_int_7_vy_71, i64 %p_int_8_vy_71, i64 %p_int_vy_3_1, i64 %p_int_vy_4_1, i64 %p_int_vy_5_1, i64 %p_int_vy_6_1, i64 %p_int_vy_7_1, i64 %p_int_vy_8_1, i64 %p_int_6_vz_71, i64 %p_int_7_vz_71, i64 %p_int_8_vz_71, i64 %p_int_vz_3_1, i64 %p_int_vz_4_1, i64 %p_int_vz_5_1, i64 %p_int_vz_6_1, i64 %p_int_vz_7_1, i64 %p_int_vz_8_1)
  %p_int_0_x_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 0
  %p_int_1_x_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 1
  %p_int_2_x_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 2
  %p_int_3_x_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 3
  %p_int_4_x_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 4
  %p_int_5_x_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 5
  %p_int_6_x_32 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 6
  %p_int_7_x_31 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 7
  %p_int_8_x_31 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 8
  %p_int_0_y_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 9
  %p_int_1_y_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 10
  %p_int_2_y_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 11
  %p_int_3_y_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 12
  %p_int_4_y_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 13
  %p_int_5_y_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 14
  %p_int_6_y_32 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 15
  %p_int_7_y_31 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 16
  %p_int_8_y_31 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 17
  %p_int_0_z_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 18
  %p_int_1_z_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 19
  %p_int_2_z_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 20
  %p_int_3_z_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 21
  %p_int_4_z_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 22
  %p_int_5_z_14 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 23
  %p_int_6_z_31 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 24
  %p_int_7_z_31 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 25
  %p_int_8_z_31 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret13, 26
  call fastcc void @to_double(i64 %p_int_0_x_14, i64 %p_int_1_x_14, i64 %p_int_2_x_14, i64 %p_int_3_x_14, i64 %p_int_4_x_14, i64 %p_int_5_x_14, i64 %p_int_6_x_32, i64 %p_int_7_x_31, i64 %p_int_8_x_31, i64 %p_int_0_y_14, i64 %p_int_1_y_14, i64 %p_int_2_y_14, i64 %p_int_3_y_14, i64 %p_int_4_y_14, i64 %p_int_5_y_14, i64 %p_int_6_y_32, i64 %p_int_7_y_31, i64 %p_int_8_y_31, i64 %p_int_0_z_14, i64 %p_int_1_z_14, i64 %p_int_2_z_14, i64 %p_int_3_z_14, i64 %p_int_4_z_14, i64 %p_int_5_z_14, i64 %p_int_6_z_31, i64 %p_int_7_z_31, i64 %p_int_8_z_31, i64 %p_int_6_vx_71, i64 %p_int_7_vx_71, i64 %p_int_8_vx_71, i64 %p_int_vx_3_1, i64 %p_int_vx_4_1, i64 %p_int_vx_5_1, i64 %p_int_vx_6_1, i64 %p_int_vx_7_1, i64 %p_int_vx_8_1, i64 %p_int_6_vy_71, i64 %p_int_7_vy_71, i64 %p_int_8_vy_71, i64 %p_int_vy_3_1, i64 %p_int_vy_4_1, i64 %p_int_vy_5_1, i64 %p_int_vy_6_1, i64 %p_int_vy_7_1, i64 %p_int_vy_8_1, i64 %p_int_6_vz_71, i64 %p_int_7_vz_71, i64 %p_int_8_vz_71, i64 %p_int_vz_3_1, i64 %p_int_vz_4_1, i64 %p_int_vz_5_1, i64 %p_int_vz_6_1, i64 %p_int_vz_7_1, i64 %p_int_vz_8_1)
  %empty_31 = call i32 (...)* @_ssdm_op_SpecRegionEnd([7 x i8]* @p_str5, i32 %tmp_30)
  %tmp_32 = call i32 (...)* @_ssdm_op_SpecRegionBegin([7 x i8]* @p_str5)
  %drift_ret14 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_14, i64 %p_int_1_x_14, i64 %p_int_2_x_14, i64 %p_int_3_x_14, i64 %p_int_4_x_14, i64 %p_int_5_x_14, i64 %p_int_6_x_32, i64 %p_int_7_x_31, i64 %p_int_8_x_31, i64 %p_int_0_y_14, i64 %p_int_1_y_14, i64 %p_int_2_y_14, i64 %p_int_3_y_14, i64 %p_int_4_y_14, i64 %p_int_5_y_14, i64 %p_int_6_y_32, i64 %p_int_7_y_31, i64 %p_int_8_y_31, i64 %p_int_0_z_14, i64 %p_int_1_z_14, i64 %p_int_2_z_14, i64 %p_int_3_z_14, i64 %p_int_4_z_14, i64 %p_int_5_z_14, i64 %p_int_6_z_31, i64 %p_int_7_z_31, i64 %p_int_8_z_31, i64 %p_int_6_vx_71, i64 %p_int_7_vx_71, i64 %p_int_8_vx_71, i64 %p_int_vx_3_1, i64 %p_int_vx_4_1, i64 %p_int_vx_5_1, i64 %p_int_vx_6_1, i64 %p_int_vx_7_1, i64 %p_int_vx_8_1, i64 %p_int_6_vy_71, i64 %p_int_7_vy_71, i64 %p_int_8_vy_71, i64 %p_int_vy_3_1, i64 %p_int_vy_4_1, i64 %p_int_vy_5_1, i64 %p_int_vy_6_1, i64 %p_int_vy_7_1, i64 %p_int_vy_8_1, i64 %p_int_6_vz_71, i64 %p_int_7_vz_71, i64 %p_int_8_vz_71, i64 %p_int_vz_3_1, i64 %p_int_vz_4_1, i64 %p_int_vz_5_1, i64 %p_int_vz_6_1, i64 %p_int_vz_7_1, i64 %p_int_vz_8_1)
  %p_int_0_x_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 0
  %p_int_1_x_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 1
  %p_int_2_x_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 2
  %p_int_3_x_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 3
  %p_int_4_x_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 4
  %p_int_5_x_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 5
  %p_int_6_x_33 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 6
  %p_int_7_x_32 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 7
  %p_int_8_x_32 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 8
  %p_int_0_y_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 9
  %p_int_1_y_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 10
  %p_int_2_y_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 11
  %p_int_3_y_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 12
  %p_int_4_y_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 13
  %p_int_5_y_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 14
  %p_int_6_y_33 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 15
  %p_int_7_y_32 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 16
  %p_int_8_y_32 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 17
  %p_int_0_z_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 18
  %p_int_1_z_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 19
  %p_int_2_z_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 20
  %p_int_3_z_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 21
  %p_int_4_z_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 22
  %p_int_5_z_15 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 23
  %p_int_6_z_32 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 24
  %p_int_7_z_32 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 25
  %p_int_8_z_32 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret14, 26
  call fastcc void @to_double(i64 %p_int_0_x_15, i64 %p_int_1_x_15, i64 %p_int_2_x_15, i64 %p_int_3_x_15, i64 %p_int_4_x_15, i64 %p_int_5_x_15, i64 %p_int_6_x_33, i64 %p_int_7_x_32, i64 %p_int_8_x_32, i64 %p_int_0_y_15, i64 %p_int_1_y_15, i64 %p_int_2_y_15, i64 %p_int_3_y_15, i64 %p_int_4_y_15, i64 %p_int_5_y_15, i64 %p_int_6_y_33, i64 %p_int_7_y_32, i64 %p_int_8_y_32, i64 %p_int_0_z_15, i64 %p_int_1_z_15, i64 %p_int_2_z_15, i64 %p_int_3_z_15, i64 %p_int_4_z_15, i64 %p_int_5_z_15, i64 %p_int_6_z_32, i64 %p_int_7_z_32, i64 %p_int_8_z_32, i64 %p_int_6_vx_71, i64 %p_int_7_vx_71, i64 %p_int_8_vx_71, i64 %p_int_vx_3_1, i64 %p_int_vx_4_1, i64 %p_int_vx_5_1, i64 %p_int_vx_6_1, i64 %p_int_vx_7_1, i64 %p_int_vx_8_1, i64 %p_int_6_vy_71, i64 %p_int_7_vy_71, i64 %p_int_8_vy_71, i64 %p_int_vy_3_1, i64 %p_int_vy_4_1, i64 %p_int_vy_5_1, i64 %p_int_vy_6_1, i64 %p_int_vy_7_1, i64 %p_int_vy_8_1, i64 %p_int_6_vz_71, i64 %p_int_7_vz_71, i64 %p_int_8_vz_71, i64 %p_int_vz_3_1, i64 %p_int_vz_4_1, i64 %p_int_vz_5_1, i64 %p_int_vz_6_1, i64 %p_int_vz_7_1, i64 %p_int_vz_8_1)
  call fastcc void @gravity() nounwind
  br label %10

; <label>:10                                      ; preds = %_ifconv1235, %janus_step.exit.6
  %p_int_vz_8_4 = phi i64 [ %p_int_vz_8_1, %janus_step.exit.6 ], [ %p_int_8_vz_35, %_ifconv1235 ]
  %p_int_vz_7_4 = phi i64 [ %p_int_vz_7_1, %janus_step.exit.6 ], [ %p_int_7_vz_35, %_ifconv1235 ]
  %p_int_vz_6_4 = phi i64 [ %p_int_vz_6_1, %janus_step.exit.6 ], [ %p_int_6_vz_35, %_ifconv1235 ]
  %p_int_vz_5_4 = phi i64 [ %p_int_vz_5_1, %janus_step.exit.6 ], [ %p_int_8_vz_37, %_ifconv1235 ]
  %p_int_vz_4_4 = phi i64 [ %p_int_vz_4_1, %janus_step.exit.6 ], [ %p_int_7_vz_37, %_ifconv1235 ]
  %p_int_vz_3_4 = phi i64 [ %p_int_vz_3_1, %janus_step.exit.6 ], [ %p_int_6_vz_37, %_ifconv1235 ]
  %p_int_8_vz_74 = phi i64 [ %p_int_8_vz_71, %janus_step.exit.6 ], [ %p_int_8_vz_75, %_ifconv1235 ]
  %p_int_7_vz_74 = phi i64 [ %p_int_7_vz_71, %janus_step.exit.6 ], [ %p_int_7_vz_75, %_ifconv1235 ]
  %p_int_6_vz_74 = phi i64 [ %p_int_6_vz_71, %janus_step.exit.6 ], [ %p_int_6_vz_75, %_ifconv1235 ]
  %p_int_vy_8_4 = phi i64 [ %p_int_vy_8_1, %janus_step.exit.6 ], [ %p_int_8_vy_35, %_ifconv1235 ]
  %p_int_vy_7_4 = phi i64 [ %p_int_vy_7_1, %janus_step.exit.6 ], [ %p_int_7_vy_35, %_ifconv1235 ]
  %p_int_vy_6_4 = phi i64 [ %p_int_vy_6_1, %janus_step.exit.6 ], [ %p_int_6_vy_35, %_ifconv1235 ]
  %p_int_vy_5_4 = phi i64 [ %p_int_vy_5_1, %janus_step.exit.6 ], [ %p_int_8_vy_37, %_ifconv1235 ]
  %p_int_vy_4_4 = phi i64 [ %p_int_vy_4_1, %janus_step.exit.6 ], [ %p_int_7_vy_37, %_ifconv1235 ]
  %p_int_vy_3_4 = phi i64 [ %p_int_vy_3_1, %janus_step.exit.6 ], [ %p_int_6_vy_37, %_ifconv1235 ]
  %p_int_8_vy_74 = phi i64 [ %p_int_8_vy_71, %janus_step.exit.6 ], [ %p_int_8_vy_75, %_ifconv1235 ]
  %p_int_7_vy_74 = phi i64 [ %p_int_7_vy_71, %janus_step.exit.6 ], [ %p_int_7_vy_75, %_ifconv1235 ]
  %p_int_6_vy_74 = phi i64 [ %p_int_6_vy_71, %janus_step.exit.6 ], [ %p_int_6_vy_75, %_ifconv1235 ]
  %p_int_vx_8_4 = phi i64 [ %p_int_vx_8_1, %janus_step.exit.6 ], [ %p_int_8_vx_35, %_ifconv1235 ]
  %p_int_vx_7_4 = phi i64 [ %p_int_vx_7_1, %janus_step.exit.6 ], [ %p_int_7_vx_35, %_ifconv1235 ]
  %p_int_vx_6_4 = phi i64 [ %p_int_vx_6_1, %janus_step.exit.6 ], [ %p_int_6_vx_35, %_ifconv1235 ]
  %p_int_vx_5_4 = phi i64 [ %p_int_vx_5_1, %janus_step.exit.6 ], [ %p_int_8_vx_37, %_ifconv1235 ]
  %p_int_vx_4_4 = phi i64 [ %p_int_vx_4_1, %janus_step.exit.6 ], [ %p_int_7_vx_37, %_ifconv1235 ]
  %p_int_vx_3_4 = phi i64 [ %p_int_vx_3_1, %janus_step.exit.6 ], [ %p_int_6_vx_37, %_ifconv1235 ]
  %p_int_8_vx_74 = phi i64 [ %p_int_8_vx_71, %janus_step.exit.6 ], [ %p_int_8_vx_75, %_ifconv1235 ]
  %p_int_7_vx_74 = phi i64 [ %p_int_7_vx_71, %janus_step.exit.6 ], [ %p_int_7_vx_75, %_ifconv1235 ]
  %p_int_6_vx_74 = phi i64 [ %p_int_6_vx_71, %janus_step.exit.6 ], [ %p_int_6_vx_75, %_ifconv1235 ]
  %i_0_i_i_7 = phi i4 [ 0, %janus_step.exit.6 ], [ %i_4_7_2, %_ifconv1235 ]
  %tmp_71_7 = icmp eq i4 %i_0_i_i_7, -7
  br i1 %tmp_71_7, label %janus_step.exit.7, label %_ifconv1235

_ifconv1235:                                      ; preds = %10
  %empty_32 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_35 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str7)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %p_ax_6_load_7 = load double* @p_ax_6, align 16
  %p_ax_0_load_7 = load double* @p_ax_0, align 16
  %p_ax_3_load_7 = load double* @p_ax_3, align 16
  %sel_tmp125 = icmp eq i4 %i_0_i_i_7, 0
  %sel_tmp126 = select i1 %sel_tmp125, double %p_ax_0_load_7, double %p_ax_6_load_7
  %sel_tmp127 = icmp eq i4 %i_0_i_i_7, 3
  %p_ax_load_7_0_phi = select i1 %sel_tmp127, double %p_ax_3_load_7, double %sel_tmp126
  %tmp_73_7 = fmul double %p_ax_load_7_0_phi, 1.000000e-02
  %tmp_74_7 = fmul double %tmp_73_7, 1.000000e+16
  %tmp_75_7 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_7) nounwind
  %p_int_vx_load_7_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vx_74, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i64 %p_int_vx_3_4, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i64 %p_int_vx_6_4, i4 %i_0_i_i_7)
  %p_int_0_vx_8 = add nsw i64 %tmp_75_7, %p_int_vx_load_7_0_ph
  %p_int_6_vx_34 = select i1 %sel_tmp127, i64 %p_int_vx_6_4, i64 %p_int_0_vx_8
  %p_int_6_vx_35 = select i1 %sel_tmp125, i64 %p_int_vx_6_4, i64 %p_int_6_vx_34
  %p_int_6_vx_36 = select i1 %sel_tmp127, i64 %p_int_0_vx_8, i64 %p_int_vx_3_4
  %p_int_6_vx_37 = select i1 %sel_tmp125, i64 %p_int_vx_3_4, i64 %p_int_6_vx_36
  %p_int_6_vx_75 = select i1 %sel_tmp125, i64 %p_int_0_vx_8, i64 %p_int_6_vx_74
  %p_ay_6_load_7 = load double* @p_ay_6, align 8
  %p_ay_0_load_7 = load double* @p_ay_0, align 8
  %p_ay_3_load_7 = load double* @p_ay_3, align 8
  %sel_tmp128 = select i1 %sel_tmp125, double %p_ay_0_load_7, double %p_ay_6_load_7
  %p_ay_load_7_0_phi = select i1 %sel_tmp127, double %p_ay_3_load_7, double %sel_tmp128
  %tmp_77_7 = fmul double %p_ay_load_7_0_phi, 1.000000e-02
  %tmp_78_7 = fmul double %tmp_77_7, 1.000000e+16
  %tmp_79_7 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_7) nounwind
  %p_int_vy_load_7_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vy_74, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i64 %p_int_vy_3_4, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i64 %p_int_vy_6_4, i4 %i_0_i_i_7)
  %p_int_0_vy_8 = add nsw i64 %tmp_79_7, %p_int_vy_load_7_0_ph
  %p_int_6_vy_34 = select i1 %sel_tmp127, i64 %p_int_vy_6_4, i64 %p_int_0_vy_8
  %p_int_6_vy_35 = select i1 %sel_tmp125, i64 %p_int_vy_6_4, i64 %p_int_6_vy_34
  %p_int_6_vy_36 = select i1 %sel_tmp127, i64 %p_int_0_vy_8, i64 %p_int_vy_3_4
  %p_int_6_vy_37 = select i1 %sel_tmp125, i64 %p_int_vy_3_4, i64 %p_int_6_vy_36
  %p_int_6_vy_75 = select i1 %sel_tmp125, i64 %p_int_0_vy_8, i64 %p_int_6_vy_74
  %p_az_6_load_7 = load double* @p_az_6, align 16
  %p_az_0_load_8 = load double* @p_az_0, align 16
  %p_az_3_load_8 = load double* @p_az_3, align 16
  %sel_tmp129 = select i1 %sel_tmp125, double %p_az_0_load_8, double %p_az_6_load_7
  %p_az_load_7_0_phi = select i1 %sel_tmp127, double %p_az_3_load_8, double %sel_tmp129
  %tmp_81_7 = fmul double %p_az_load_7_0_phi, 1.000000e-02
  %tmp_82_7 = fmul double %tmp_81_7, 1.000000e+16
  %tmp_83_7 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_7) nounwind
  %p_int_vz_load_7_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vz_74, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i64 %p_int_vz_3_4, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i64 %p_int_vz_6_4, i4 %i_0_i_i_7)
  %p_int_0_vz_8 = add nsw i64 %tmp_83_7, %p_int_vz_load_7_0_ph
  %p_int_6_vz_34 = select i1 %sel_tmp127, i64 %p_int_vz_6_4, i64 %p_int_0_vz_8
  %p_int_6_vz_35 = select i1 %sel_tmp125, i64 %p_int_vz_6_4, i64 %p_int_6_vz_34
  %p_int_6_vz_36 = select i1 %sel_tmp127, i64 %p_int_0_vz_8, i64 %p_int_vz_3_4
  %p_int_6_vz_37 = select i1 %sel_tmp125, i64 %p_int_vz_3_4, i64 %p_int_6_vz_36
  %p_int_6_vz_75 = select i1 %sel_tmp125, i64 %p_int_0_vz_8, i64 %p_int_6_vz_74
  %empty_33 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str7, i32 %tmp_35)
  %i_4_7_0_t = add i4 %i_0_i_i_7, 1
  %p_ax_7_load_7 = load double* @p_ax_7, align 16
  %p_ax_1_load_8 = load double* @p_ax_1, align 16
  %p_ax_4_load_8 = load double* @p_ax_4, align 16
  %sel_tmp130 = select i1 %sel_tmp125, double %p_ax_1_load_8, double %p_ax_7_load_7
  %p_ax_load_7_1_phi = select i1 %sel_tmp127, double %p_ax_4_load_8, double %sel_tmp130
  %tmp_73_7_1 = fmul double %p_ax_load_7_1_phi, 1.000000e-02
  %tmp_74_7_1 = fmul double %tmp_73_7_1, 1.000000e+16
  %tmp_75_7_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_7_1) nounwind
  %p_int_vx_load_7_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_7_4, i64 %p_int_7_vx_74, i64 %p_int_vx_7_4, i64 %p_int_vx_7_4, i64 %p_int_vx_4_4, i64 %p_int_vx_7_4, i64 %p_int_vx_7_4, i64 %p_int_vx_7_4, i64 %p_int_vx_7_4, i64 %p_int_vx_7_4, i64 %p_int_vx_7_4, i64 %p_int_vx_7_4, i64 %p_int_vx_7_4, i64 %p_int_vx_7_4, i64 %p_int_vx_7_4, i64 %p_int_vx_7_4, i4 %i_4_7_0_t)
  %p_int_1_vx_8 = add nsw i64 %tmp_75_7_1, %p_int_vx_load_7_1_ph
  %p_int_7_vx_34 = select i1 %sel_tmp127, i64 %p_int_vx_7_4, i64 %p_int_1_vx_8
  %p_int_7_vx_35 = select i1 %sel_tmp125, i64 %p_int_vx_7_4, i64 %p_int_7_vx_34
  %p_int_7_vx_36 = select i1 %sel_tmp127, i64 %p_int_1_vx_8, i64 %p_int_vx_4_4
  %p_int_7_vx_37 = select i1 %sel_tmp125, i64 %p_int_vx_4_4, i64 %p_int_7_vx_36
  %p_int_7_vx_75 = select i1 %sel_tmp125, i64 %p_int_1_vx_8, i64 %p_int_7_vx_74
  %p_ay_7_load_7 = load double* @p_ay_7, align 8
  %p_ay_1_load_8 = load double* @p_ay_1, align 8
  %p_ay_4_load_8 = load double* @p_ay_4, align 8
  %sel_tmp131 = select i1 %sel_tmp125, double %p_ay_1_load_8, double %p_ay_7_load_7
  %p_ay_load_7_1_phi = select i1 %sel_tmp127, double %p_ay_4_load_8, double %sel_tmp131
  %tmp_77_7_1 = fmul double %p_ay_load_7_1_phi, 1.000000e-02
  %tmp_78_7_1 = fmul double %tmp_77_7_1, 1.000000e+16
  %tmp_79_7_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_7_1) nounwind
  %p_int_vy_load_7_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_7_4, i64 %p_int_7_vy_74, i64 %p_int_vy_7_4, i64 %p_int_vy_7_4, i64 %p_int_vy_4_4, i64 %p_int_vy_7_4, i64 %p_int_vy_7_4, i64 %p_int_vy_7_4, i64 %p_int_vy_7_4, i64 %p_int_vy_7_4, i64 %p_int_vy_7_4, i64 %p_int_vy_7_4, i64 %p_int_vy_7_4, i64 %p_int_vy_7_4, i64 %p_int_vy_7_4, i64 %p_int_vy_7_4, i4 %i_4_7_0_t)
  %p_int_1_vy_8 = add nsw i64 %tmp_79_7_1, %p_int_vy_load_7_1_ph
  %p_int_7_vy_34 = select i1 %sel_tmp127, i64 %p_int_vy_7_4, i64 %p_int_1_vy_8
  %p_int_7_vy_35 = select i1 %sel_tmp125, i64 %p_int_vy_7_4, i64 %p_int_7_vy_34
  %p_int_7_vy_36 = select i1 %sel_tmp127, i64 %p_int_1_vy_8, i64 %p_int_vy_4_4
  %p_int_7_vy_37 = select i1 %sel_tmp125, i64 %p_int_vy_4_4, i64 %p_int_7_vy_36
  %p_int_7_vy_75 = select i1 %sel_tmp125, i64 %p_int_1_vy_8, i64 %p_int_7_vy_74
  %p_az_7_load_7 = load double* @p_az_7, align 16
  %p_az_1_load_8 = load double* @p_az_1, align 16
  %p_az_4_load_8 = load double* @p_az_4, align 16
  %sel_tmp132 = select i1 %sel_tmp125, double %p_az_1_load_8, double %p_az_7_load_7
  %p_az_load_7_1_phi = select i1 %sel_tmp127, double %p_az_4_load_8, double %sel_tmp132
  %tmp_81_7_1 = fmul double %p_az_load_7_1_phi, 1.000000e-02
  %tmp_82_7_1 = fmul double %tmp_81_7_1, 1.000000e+16
  %tmp_83_7_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_7_1) nounwind
  %p_int_vz_load_7_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_7_4, i64 %p_int_7_vz_74, i64 %p_int_vz_7_4, i64 %p_int_vz_7_4, i64 %p_int_vz_4_4, i64 %p_int_vz_7_4, i64 %p_int_vz_7_4, i64 %p_int_vz_7_4, i64 %p_int_vz_7_4, i64 %p_int_vz_7_4, i64 %p_int_vz_7_4, i64 %p_int_vz_7_4, i64 %p_int_vz_7_4, i64 %p_int_vz_7_4, i64 %p_int_vz_7_4, i64 %p_int_vz_7_4, i4 %i_4_7_0_t)
  %p_int_1_vz_8 = add nsw i64 %tmp_83_7_1, %p_int_vz_load_7_1_ph
  %p_int_7_vz_34 = select i1 %sel_tmp127, i64 %p_int_vz_7_4, i64 %p_int_1_vz_8
  %p_int_7_vz_35 = select i1 %sel_tmp125, i64 %p_int_vz_7_4, i64 %p_int_7_vz_34
  %p_int_7_vz_36 = select i1 %sel_tmp127, i64 %p_int_1_vz_8, i64 %p_int_vz_4_4
  %p_int_7_vz_37 = select i1 %sel_tmp125, i64 %p_int_vz_4_4, i64 %p_int_7_vz_36
  %p_int_7_vz_75 = select i1 %sel_tmp125, i64 %p_int_1_vz_8, i64 %p_int_7_vz_74
  %i_4_7_1_t = add i4 %i_0_i_i_7, 2
  %p_ax_8_load_7 = load double* @p_ax_8, align 16
  %p_ax_2_load_8 = load double* @p_ax_2, align 16
  %p_ax_5_load_8 = load double* @p_ax_5, align 16
  %sel_tmp133 = select i1 %sel_tmp125, double %p_ax_2_load_8, double %p_ax_8_load_7
  %p_ax_load_7_2_phi = select i1 %sel_tmp127, double %p_ax_5_load_8, double %sel_tmp133
  %tmp_73_7_2 = fmul double %p_ax_load_7_2_phi, 1.000000e-02
  %tmp_74_7_2 = fmul double %tmp_73_7_2, 1.000000e+16
  %tmp_75_7_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_7_2) nounwind
  %p_int_vx_load_7_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_8_4, i64 %p_int_vx_8_4, i64 %p_int_8_vx_74, i64 %p_int_vx_8_4, i64 %p_int_vx_8_4, i64 %p_int_vx_5_4, i64 %p_int_vx_8_4, i64 %p_int_vx_8_4, i64 %p_int_vx_8_4, i64 %p_int_vx_8_4, i64 %p_int_vx_8_4, i64 %p_int_vx_8_4, i64 %p_int_vx_8_4, i64 %p_int_vx_8_4, i64 %p_int_vx_8_4, i64 %p_int_vx_8_4, i4 %i_4_7_1_t)
  %p_int_2_vx_8 = add nsw i64 %tmp_75_7_2, %p_int_vx_load_7_2_ph
  %p_int_8_vx_34 = select i1 %sel_tmp127, i64 %p_int_vx_8_4, i64 %p_int_2_vx_8
  %p_int_8_vx_35 = select i1 %sel_tmp125, i64 %p_int_vx_8_4, i64 %p_int_8_vx_34
  %p_int_8_vx_36 = select i1 %sel_tmp127, i64 %p_int_2_vx_8, i64 %p_int_vx_5_4
  %p_int_8_vx_37 = select i1 %sel_tmp125, i64 %p_int_vx_5_4, i64 %p_int_8_vx_36
  %p_int_8_vx_75 = select i1 %sel_tmp125, i64 %p_int_2_vx_8, i64 %p_int_8_vx_74
  %p_ay_8_load_7 = load double* @p_ay_8, align 8
  %p_ay_2_load_8 = load double* @p_ay_2, align 8
  %p_ay_5_load_8 = load double* @p_ay_5, align 8
  %sel_tmp134 = select i1 %sel_tmp125, double %p_ay_2_load_8, double %p_ay_8_load_7
  %p_ay_load_7_2_phi = select i1 %sel_tmp127, double %p_ay_5_load_8, double %sel_tmp134
  %tmp_77_7_2 = fmul double %p_ay_load_7_2_phi, 1.000000e-02
  %tmp_78_7_2 = fmul double %tmp_77_7_2, 1.000000e+16
  %tmp_79_7_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_7_2) nounwind
  %p_int_vy_load_7_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_8_4, i64 %p_int_vy_8_4, i64 %p_int_8_vy_74, i64 %p_int_vy_8_4, i64 %p_int_vy_8_4, i64 %p_int_vy_5_4, i64 %p_int_vy_8_4, i64 %p_int_vy_8_4, i64 %p_int_vy_8_4, i64 %p_int_vy_8_4, i64 %p_int_vy_8_4, i64 %p_int_vy_8_4, i64 %p_int_vy_8_4, i64 %p_int_vy_8_4, i64 %p_int_vy_8_4, i64 %p_int_vy_8_4, i4 %i_4_7_1_t)
  %p_int_2_vy_8 = add nsw i64 %tmp_79_7_2, %p_int_vy_load_7_2_ph
  %p_int_8_vy_34 = select i1 %sel_tmp127, i64 %p_int_vy_8_4, i64 %p_int_2_vy_8
  %p_int_8_vy_35 = select i1 %sel_tmp125, i64 %p_int_vy_8_4, i64 %p_int_8_vy_34
  %p_int_8_vy_36 = select i1 %sel_tmp127, i64 %p_int_2_vy_8, i64 %p_int_vy_5_4
  %p_int_8_vy_37 = select i1 %sel_tmp125, i64 %p_int_vy_5_4, i64 %p_int_8_vy_36
  %p_int_8_vy_75 = select i1 %sel_tmp125, i64 %p_int_2_vy_8, i64 %p_int_8_vy_74
  %p_az_8_load_7 = load double* @p_az_8, align 16
  %p_az_2_load_8 = load double* @p_az_2, align 16
  %p_az_5_load_8 = load double* @p_az_5, align 16
  %sel_tmp135 = select i1 %sel_tmp125, double %p_az_2_load_8, double %p_az_8_load_7
  %p_az_load_7_2_phi = select i1 %sel_tmp127, double %p_az_5_load_8, double %sel_tmp135
  %tmp_81_7_2 = fmul double %p_az_load_7_2_phi, 1.000000e-02
  %tmp_82_7_2 = fmul double %tmp_81_7_2, 1.000000e+16
  %tmp_83_7_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_7_2) nounwind
  %p_int_vz_load_7_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_8_4, i64 %p_int_vz_8_4, i64 %p_int_8_vz_74, i64 %p_int_vz_8_4, i64 %p_int_vz_8_4, i64 %p_int_vz_5_4, i64 %p_int_vz_8_4, i64 %p_int_vz_8_4, i64 %p_int_vz_8_4, i64 %p_int_vz_8_4, i64 %p_int_vz_8_4, i64 %p_int_vz_8_4, i64 %p_int_vz_8_4, i64 %p_int_vz_8_4, i64 %p_int_vz_8_4, i64 %p_int_vz_8_4, i4 %i_4_7_1_t)
  %p_int_2_vz_8 = add nsw i64 %tmp_83_7_2, %p_int_vz_load_7_2_ph
  %p_int_8_vz_34 = select i1 %sel_tmp127, i64 %p_int_vz_8_4, i64 %p_int_2_vz_8
  %p_int_8_vz_35 = select i1 %sel_tmp125, i64 %p_int_vz_8_4, i64 %p_int_8_vz_34
  %p_int_8_vz_36 = select i1 %sel_tmp127, i64 %p_int_2_vz_8, i64 %p_int_vz_5_4
  %p_int_8_vz_37 = select i1 %sel_tmp125, i64 %p_int_vz_5_4, i64 %p_int_8_vz_36
  %p_int_8_vz_75 = select i1 %sel_tmp125, i64 %p_int_2_vz_8, i64 %p_int_8_vz_74
  %i_4_7_2 = add i4 %i_0_i_i_7, 3
  br label %10

janus_step.exit.7:                                ; preds = %10
  %drift_ret15 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_15, i64 %p_int_1_x_15, i64 %p_int_2_x_15, i64 %p_int_3_x_15, i64 %p_int_4_x_15, i64 %p_int_5_x_15, i64 %p_int_6_x_33, i64 %p_int_7_x_32, i64 %p_int_8_x_32, i64 %p_int_0_y_15, i64 %p_int_1_y_15, i64 %p_int_2_y_15, i64 %p_int_3_y_15, i64 %p_int_4_y_15, i64 %p_int_5_y_15, i64 %p_int_6_y_33, i64 %p_int_7_y_32, i64 %p_int_8_y_32, i64 %p_int_0_z_15, i64 %p_int_1_z_15, i64 %p_int_2_z_15, i64 %p_int_3_z_15, i64 %p_int_4_z_15, i64 %p_int_5_z_15, i64 %p_int_6_z_32, i64 %p_int_7_z_32, i64 %p_int_8_z_32, i64 %p_int_6_vx_74, i64 %p_int_7_vx_74, i64 %p_int_8_vx_74, i64 %p_int_vx_3_4, i64 %p_int_vx_4_4, i64 %p_int_vx_5_4, i64 %p_int_vx_6_4, i64 %p_int_vx_7_4, i64 %p_int_vx_8_4, i64 %p_int_6_vy_74, i64 %p_int_7_vy_74, i64 %p_int_8_vy_74, i64 %p_int_vy_3_4, i64 %p_int_vy_4_4, i64 %p_int_vy_5_4, i64 %p_int_vy_6_4, i64 %p_int_vy_7_4, i64 %p_int_vy_8_4, i64 %p_int_6_vz_74, i64 %p_int_7_vz_74, i64 %p_int_8_vz_74, i64 %p_int_vz_3_4, i64 %p_int_vz_4_4, i64 %p_int_vz_5_4, i64 %p_int_vz_6_4, i64 %p_int_vz_7_4, i64 %p_int_vz_8_4)
  %p_int_0_x_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 0
  %p_int_1_x_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 1
  %p_int_2_x_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 2
  %p_int_3_x_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 3
  %p_int_4_x_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 4
  %p_int_5_x_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 5
  %p_int_6_x_34 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 6
  %p_int_7_x_33 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 7
  %p_int_8_x_33 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 8
  %p_int_0_y_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 9
  %p_int_1_y_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 10
  %p_int_2_y_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 11
  %p_int_3_y_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 12
  %p_int_4_y_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 13
  %p_int_5_y_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 14
  %p_int_6_y_34 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 15
  %p_int_7_y_33 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 16
  %p_int_8_y_33 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 17
  %p_int_0_z_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 18
  %p_int_1_z_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 19
  %p_int_2_z_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 20
  %p_int_3_z_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 21
  %p_int_4_z_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 22
  %p_int_5_z_16 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 23
  %p_int_6_z_33 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 24
  %p_int_7_z_33 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 25
  %p_int_8_z_33 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret15, 26
  call fastcc void @to_double(i64 %p_int_0_x_16, i64 %p_int_1_x_16, i64 %p_int_2_x_16, i64 %p_int_3_x_16, i64 %p_int_4_x_16, i64 %p_int_5_x_16, i64 %p_int_6_x_34, i64 %p_int_7_x_33, i64 %p_int_8_x_33, i64 %p_int_0_y_16, i64 %p_int_1_y_16, i64 %p_int_2_y_16, i64 %p_int_3_y_16, i64 %p_int_4_y_16, i64 %p_int_5_y_16, i64 %p_int_6_y_34, i64 %p_int_7_y_33, i64 %p_int_8_y_33, i64 %p_int_0_z_16, i64 %p_int_1_z_16, i64 %p_int_2_z_16, i64 %p_int_3_z_16, i64 %p_int_4_z_16, i64 %p_int_5_z_16, i64 %p_int_6_z_33, i64 %p_int_7_z_33, i64 %p_int_8_z_33, i64 %p_int_6_vx_74, i64 %p_int_7_vx_74, i64 %p_int_8_vx_74, i64 %p_int_vx_3_4, i64 %p_int_vx_4_4, i64 %p_int_vx_5_4, i64 %p_int_vx_6_4, i64 %p_int_vx_7_4, i64 %p_int_vx_8_4, i64 %p_int_6_vy_74, i64 %p_int_7_vy_74, i64 %p_int_8_vy_74, i64 %p_int_vy_3_4, i64 %p_int_vy_4_4, i64 %p_int_vy_5_4, i64 %p_int_vy_6_4, i64 %p_int_vy_7_4, i64 %p_int_vy_8_4, i64 %p_int_6_vz_74, i64 %p_int_7_vz_74, i64 %p_int_8_vz_74, i64 %p_int_vz_3_4, i64 %p_int_vz_4_4, i64 %p_int_vz_5_4, i64 %p_int_vz_6_4, i64 %p_int_vz_7_4, i64 %p_int_vz_8_4)
  %empty_34 = call i32 (...)* @_ssdm_op_SpecRegionEnd([7 x i8]* @p_str5, i32 %tmp_32)
  %tmp_34 = call i32 (...)* @_ssdm_op_SpecRegionBegin([7 x i8]* @p_str5)
  %drift_ret16 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_16, i64 %p_int_1_x_16, i64 %p_int_2_x_16, i64 %p_int_3_x_16, i64 %p_int_4_x_16, i64 %p_int_5_x_16, i64 %p_int_6_x_34, i64 %p_int_7_x_33, i64 %p_int_8_x_33, i64 %p_int_0_y_16, i64 %p_int_1_y_16, i64 %p_int_2_y_16, i64 %p_int_3_y_16, i64 %p_int_4_y_16, i64 %p_int_5_y_16, i64 %p_int_6_y_34, i64 %p_int_7_y_33, i64 %p_int_8_y_33, i64 %p_int_0_z_16, i64 %p_int_1_z_16, i64 %p_int_2_z_16, i64 %p_int_3_z_16, i64 %p_int_4_z_16, i64 %p_int_5_z_16, i64 %p_int_6_z_33, i64 %p_int_7_z_33, i64 %p_int_8_z_33, i64 %p_int_6_vx_74, i64 %p_int_7_vx_74, i64 %p_int_8_vx_74, i64 %p_int_vx_3_4, i64 %p_int_vx_4_4, i64 %p_int_vx_5_4, i64 %p_int_vx_6_4, i64 %p_int_vx_7_4, i64 %p_int_vx_8_4, i64 %p_int_6_vy_74, i64 %p_int_7_vy_74, i64 %p_int_8_vy_74, i64 %p_int_vy_3_4, i64 %p_int_vy_4_4, i64 %p_int_vy_5_4, i64 %p_int_vy_6_4, i64 %p_int_vy_7_4, i64 %p_int_vy_8_4, i64 %p_int_6_vz_74, i64 %p_int_7_vz_74, i64 %p_int_8_vz_74, i64 %p_int_vz_3_4, i64 %p_int_vz_4_4, i64 %p_int_vz_5_4, i64 %p_int_vz_6_4, i64 %p_int_vz_7_4, i64 %p_int_vz_8_4)
  %p_int_0_x_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 0
  %p_int_1_x_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 1
  %p_int_2_x_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 2
  %p_int_3_x_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 3
  %p_int_4_x_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 4
  %p_int_5_x_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 5
  %p_int_6_x_35 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 6
  %p_int_7_x_34 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 7
  %p_int_8_x_34 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 8
  %p_int_0_y_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 9
  %p_int_1_y_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 10
  %p_int_2_y_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 11
  %p_int_3_y_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 12
  %p_int_4_y_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 13
  %p_int_5_y_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 14
  %p_int_6_y_35 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 15
  %p_int_7_y_34 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 16
  %p_int_8_y_34 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 17
  %p_int_0_z_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 18
  %p_int_1_z_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 19
  %p_int_2_z_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 20
  %p_int_3_z_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 21
  %p_int_4_z_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 22
  %p_int_5_z_17 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 23
  %p_int_6_z_34 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 24
  %p_int_7_z_34 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 25
  %p_int_8_z_34 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret16, 26
  call fastcc void @to_double(i64 %p_int_0_x_17, i64 %p_int_1_x_17, i64 %p_int_2_x_17, i64 %p_int_3_x_17, i64 %p_int_4_x_17, i64 %p_int_5_x_17, i64 %p_int_6_x_35, i64 %p_int_7_x_34, i64 %p_int_8_x_34, i64 %p_int_0_y_17, i64 %p_int_1_y_17, i64 %p_int_2_y_17, i64 %p_int_3_y_17, i64 %p_int_4_y_17, i64 %p_int_5_y_17, i64 %p_int_6_y_35, i64 %p_int_7_y_34, i64 %p_int_8_y_34, i64 %p_int_0_z_17, i64 %p_int_1_z_17, i64 %p_int_2_z_17, i64 %p_int_3_z_17, i64 %p_int_4_z_17, i64 %p_int_5_z_17, i64 %p_int_6_z_34, i64 %p_int_7_z_34, i64 %p_int_8_z_34, i64 %p_int_6_vx_74, i64 %p_int_7_vx_74, i64 %p_int_8_vx_74, i64 %p_int_vx_3_4, i64 %p_int_vx_4_4, i64 %p_int_vx_5_4, i64 %p_int_vx_6_4, i64 %p_int_vx_7_4, i64 %p_int_vx_8_4, i64 %p_int_6_vy_74, i64 %p_int_7_vy_74, i64 %p_int_8_vy_74, i64 %p_int_vy_3_4, i64 %p_int_vy_4_4, i64 %p_int_vy_5_4, i64 %p_int_vy_6_4, i64 %p_int_vy_7_4, i64 %p_int_vy_8_4, i64 %p_int_6_vz_74, i64 %p_int_7_vz_74, i64 %p_int_8_vz_74, i64 %p_int_vz_3_4, i64 %p_int_vz_4_4, i64 %p_int_vz_5_4, i64 %p_int_vz_6_4, i64 %p_int_vz_7_4, i64 %p_int_vz_8_4)
  call fastcc void @gravity() nounwind
  br label %11

; <label>:11                                      ; preds = %_ifconv1380, %janus_step.exit.7
  %p_int_vz_8_8 = phi i64 [ %p_int_vz_8_4, %janus_step.exit.7 ], [ %p_int_8_vz_39, %_ifconv1380 ]
  %p_int_vz_7_8 = phi i64 [ %p_int_vz_7_4, %janus_step.exit.7 ], [ %p_int_7_vz_39, %_ifconv1380 ]
  %p_int_vz_6_8 = phi i64 [ %p_int_vz_6_4, %janus_step.exit.7 ], [ %p_int_6_vz_39, %_ifconv1380 ]
  %p_int_vz_5_8 = phi i64 [ %p_int_vz_5_4, %janus_step.exit.7 ], [ %p_int_8_vz_41, %_ifconv1380 ]
  %p_int_vz_4_8 = phi i64 [ %p_int_vz_4_4, %janus_step.exit.7 ], [ %p_int_7_vz_41, %_ifconv1380 ]
  %p_int_vz_3_8 = phi i64 [ %p_int_vz_3_4, %janus_step.exit.7 ], [ %p_int_6_vz_41, %_ifconv1380 ]
  %p_int_8_vz_77 = phi i64 [ %p_int_8_vz_74, %janus_step.exit.7 ], [ %p_int_8_vz_78, %_ifconv1380 ]
  %p_int_7_vz_77 = phi i64 [ %p_int_7_vz_74, %janus_step.exit.7 ], [ %p_int_7_vz_78, %_ifconv1380 ]
  %p_int_6_vz_77 = phi i64 [ %p_int_6_vz_74, %janus_step.exit.7 ], [ %p_int_6_vz_78, %_ifconv1380 ]
  %p_int_vy_8_8 = phi i64 [ %p_int_vy_8_4, %janus_step.exit.7 ], [ %p_int_8_vy_39, %_ifconv1380 ]
  %p_int_vy_7_8 = phi i64 [ %p_int_vy_7_4, %janus_step.exit.7 ], [ %p_int_7_vy_39, %_ifconv1380 ]
  %p_int_vy_6_8 = phi i64 [ %p_int_vy_6_4, %janus_step.exit.7 ], [ %p_int_6_vy_39, %_ifconv1380 ]
  %p_int_vy_5_8 = phi i64 [ %p_int_vy_5_4, %janus_step.exit.7 ], [ %p_int_8_vy_41, %_ifconv1380 ]
  %p_int_vy_4_8 = phi i64 [ %p_int_vy_4_4, %janus_step.exit.7 ], [ %p_int_7_vy_41, %_ifconv1380 ]
  %p_int_vy_3_8 = phi i64 [ %p_int_vy_3_4, %janus_step.exit.7 ], [ %p_int_6_vy_41, %_ifconv1380 ]
  %p_int_8_vy_77 = phi i64 [ %p_int_8_vy_74, %janus_step.exit.7 ], [ %p_int_8_vy_78, %_ifconv1380 ]
  %p_int_7_vy_77 = phi i64 [ %p_int_7_vy_74, %janus_step.exit.7 ], [ %p_int_7_vy_78, %_ifconv1380 ]
  %p_int_6_vy_77 = phi i64 [ %p_int_6_vy_74, %janus_step.exit.7 ], [ %p_int_6_vy_78, %_ifconv1380 ]
  %p_int_vx_8_8 = phi i64 [ %p_int_vx_8_4, %janus_step.exit.7 ], [ %p_int_8_vx_39, %_ifconv1380 ]
  %p_int_vx_7_8 = phi i64 [ %p_int_vx_7_4, %janus_step.exit.7 ], [ %p_int_7_vx_39, %_ifconv1380 ]
  %p_int_vx_6_8 = phi i64 [ %p_int_vx_6_4, %janus_step.exit.7 ], [ %p_int_6_vx_39, %_ifconv1380 ]
  %p_int_vx_5_8 = phi i64 [ %p_int_vx_5_4, %janus_step.exit.7 ], [ %p_int_8_vx_41, %_ifconv1380 ]
  %p_int_vx_4_8 = phi i64 [ %p_int_vx_4_4, %janus_step.exit.7 ], [ %p_int_7_vx_41, %_ifconv1380 ]
  %p_int_vx_3_8 = phi i64 [ %p_int_vx_3_4, %janus_step.exit.7 ], [ %p_int_6_vx_41, %_ifconv1380 ]
  %p_int_8_vx_77 = phi i64 [ %p_int_8_vx_74, %janus_step.exit.7 ], [ %p_int_8_vx_78, %_ifconv1380 ]
  %p_int_7_vx_77 = phi i64 [ %p_int_7_vx_74, %janus_step.exit.7 ], [ %p_int_7_vx_78, %_ifconv1380 ]
  %p_int_6_vx_77 = phi i64 [ %p_int_6_vx_74, %janus_step.exit.7 ], [ %p_int_6_vx_78, %_ifconv1380 ]
  %i_0_i_i_8 = phi i4 [ 0, %janus_step.exit.7 ], [ %i_4_8_2, %_ifconv1380 ]
  %tmp_71_8 = icmp eq i4 %i_0_i_i_8, -7
  br i1 %tmp_71_8, label %janus_step.exit.8, label %_ifconv1380

_ifconv1380:                                      ; preds = %11
  %empty_35 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_37 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str7)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %p_ax_6_load_8 = load double* @p_ax_6, align 16
  %p_ax_0_load_8 = load double* @p_ax_0, align 16
  %p_ax_3_load_8 = load double* @p_ax_3, align 16
  %sel_tmp136 = icmp eq i4 %i_0_i_i_8, 0
  %sel_tmp137 = select i1 %sel_tmp136, double %p_ax_0_load_8, double %p_ax_6_load_8
  %sel_tmp138 = icmp eq i4 %i_0_i_i_8, 3
  %p_ax_load_8_0_phi = select i1 %sel_tmp138, double %p_ax_3_load_8, double %sel_tmp137
  %tmp_73_8 = fmul double %p_ax_load_8_0_phi, 1.000000e-02
  %tmp_74_8 = fmul double %tmp_73_8, 1.000000e+16
  %tmp_75_8 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_8) nounwind
  %p_int_vx_load_8_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vx_77, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i64 %p_int_vx_3_8, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i64 %p_int_vx_6_8, i4 %i_0_i_i_8)
  %p_int_0_vx_9 = add nsw i64 %tmp_75_8, %p_int_vx_load_8_0_ph
  %p_int_6_vx_38 = select i1 %sel_tmp138, i64 %p_int_vx_6_8, i64 %p_int_0_vx_9
  %p_int_6_vx_39 = select i1 %sel_tmp136, i64 %p_int_vx_6_8, i64 %p_int_6_vx_38
  %p_int_6_vx_40 = select i1 %sel_tmp138, i64 %p_int_0_vx_9, i64 %p_int_vx_3_8
  %p_int_6_vx_41 = select i1 %sel_tmp136, i64 %p_int_vx_3_8, i64 %p_int_6_vx_40
  %p_int_6_vx_78 = select i1 %sel_tmp136, i64 %p_int_0_vx_9, i64 %p_int_6_vx_77
  %p_ay_6_load_8 = load double* @p_ay_6, align 8
  %p_ay_0_load_9 = load double* @p_ay_0, align 8
  %p_ay_3_load_9 = load double* @p_ay_3, align 8
  %sel_tmp139 = select i1 %sel_tmp136, double %p_ay_0_load_9, double %p_ay_6_load_8
  %p_ay_load_8_0_phi = select i1 %sel_tmp138, double %p_ay_3_load_9, double %sel_tmp139
  %tmp_77_8 = fmul double %p_ay_load_8_0_phi, 1.000000e-02
  %tmp_78_8 = fmul double %tmp_77_8, 1.000000e+16
  %tmp_79_8 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_8) nounwind
  %p_int_vy_load_8_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vy_77, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i64 %p_int_vy_3_8, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i64 %p_int_vy_6_8, i4 %i_0_i_i_8)
  %p_int_0_vy_9 = add nsw i64 %tmp_79_8, %p_int_vy_load_8_0_ph
  %p_int_6_vy_38 = select i1 %sel_tmp138, i64 %p_int_vy_6_8, i64 %p_int_0_vy_9
  %p_int_6_vy_39 = select i1 %sel_tmp136, i64 %p_int_vy_6_8, i64 %p_int_6_vy_38
  %p_int_6_vy_40 = select i1 %sel_tmp138, i64 %p_int_0_vy_9, i64 %p_int_vy_3_8
  %p_int_6_vy_41 = select i1 %sel_tmp136, i64 %p_int_vy_3_8, i64 %p_int_6_vy_40
  %p_int_6_vy_78 = select i1 %sel_tmp136, i64 %p_int_0_vy_9, i64 %p_int_6_vy_77
  %p_az_6_load_8 = load double* @p_az_6, align 16
  %p_az_0_load_9 = load double* @p_az_0, align 16
  %p_az_3_load_9 = load double* @p_az_3, align 16
  %sel_tmp140 = select i1 %sel_tmp136, double %p_az_0_load_9, double %p_az_6_load_8
  %p_az_load_8_0_phi = select i1 %sel_tmp138, double %p_az_3_load_9, double %sel_tmp140
  %tmp_81_8 = fmul double %p_az_load_8_0_phi, 1.000000e-02
  %tmp_82_8 = fmul double %tmp_81_8, 1.000000e+16
  %tmp_83_8 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_8) nounwind
  %p_int_vz_load_8_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vz_77, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i64 %p_int_vz_3_8, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i64 %p_int_vz_6_8, i4 %i_0_i_i_8)
  %p_int_0_vz_9 = add nsw i64 %tmp_83_8, %p_int_vz_load_8_0_ph
  %p_int_6_vz_38 = select i1 %sel_tmp138, i64 %p_int_vz_6_8, i64 %p_int_0_vz_9
  %p_int_6_vz_39 = select i1 %sel_tmp136, i64 %p_int_vz_6_8, i64 %p_int_6_vz_38
  %p_int_6_vz_40 = select i1 %sel_tmp138, i64 %p_int_0_vz_9, i64 %p_int_vz_3_8
  %p_int_6_vz_41 = select i1 %sel_tmp136, i64 %p_int_vz_3_8, i64 %p_int_6_vz_40
  %p_int_6_vz_78 = select i1 %sel_tmp136, i64 %p_int_0_vz_9, i64 %p_int_6_vz_77
  %empty_36 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str7, i32 %tmp_37)
  %i_4_8_0_t = add i4 %i_0_i_i_8, 1
  %p_ax_7_load_8 = load double* @p_ax_7, align 16
  %p_ax_1_load_9 = load double* @p_ax_1, align 16
  %p_ax_4_load_9 = load double* @p_ax_4, align 16
  %sel_tmp141 = select i1 %sel_tmp136, double %p_ax_1_load_9, double %p_ax_7_load_8
  %p_ax_load_8_1_phi = select i1 %sel_tmp138, double %p_ax_4_load_9, double %sel_tmp141
  %tmp_73_8_1 = fmul double %p_ax_load_8_1_phi, 1.000000e-02
  %tmp_74_8_1 = fmul double %tmp_73_8_1, 1.000000e+16
  %tmp_75_8_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_8_1) nounwind
  %p_int_vx_load_8_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_7_8, i64 %p_int_7_vx_77, i64 %p_int_vx_7_8, i64 %p_int_vx_7_8, i64 %p_int_vx_4_8, i64 %p_int_vx_7_8, i64 %p_int_vx_7_8, i64 %p_int_vx_7_8, i64 %p_int_vx_7_8, i64 %p_int_vx_7_8, i64 %p_int_vx_7_8, i64 %p_int_vx_7_8, i64 %p_int_vx_7_8, i64 %p_int_vx_7_8, i64 %p_int_vx_7_8, i64 %p_int_vx_7_8, i4 %i_4_8_0_t)
  %p_int_1_vx_9 = add nsw i64 %tmp_75_8_1, %p_int_vx_load_8_1_ph
  %p_int_7_vx_38 = select i1 %sel_tmp138, i64 %p_int_vx_7_8, i64 %p_int_1_vx_9
  %p_int_7_vx_39 = select i1 %sel_tmp136, i64 %p_int_vx_7_8, i64 %p_int_7_vx_38
  %p_int_7_vx_40 = select i1 %sel_tmp138, i64 %p_int_1_vx_9, i64 %p_int_vx_4_8
  %p_int_7_vx_41 = select i1 %sel_tmp136, i64 %p_int_vx_4_8, i64 %p_int_7_vx_40
  %p_int_7_vx_78 = select i1 %sel_tmp136, i64 %p_int_1_vx_9, i64 %p_int_7_vx_77
  %p_ay_7_load_8 = load double* @p_ay_7, align 8
  %p_ay_1_load_9 = load double* @p_ay_1, align 8
  %p_ay_4_load_9 = load double* @p_ay_4, align 8
  %sel_tmp142 = select i1 %sel_tmp136, double %p_ay_1_load_9, double %p_ay_7_load_8
  %p_ay_load_8_1_phi = select i1 %sel_tmp138, double %p_ay_4_load_9, double %sel_tmp142
  %tmp_77_8_1 = fmul double %p_ay_load_8_1_phi, 1.000000e-02
  %tmp_78_8_1 = fmul double %tmp_77_8_1, 1.000000e+16
  %tmp_79_8_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_8_1) nounwind
  %p_int_vy_load_8_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_7_8, i64 %p_int_7_vy_77, i64 %p_int_vy_7_8, i64 %p_int_vy_7_8, i64 %p_int_vy_4_8, i64 %p_int_vy_7_8, i64 %p_int_vy_7_8, i64 %p_int_vy_7_8, i64 %p_int_vy_7_8, i64 %p_int_vy_7_8, i64 %p_int_vy_7_8, i64 %p_int_vy_7_8, i64 %p_int_vy_7_8, i64 %p_int_vy_7_8, i64 %p_int_vy_7_8, i64 %p_int_vy_7_8, i4 %i_4_8_0_t)
  %p_int_1_vy_9 = add nsw i64 %tmp_79_8_1, %p_int_vy_load_8_1_ph
  %p_int_7_vy_38 = select i1 %sel_tmp138, i64 %p_int_vy_7_8, i64 %p_int_1_vy_9
  %p_int_7_vy_39 = select i1 %sel_tmp136, i64 %p_int_vy_7_8, i64 %p_int_7_vy_38
  %p_int_7_vy_40 = select i1 %sel_tmp138, i64 %p_int_1_vy_9, i64 %p_int_vy_4_8
  %p_int_7_vy_41 = select i1 %sel_tmp136, i64 %p_int_vy_4_8, i64 %p_int_7_vy_40
  %p_int_7_vy_78 = select i1 %sel_tmp136, i64 %p_int_1_vy_9, i64 %p_int_7_vy_77
  %p_az_7_load_8 = load double* @p_az_7, align 16
  %p_az_1_load_9 = load double* @p_az_1, align 16
  %p_az_4_load_9 = load double* @p_az_4, align 16
  %sel_tmp143 = select i1 %sel_tmp136, double %p_az_1_load_9, double %p_az_7_load_8
  %p_az_load_8_1_phi = select i1 %sel_tmp138, double %p_az_4_load_9, double %sel_tmp143
  %tmp_81_8_1 = fmul double %p_az_load_8_1_phi, 1.000000e-02
  %tmp_82_8_1 = fmul double %tmp_81_8_1, 1.000000e+16
  %tmp_83_8_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_8_1) nounwind
  %p_int_vz_load_8_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_7_8, i64 %p_int_7_vz_77, i64 %p_int_vz_7_8, i64 %p_int_vz_7_8, i64 %p_int_vz_4_8, i64 %p_int_vz_7_8, i64 %p_int_vz_7_8, i64 %p_int_vz_7_8, i64 %p_int_vz_7_8, i64 %p_int_vz_7_8, i64 %p_int_vz_7_8, i64 %p_int_vz_7_8, i64 %p_int_vz_7_8, i64 %p_int_vz_7_8, i64 %p_int_vz_7_8, i64 %p_int_vz_7_8, i4 %i_4_8_0_t)
  %p_int_1_vz_9 = add nsw i64 %tmp_83_8_1, %p_int_vz_load_8_1_ph
  %p_int_7_vz_38 = select i1 %sel_tmp138, i64 %p_int_vz_7_8, i64 %p_int_1_vz_9
  %p_int_7_vz_39 = select i1 %sel_tmp136, i64 %p_int_vz_7_8, i64 %p_int_7_vz_38
  %p_int_7_vz_40 = select i1 %sel_tmp138, i64 %p_int_1_vz_9, i64 %p_int_vz_4_8
  %p_int_7_vz_41 = select i1 %sel_tmp136, i64 %p_int_vz_4_8, i64 %p_int_7_vz_40
  %p_int_7_vz_78 = select i1 %sel_tmp136, i64 %p_int_1_vz_9, i64 %p_int_7_vz_77
  %i_4_8_1_t = add i4 %i_0_i_i_8, 2
  %p_ax_8_load_8 = load double* @p_ax_8, align 16
  %p_ax_2_load_9 = load double* @p_ax_2, align 16
  %p_ax_5_load_9 = load double* @p_ax_5, align 16
  %sel_tmp144 = select i1 %sel_tmp136, double %p_ax_2_load_9, double %p_ax_8_load_8
  %p_ax_load_8_2_phi = select i1 %sel_tmp138, double %p_ax_5_load_9, double %sel_tmp144
  %tmp_73_8_2 = fmul double %p_ax_load_8_2_phi, 1.000000e-02
  %tmp_74_8_2 = fmul double %tmp_73_8_2, 1.000000e+16
  %tmp_75_8_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_8_2) nounwind
  %p_int_vx_load_8_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_8_8, i64 %p_int_vx_8_8, i64 %p_int_8_vx_77, i64 %p_int_vx_8_8, i64 %p_int_vx_8_8, i64 %p_int_vx_5_8, i64 %p_int_vx_8_8, i64 %p_int_vx_8_8, i64 %p_int_vx_8_8, i64 %p_int_vx_8_8, i64 %p_int_vx_8_8, i64 %p_int_vx_8_8, i64 %p_int_vx_8_8, i64 %p_int_vx_8_8, i64 %p_int_vx_8_8, i64 %p_int_vx_8_8, i4 %i_4_8_1_t)
  %p_int_2_vx_9 = add nsw i64 %tmp_75_8_2, %p_int_vx_load_8_2_ph
  %p_int_8_vx_38 = select i1 %sel_tmp138, i64 %p_int_vx_8_8, i64 %p_int_2_vx_9
  %p_int_8_vx_39 = select i1 %sel_tmp136, i64 %p_int_vx_8_8, i64 %p_int_8_vx_38
  %p_int_8_vx_40 = select i1 %sel_tmp138, i64 %p_int_2_vx_9, i64 %p_int_vx_5_8
  %p_int_8_vx_41 = select i1 %sel_tmp136, i64 %p_int_vx_5_8, i64 %p_int_8_vx_40
  %p_int_8_vx_78 = select i1 %sel_tmp136, i64 %p_int_2_vx_9, i64 %p_int_8_vx_77
  %p_ay_8_load_8 = load double* @p_ay_8, align 8
  %p_ay_2_load_9 = load double* @p_ay_2, align 8
  %p_ay_5_load_9 = load double* @p_ay_5, align 8
  %sel_tmp145 = select i1 %sel_tmp136, double %p_ay_2_load_9, double %p_ay_8_load_8
  %p_ay_load_8_2_phi = select i1 %sel_tmp138, double %p_ay_5_load_9, double %sel_tmp145
  %tmp_77_8_2 = fmul double %p_ay_load_8_2_phi, 1.000000e-02
  %tmp_78_8_2 = fmul double %tmp_77_8_2, 1.000000e+16
  %tmp_79_8_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_8_2) nounwind
  %p_int_vy_load_8_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_8_8, i64 %p_int_vy_8_8, i64 %p_int_8_vy_77, i64 %p_int_vy_8_8, i64 %p_int_vy_8_8, i64 %p_int_vy_5_8, i64 %p_int_vy_8_8, i64 %p_int_vy_8_8, i64 %p_int_vy_8_8, i64 %p_int_vy_8_8, i64 %p_int_vy_8_8, i64 %p_int_vy_8_8, i64 %p_int_vy_8_8, i64 %p_int_vy_8_8, i64 %p_int_vy_8_8, i64 %p_int_vy_8_8, i4 %i_4_8_1_t)
  %p_int_2_vy_9 = add nsw i64 %tmp_79_8_2, %p_int_vy_load_8_2_ph
  %p_int_8_vy_38 = select i1 %sel_tmp138, i64 %p_int_vy_8_8, i64 %p_int_2_vy_9
  %p_int_8_vy_39 = select i1 %sel_tmp136, i64 %p_int_vy_8_8, i64 %p_int_8_vy_38
  %p_int_8_vy_40 = select i1 %sel_tmp138, i64 %p_int_2_vy_9, i64 %p_int_vy_5_8
  %p_int_8_vy_41 = select i1 %sel_tmp136, i64 %p_int_vy_5_8, i64 %p_int_8_vy_40
  %p_int_8_vy_78 = select i1 %sel_tmp136, i64 %p_int_2_vy_9, i64 %p_int_8_vy_77
  %p_az_8_load_8 = load double* @p_az_8, align 16
  %p_az_2_load_9 = load double* @p_az_2, align 16
  %p_az_5_load_9 = load double* @p_az_5, align 16
  %sel_tmp146 = select i1 %sel_tmp136, double %p_az_2_load_9, double %p_az_8_load_8
  %p_az_load_8_2_phi = select i1 %sel_tmp138, double %p_az_5_load_9, double %sel_tmp146
  %tmp_81_8_2 = fmul double %p_az_load_8_2_phi, 1.000000e-02
  %tmp_82_8_2 = fmul double %tmp_81_8_2, 1.000000e+16
  %tmp_83_8_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_8_2) nounwind
  %p_int_vz_load_8_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_8_8, i64 %p_int_vz_8_8, i64 %p_int_8_vz_77, i64 %p_int_vz_8_8, i64 %p_int_vz_8_8, i64 %p_int_vz_5_8, i64 %p_int_vz_8_8, i64 %p_int_vz_8_8, i64 %p_int_vz_8_8, i64 %p_int_vz_8_8, i64 %p_int_vz_8_8, i64 %p_int_vz_8_8, i64 %p_int_vz_8_8, i64 %p_int_vz_8_8, i64 %p_int_vz_8_8, i64 %p_int_vz_8_8, i4 %i_4_8_1_t)
  %p_int_2_vz_9 = add nsw i64 %tmp_83_8_2, %p_int_vz_load_8_2_ph
  %p_int_8_vz_38 = select i1 %sel_tmp138, i64 %p_int_vz_8_8, i64 %p_int_2_vz_9
  %p_int_8_vz_39 = select i1 %sel_tmp136, i64 %p_int_vz_8_8, i64 %p_int_8_vz_38
  %p_int_8_vz_40 = select i1 %sel_tmp138, i64 %p_int_2_vz_9, i64 %p_int_vz_5_8
  %p_int_8_vz_41 = select i1 %sel_tmp136, i64 %p_int_vz_5_8, i64 %p_int_8_vz_40
  %p_int_8_vz_78 = select i1 %sel_tmp136, i64 %p_int_2_vz_9, i64 %p_int_8_vz_77
  %i_4_8_2 = add i4 %i_0_i_i_8, 3
  br label %11

janus_step.exit.8:                                ; preds = %11
  %drift_ret17 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_17, i64 %p_int_1_x_17, i64 %p_int_2_x_17, i64 %p_int_3_x_17, i64 %p_int_4_x_17, i64 %p_int_5_x_17, i64 %p_int_6_x_35, i64 %p_int_7_x_34, i64 %p_int_8_x_34, i64 %p_int_0_y_17, i64 %p_int_1_y_17, i64 %p_int_2_y_17, i64 %p_int_3_y_17, i64 %p_int_4_y_17, i64 %p_int_5_y_17, i64 %p_int_6_y_35, i64 %p_int_7_y_34, i64 %p_int_8_y_34, i64 %p_int_0_z_17, i64 %p_int_1_z_17, i64 %p_int_2_z_17, i64 %p_int_3_z_17, i64 %p_int_4_z_17, i64 %p_int_5_z_17, i64 %p_int_6_z_34, i64 %p_int_7_z_34, i64 %p_int_8_z_34, i64 %p_int_6_vx_77, i64 %p_int_7_vx_77, i64 %p_int_8_vx_77, i64 %p_int_vx_3_8, i64 %p_int_vx_4_8, i64 %p_int_vx_5_8, i64 %p_int_vx_6_8, i64 %p_int_vx_7_8, i64 %p_int_vx_8_8, i64 %p_int_6_vy_77, i64 %p_int_7_vy_77, i64 %p_int_8_vy_77, i64 %p_int_vy_3_8, i64 %p_int_vy_4_8, i64 %p_int_vy_5_8, i64 %p_int_vy_6_8, i64 %p_int_vy_7_8, i64 %p_int_vy_8_8, i64 %p_int_6_vz_77, i64 %p_int_7_vz_77, i64 %p_int_8_vz_77, i64 %p_int_vz_3_8, i64 %p_int_vz_4_8, i64 %p_int_vz_5_8, i64 %p_int_vz_6_8, i64 %p_int_vz_7_8, i64 %p_int_vz_8_8)
  %p_int_0_x_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 0
  %p_int_1_x_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 1
  %p_int_2_x_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 2
  %p_int_3_x_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 3
  %p_int_4_x_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 4
  %p_int_5_x_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 5
  %p_int_6_x_36 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 6
  %p_int_7_x_35 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 7
  %p_int_8_x_35 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 8
  %p_int_0_y_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 9
  %p_int_1_y_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 10
  %p_int_2_y_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 11
  %p_int_3_y_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 12
  %p_int_4_y_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 13
  %p_int_5_y_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 14
  %p_int_6_y_36 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 15
  %p_int_7_y_35 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 16
  %p_int_8_y_35 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 17
  %p_int_0_z_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 18
  %p_int_1_z_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 19
  %p_int_2_z_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 20
  %p_int_3_z_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 21
  %p_int_4_z_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 22
  %p_int_5_z_18 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 23
  %p_int_6_z_35 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 24
  %p_int_7_z_35 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 25
  %p_int_8_z_35 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret17, 26
  call fastcc void @to_double(i64 %p_int_0_x_18, i64 %p_int_1_x_18, i64 %p_int_2_x_18, i64 %p_int_3_x_18, i64 %p_int_4_x_18, i64 %p_int_5_x_18, i64 %p_int_6_x_36, i64 %p_int_7_x_35, i64 %p_int_8_x_35, i64 %p_int_0_y_18, i64 %p_int_1_y_18, i64 %p_int_2_y_18, i64 %p_int_3_y_18, i64 %p_int_4_y_18, i64 %p_int_5_y_18, i64 %p_int_6_y_36, i64 %p_int_7_y_35, i64 %p_int_8_y_35, i64 %p_int_0_z_18, i64 %p_int_1_z_18, i64 %p_int_2_z_18, i64 %p_int_3_z_18, i64 %p_int_4_z_18, i64 %p_int_5_z_18, i64 %p_int_6_z_35, i64 %p_int_7_z_35, i64 %p_int_8_z_35, i64 %p_int_6_vx_77, i64 %p_int_7_vx_77, i64 %p_int_8_vx_77, i64 %p_int_vx_3_8, i64 %p_int_vx_4_8, i64 %p_int_vx_5_8, i64 %p_int_vx_6_8, i64 %p_int_vx_7_8, i64 %p_int_vx_8_8, i64 %p_int_6_vy_77, i64 %p_int_7_vy_77, i64 %p_int_8_vy_77, i64 %p_int_vy_3_8, i64 %p_int_vy_4_8, i64 %p_int_vy_5_8, i64 %p_int_vy_6_8, i64 %p_int_vy_7_8, i64 %p_int_vy_8_8, i64 %p_int_6_vz_77, i64 %p_int_7_vz_77, i64 %p_int_8_vz_77, i64 %p_int_vz_3_8, i64 %p_int_vz_4_8, i64 %p_int_vz_5_8, i64 %p_int_vz_6_8, i64 %p_int_vz_7_8, i64 %p_int_vz_8_8)
  %empty_37 = call i32 (...)* @_ssdm_op_SpecRegionEnd([7 x i8]* @p_str5, i32 %tmp_34)
  %tmp_36 = call i32 (...)* @_ssdm_op_SpecRegionBegin([7 x i8]* @p_str5)
  %drift_ret18 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_18, i64 %p_int_1_x_18, i64 %p_int_2_x_18, i64 %p_int_3_x_18, i64 %p_int_4_x_18, i64 %p_int_5_x_18, i64 %p_int_6_x_36, i64 %p_int_7_x_35, i64 %p_int_8_x_35, i64 %p_int_0_y_18, i64 %p_int_1_y_18, i64 %p_int_2_y_18, i64 %p_int_3_y_18, i64 %p_int_4_y_18, i64 %p_int_5_y_18, i64 %p_int_6_y_36, i64 %p_int_7_y_35, i64 %p_int_8_y_35, i64 %p_int_0_z_18, i64 %p_int_1_z_18, i64 %p_int_2_z_18, i64 %p_int_3_z_18, i64 %p_int_4_z_18, i64 %p_int_5_z_18, i64 %p_int_6_z_35, i64 %p_int_7_z_35, i64 %p_int_8_z_35, i64 %p_int_6_vx_77, i64 %p_int_7_vx_77, i64 %p_int_8_vx_77, i64 %p_int_vx_3_8, i64 %p_int_vx_4_8, i64 %p_int_vx_5_8, i64 %p_int_vx_6_8, i64 %p_int_vx_7_8, i64 %p_int_vx_8_8, i64 %p_int_6_vy_77, i64 %p_int_7_vy_77, i64 %p_int_8_vy_77, i64 %p_int_vy_3_8, i64 %p_int_vy_4_8, i64 %p_int_vy_5_8, i64 %p_int_vy_6_8, i64 %p_int_vy_7_8, i64 %p_int_vy_8_8, i64 %p_int_6_vz_77, i64 %p_int_7_vz_77, i64 %p_int_8_vz_77, i64 %p_int_vz_3_8, i64 %p_int_vz_4_8, i64 %p_int_vz_5_8, i64 %p_int_vz_6_8, i64 %p_int_vz_7_8, i64 %p_int_vz_8_8)
  %p_int_0_x_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 0
  %p_int_1_x_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 1
  %p_int_2_x_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 2
  %p_int_3_x_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 3
  %p_int_4_x_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 4
  %p_int_5_x_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 5
  %p_int_6_x_37 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 6
  %p_int_7_x_36 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 7
  %p_int_8_x_36 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 8
  %p_int_0_y_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 9
  %p_int_1_y_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 10
  %p_int_2_y_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 11
  %p_int_3_y_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 12
  %p_int_4_y_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 13
  %p_int_5_y_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 14
  %p_int_6_y_37 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 15
  %p_int_7_y_36 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 16
  %p_int_8_y_36 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 17
  %p_int_0_z_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 18
  %p_int_1_z_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 19
  %p_int_2_z_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 20
  %p_int_3_z_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 21
  %p_int_4_z_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 22
  %p_int_5_z_19 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 23
  %p_int_6_z_36 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 24
  %p_int_7_z_36 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 25
  %p_int_8_z_36 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret18, 26
  call fastcc void @to_double(i64 %p_int_0_x_19, i64 %p_int_1_x_19, i64 %p_int_2_x_19, i64 %p_int_3_x_19, i64 %p_int_4_x_19, i64 %p_int_5_x_19, i64 %p_int_6_x_37, i64 %p_int_7_x_36, i64 %p_int_8_x_36, i64 %p_int_0_y_19, i64 %p_int_1_y_19, i64 %p_int_2_y_19, i64 %p_int_3_y_19, i64 %p_int_4_y_19, i64 %p_int_5_y_19, i64 %p_int_6_y_37, i64 %p_int_7_y_36, i64 %p_int_8_y_36, i64 %p_int_0_z_19, i64 %p_int_1_z_19, i64 %p_int_2_z_19, i64 %p_int_3_z_19, i64 %p_int_4_z_19, i64 %p_int_5_z_19, i64 %p_int_6_z_36, i64 %p_int_7_z_36, i64 %p_int_8_z_36, i64 %p_int_6_vx_77, i64 %p_int_7_vx_77, i64 %p_int_8_vx_77, i64 %p_int_vx_3_8, i64 %p_int_vx_4_8, i64 %p_int_vx_5_8, i64 %p_int_vx_6_8, i64 %p_int_vx_7_8, i64 %p_int_vx_8_8, i64 %p_int_6_vy_77, i64 %p_int_7_vy_77, i64 %p_int_8_vy_77, i64 %p_int_vy_3_8, i64 %p_int_vy_4_8, i64 %p_int_vy_5_8, i64 %p_int_vy_6_8, i64 %p_int_vy_7_8, i64 %p_int_vy_8_8, i64 %p_int_6_vz_77, i64 %p_int_7_vz_77, i64 %p_int_8_vz_77, i64 %p_int_vz_3_8, i64 %p_int_vz_4_8, i64 %p_int_vz_5_8, i64 %p_int_vz_6_8, i64 %p_int_vz_7_8, i64 %p_int_vz_8_8)
  call fastcc void @gravity() nounwind
  br label %12

; <label>:12                                      ; preds = %_ifconv1525, %janus_step.exit.8
  %p_int_vz_8_10 = phi i64 [ %p_int_vz_8_8, %janus_step.exit.8 ], [ %p_int_8_vz_43, %_ifconv1525 ]
  %p_int_vz_7_10 = phi i64 [ %p_int_vz_7_8, %janus_step.exit.8 ], [ %p_int_7_vz_43, %_ifconv1525 ]
  %p_int_vz_6_10 = phi i64 [ %p_int_vz_6_8, %janus_step.exit.8 ], [ %p_int_6_vz_43, %_ifconv1525 ]
  %p_int_vz_5_10 = phi i64 [ %p_int_vz_5_8, %janus_step.exit.8 ], [ %p_int_8_vz_45, %_ifconv1525 ]
  %p_int_vz_4_10 = phi i64 [ %p_int_vz_4_8, %janus_step.exit.8 ], [ %p_int_7_vz_45, %_ifconv1525 ]
  %p_int_vz_3_10 = phi i64 [ %p_int_vz_3_8, %janus_step.exit.8 ], [ %p_int_6_vz_45, %_ifconv1525 ]
  %p_int_8_vz_80 = phi i64 [ %p_int_8_vz_77, %janus_step.exit.8 ], [ %p_int_8_vz_81, %_ifconv1525 ]
  %p_int_7_vz_80 = phi i64 [ %p_int_7_vz_77, %janus_step.exit.8 ], [ %p_int_7_vz_81, %_ifconv1525 ]
  %p_int_6_vz_80 = phi i64 [ %p_int_6_vz_77, %janus_step.exit.8 ], [ %p_int_6_vz_81, %_ifconv1525 ]
  %p_int_vy_8_10 = phi i64 [ %p_int_vy_8_8, %janus_step.exit.8 ], [ %p_int_8_vy_43, %_ifconv1525 ]
  %p_int_vy_7_10 = phi i64 [ %p_int_vy_7_8, %janus_step.exit.8 ], [ %p_int_7_vy_43, %_ifconv1525 ]
  %p_int_vy_6_10 = phi i64 [ %p_int_vy_6_8, %janus_step.exit.8 ], [ %p_int_6_vy_43, %_ifconv1525 ]
  %p_int_vy_5_10 = phi i64 [ %p_int_vy_5_8, %janus_step.exit.8 ], [ %p_int_8_vy_45, %_ifconv1525 ]
  %p_int_vy_4_10 = phi i64 [ %p_int_vy_4_8, %janus_step.exit.8 ], [ %p_int_7_vy_45, %_ifconv1525 ]
  %p_int_vy_3_10 = phi i64 [ %p_int_vy_3_8, %janus_step.exit.8 ], [ %p_int_6_vy_45, %_ifconv1525 ]
  %p_int_8_vy_80 = phi i64 [ %p_int_8_vy_77, %janus_step.exit.8 ], [ %p_int_8_vy_81, %_ifconv1525 ]
  %p_int_7_vy_80 = phi i64 [ %p_int_7_vy_77, %janus_step.exit.8 ], [ %p_int_7_vy_81, %_ifconv1525 ]
  %p_int_6_vy_80 = phi i64 [ %p_int_6_vy_77, %janus_step.exit.8 ], [ %p_int_6_vy_81, %_ifconv1525 ]
  %p_int_vx_8_10 = phi i64 [ %p_int_vx_8_8, %janus_step.exit.8 ], [ %p_int_8_vx_43, %_ifconv1525 ]
  %p_int_vx_7_10 = phi i64 [ %p_int_vx_7_8, %janus_step.exit.8 ], [ %p_int_7_vx_43, %_ifconv1525 ]
  %p_int_vx_6_10 = phi i64 [ %p_int_vx_6_8, %janus_step.exit.8 ], [ %p_int_6_vx_43, %_ifconv1525 ]
  %p_int_vx_5_10 = phi i64 [ %p_int_vx_5_8, %janus_step.exit.8 ], [ %p_int_8_vx_45, %_ifconv1525 ]
  %p_int_vx_4_10 = phi i64 [ %p_int_vx_4_8, %janus_step.exit.8 ], [ %p_int_7_vx_45, %_ifconv1525 ]
  %p_int_vx_3_10 = phi i64 [ %p_int_vx_3_8, %janus_step.exit.8 ], [ %p_int_6_vx_45, %_ifconv1525 ]
  %p_int_8_vx_80 = phi i64 [ %p_int_8_vx_77, %janus_step.exit.8 ], [ %p_int_8_vx_81, %_ifconv1525 ]
  %p_int_7_vx_80 = phi i64 [ %p_int_7_vx_77, %janus_step.exit.8 ], [ %p_int_7_vx_81, %_ifconv1525 ]
  %p_int_6_vx_80 = phi i64 [ %p_int_6_vx_77, %janus_step.exit.8 ], [ %p_int_6_vx_81, %_ifconv1525 ]
  %i_0_i_i_9 = phi i4 [ 0, %janus_step.exit.8 ], [ %i_4_9_2, %_ifconv1525 ]
  %tmp_71_9 = icmp eq i4 %i_0_i_i_9, -7
  br i1 %tmp_71_9, label %janus_step.exit.9, label %_ifconv1525

_ifconv1525:                                      ; preds = %12
  %empty_38 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 3, i64 3, i64 3)
  %tmp_39 = call i32 (...)* @_ssdm_op_SpecRegionBegin([12 x i8]* @p_str7)
  call void (...)* @_ssdm_op_SpecPipeline(i32 -1, i32 1, i32 1, i32 0, [1 x i8]* @p_str) nounwind
  %p_ax_6_load_9 = load double* @p_ax_6, align 16
  %p_ax_0_load_9 = load double* @p_ax_0, align 16
  %p_ax_3_load_9 = load double* @p_ax_3, align 16
  %sel_tmp147 = icmp eq i4 %i_0_i_i_9, 0
  %sel_tmp148 = select i1 %sel_tmp147, double %p_ax_0_load_9, double %p_ax_6_load_9
  %sel_tmp149 = icmp eq i4 %i_0_i_i_9, 3
  %p_ax_load_9_0_phi = select i1 %sel_tmp149, double %p_ax_3_load_9, double %sel_tmp148
  %tmp_73_9 = fmul double %p_ax_load_9_0_phi, 1.000000e-02
  %tmp_74_9 = fmul double %tmp_73_9, 1.000000e+16
  %tmp_75_9 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_9) nounwind
  %p_int_vx_load_9_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vx_80, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i64 %p_int_vx_3_10, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i64 %p_int_vx_6_10, i4 %i_0_i_i_9)
  %p_int_0_vx_10 = add nsw i64 %tmp_75_9, %p_int_vx_load_9_0_ph
  %p_int_6_vx_42 = select i1 %sel_tmp149, i64 %p_int_vx_6_10, i64 %p_int_0_vx_10
  %p_int_6_vx_43 = select i1 %sel_tmp147, i64 %p_int_vx_6_10, i64 %p_int_6_vx_42
  %p_int_6_vx_44 = select i1 %sel_tmp149, i64 %p_int_0_vx_10, i64 %p_int_vx_3_10
  %p_int_6_vx_45 = select i1 %sel_tmp147, i64 %p_int_vx_3_10, i64 %p_int_6_vx_44
  %p_int_6_vx_81 = select i1 %sel_tmp147, i64 %p_int_0_vx_10, i64 %p_int_6_vx_80
  %p_ay_6_load_9 = load double* @p_ay_6, align 8
  %p_ay_0_load_10 = load double* @p_ay_0, align 8
  %p_ay_3_load_10 = load double* @p_ay_3, align 8
  %sel_tmp150 = select i1 %sel_tmp147, double %p_ay_0_load_10, double %p_ay_6_load_9
  %p_ay_load_9_0_phi = select i1 %sel_tmp149, double %p_ay_3_load_10, double %sel_tmp150
  %tmp_77_9 = fmul double %p_ay_load_9_0_phi, 1.000000e-02
  %tmp_78_9 = fmul double %tmp_77_9, 1.000000e+16
  %tmp_79_9 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_9) nounwind
  %p_int_vy_load_9_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vy_80, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i64 %p_int_vy_3_10, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i64 %p_int_vy_6_10, i4 %i_0_i_i_9)
  %p_int_0_vy_10 = add nsw i64 %tmp_79_9, %p_int_vy_load_9_0_ph
  %p_int_6_vy_42 = select i1 %sel_tmp149, i64 %p_int_vy_6_10, i64 %p_int_0_vy_10
  %p_int_6_vy_43 = select i1 %sel_tmp147, i64 %p_int_vy_6_10, i64 %p_int_6_vy_42
  %p_int_6_vy_44 = select i1 %sel_tmp149, i64 %p_int_0_vy_10, i64 %p_int_vy_3_10
  %p_int_6_vy_45 = select i1 %sel_tmp147, i64 %p_int_vy_3_10, i64 %p_int_6_vy_44
  %p_int_6_vy_81 = select i1 %sel_tmp147, i64 %p_int_0_vy_10, i64 %p_int_6_vy_80
  %p_az_6_load_9 = load double* @p_az_6, align 16
  %p_az_0_load_10 = load double* @p_az_0, align 16
  %p_az_3_load_10 = load double* @p_az_3, align 16
  %sel_tmp151 = select i1 %sel_tmp147, double %p_az_0_load_10, double %p_az_6_load_9
  %p_az_load_9_0_phi = select i1 %sel_tmp149, double %p_az_3_load_10, double %sel_tmp151
  %tmp_81_9 = fmul double %p_az_load_9_0_phi, 1.000000e-02
  %tmp_82_9 = fmul double %tmp_81_9, 1.000000e+16
  %tmp_83_9 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_9) nounwind
  %p_int_vz_load_9_0_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_6_vz_80, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i64 %p_int_vz_3_10, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i64 %p_int_vz_6_10, i4 %i_0_i_i_9)
  %p_int_0_vz_10 = add nsw i64 %tmp_83_9, %p_int_vz_load_9_0_ph
  %p_int_6_vz_42 = select i1 %sel_tmp149, i64 %p_int_vz_6_10, i64 %p_int_0_vz_10
  %p_int_6_vz_43 = select i1 %sel_tmp147, i64 %p_int_vz_6_10, i64 %p_int_6_vz_42
  %p_int_6_vz_44 = select i1 %sel_tmp149, i64 %p_int_0_vz_10, i64 %p_int_vz_3_10
  %p_int_6_vz_45 = select i1 %sel_tmp147, i64 %p_int_vz_3_10, i64 %p_int_6_vz_44
  %p_int_6_vz_81 = select i1 %sel_tmp147, i64 %p_int_0_vz_10, i64 %p_int_6_vz_80
  %empty_39 = call i32 (...)* @_ssdm_op_SpecRegionEnd([12 x i8]* @p_str7, i32 %tmp_39)
  %i_4_9_0_t = add i4 %i_0_i_i_9, 1
  %p_ax_7_load_9 = load double* @p_ax_7, align 16
  %p_ax_1_load_10 = load double* @p_ax_1, align 16
  %p_ax_4_load_10 = load double* @p_ax_4, align 16
  %sel_tmp152 = select i1 %sel_tmp147, double %p_ax_1_load_10, double %p_ax_7_load_9
  %p_ax_load_9_1_phi = select i1 %sel_tmp149, double %p_ax_4_load_10, double %sel_tmp152
  %tmp_73_9_1 = fmul double %p_ax_load_9_1_phi, 1.000000e-02
  %tmp_74_9_1 = fmul double %tmp_73_9_1, 1.000000e+16
  %tmp_75_9_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_9_1) nounwind
  %p_int_vx_load_9_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_7_10, i64 %p_int_7_vx_80, i64 %p_int_vx_7_10, i64 %p_int_vx_7_10, i64 %p_int_vx_4_10, i64 %p_int_vx_7_10, i64 %p_int_vx_7_10, i64 %p_int_vx_7_10, i64 %p_int_vx_7_10, i64 %p_int_vx_7_10, i64 %p_int_vx_7_10, i64 %p_int_vx_7_10, i64 %p_int_vx_7_10, i64 %p_int_vx_7_10, i64 %p_int_vx_7_10, i64 %p_int_vx_7_10, i4 %i_4_9_0_t)
  %p_int_1_vx_10 = add nsw i64 %tmp_75_9_1, %p_int_vx_load_9_1_ph
  %p_int_7_vx_42 = select i1 %sel_tmp149, i64 %p_int_vx_7_10, i64 %p_int_1_vx_10
  %p_int_7_vx_43 = select i1 %sel_tmp147, i64 %p_int_vx_7_10, i64 %p_int_7_vx_42
  %p_int_7_vx_44 = select i1 %sel_tmp149, i64 %p_int_1_vx_10, i64 %p_int_vx_4_10
  %p_int_7_vx_45 = select i1 %sel_tmp147, i64 %p_int_vx_4_10, i64 %p_int_7_vx_44
  %p_int_7_vx_81 = select i1 %sel_tmp147, i64 %p_int_1_vx_10, i64 %p_int_7_vx_80
  %p_ay_7_load_9 = load double* @p_ay_7, align 8
  %p_ay_1_load_10 = load double* @p_ay_1, align 8
  %p_ay_4_load_10 = load double* @p_ay_4, align 8
  %sel_tmp153 = select i1 %sel_tmp147, double %p_ay_1_load_10, double %p_ay_7_load_9
  %p_ay_load_9_1_phi = select i1 %sel_tmp149, double %p_ay_4_load_10, double %sel_tmp153
  %tmp_77_9_1 = fmul double %p_ay_load_9_1_phi, 1.000000e-02
  %tmp_78_9_1 = fmul double %tmp_77_9_1, 1.000000e+16
  %tmp_79_9_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_9_1) nounwind
  %p_int_vy_load_9_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_7_10, i64 %p_int_7_vy_80, i64 %p_int_vy_7_10, i64 %p_int_vy_7_10, i64 %p_int_vy_4_10, i64 %p_int_vy_7_10, i64 %p_int_vy_7_10, i64 %p_int_vy_7_10, i64 %p_int_vy_7_10, i64 %p_int_vy_7_10, i64 %p_int_vy_7_10, i64 %p_int_vy_7_10, i64 %p_int_vy_7_10, i64 %p_int_vy_7_10, i64 %p_int_vy_7_10, i64 %p_int_vy_7_10, i4 %i_4_9_0_t)
  %p_int_1_vy_10 = add nsw i64 %tmp_79_9_1, %p_int_vy_load_9_1_ph
  %p_int_7_vy_42 = select i1 %sel_tmp149, i64 %p_int_vy_7_10, i64 %p_int_1_vy_10
  %p_int_7_vy_43 = select i1 %sel_tmp147, i64 %p_int_vy_7_10, i64 %p_int_7_vy_42
  %p_int_7_vy_44 = select i1 %sel_tmp149, i64 %p_int_1_vy_10, i64 %p_int_vy_4_10
  %p_int_7_vy_45 = select i1 %sel_tmp147, i64 %p_int_vy_4_10, i64 %p_int_7_vy_44
  %p_int_7_vy_81 = select i1 %sel_tmp147, i64 %p_int_1_vy_10, i64 %p_int_7_vy_80
  %p_az_7_load_9 = load double* @p_az_7, align 16
  %p_az_1_load_10 = load double* @p_az_1, align 16
  %p_az_4_load_10 = load double* @p_az_4, align 16
  %sel_tmp154 = select i1 %sel_tmp147, double %p_az_1_load_10, double %p_az_7_load_9
  %p_az_load_9_1_phi = select i1 %sel_tmp149, double %p_az_4_load_10, double %sel_tmp154
  %tmp_81_9_1 = fmul double %p_az_load_9_1_phi, 1.000000e-02
  %tmp_82_9_1 = fmul double %tmp_81_9_1, 1.000000e+16
  %tmp_83_9_1 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_9_1) nounwind
  %p_int_vz_load_9_1_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_7_10, i64 %p_int_7_vz_80, i64 %p_int_vz_7_10, i64 %p_int_vz_7_10, i64 %p_int_vz_4_10, i64 %p_int_vz_7_10, i64 %p_int_vz_7_10, i64 %p_int_vz_7_10, i64 %p_int_vz_7_10, i64 %p_int_vz_7_10, i64 %p_int_vz_7_10, i64 %p_int_vz_7_10, i64 %p_int_vz_7_10, i64 %p_int_vz_7_10, i64 %p_int_vz_7_10, i64 %p_int_vz_7_10, i4 %i_4_9_0_t)
  %p_int_1_vz_10 = add nsw i64 %tmp_83_9_1, %p_int_vz_load_9_1_ph
  %p_int_7_vz_42 = select i1 %sel_tmp149, i64 %p_int_vz_7_10, i64 %p_int_1_vz_10
  %p_int_7_vz_43 = select i1 %sel_tmp147, i64 %p_int_vz_7_10, i64 %p_int_7_vz_42
  %p_int_7_vz_44 = select i1 %sel_tmp149, i64 %p_int_1_vz_10, i64 %p_int_vz_4_10
  %p_int_7_vz_45 = select i1 %sel_tmp147, i64 %p_int_vz_4_10, i64 %p_int_7_vz_44
  %p_int_7_vz_81 = select i1 %sel_tmp147, i64 %p_int_1_vz_10, i64 %p_int_7_vz_80
  %i_4_9_1_t = add i4 %i_0_i_i_9, 2
  %p_ax_8_load_9 = load double* @p_ax_8, align 16
  %p_ax_2_load_10 = load double* @p_ax_2, align 16
  %p_ax_5_load_10 = load double* @p_ax_5, align 16
  %sel_tmp155 = select i1 %sel_tmp147, double %p_ax_2_load_10, double %p_ax_8_load_9
  %p_ax_load_9_2_phi = select i1 %sel_tmp149, double %p_ax_5_load_10, double %sel_tmp155
  %tmp_73_9_2 = fmul double %p_ax_load_9_2_phi, 1.000000e-02
  %tmp_74_9_2 = fmul double %tmp_73_9_2, 1.000000e+16
  %tmp_75_9_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_74_9_2) nounwind
  %p_int_vx_load_9_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vx_8_10, i64 %p_int_vx_8_10, i64 %p_int_8_vx_80, i64 %p_int_vx_8_10, i64 %p_int_vx_8_10, i64 %p_int_vx_5_10, i64 %p_int_vx_8_10, i64 %p_int_vx_8_10, i64 %p_int_vx_8_10, i64 %p_int_vx_8_10, i64 %p_int_vx_8_10, i64 %p_int_vx_8_10, i64 %p_int_vx_8_10, i64 %p_int_vx_8_10, i64 %p_int_vx_8_10, i64 %p_int_vx_8_10, i4 %i_4_9_1_t)
  %p_int_2_vx_10 = add nsw i64 %tmp_75_9_2, %p_int_vx_load_9_2_ph
  %p_int_8_vx_42 = select i1 %sel_tmp149, i64 %p_int_vx_8_10, i64 %p_int_2_vx_10
  %p_int_8_vx_43 = select i1 %sel_tmp147, i64 %p_int_vx_8_10, i64 %p_int_8_vx_42
  %p_int_8_vx_44 = select i1 %sel_tmp149, i64 %p_int_2_vx_10, i64 %p_int_vx_5_10
  %p_int_8_vx_45 = select i1 %sel_tmp147, i64 %p_int_vx_5_10, i64 %p_int_8_vx_44
  %p_int_8_vx_81 = select i1 %sel_tmp147, i64 %p_int_2_vx_10, i64 %p_int_8_vx_80
  %p_ay_8_load_9 = load double* @p_ay_8, align 8
  %p_ay_2_load_10 = load double* @p_ay_2, align 8
  %p_ay_5_load_10 = load double* @p_ay_5, align 8
  %sel_tmp156 = select i1 %sel_tmp147, double %p_ay_2_load_10, double %p_ay_8_load_9
  %p_ay_load_9_2_phi = select i1 %sel_tmp149, double %p_ay_5_load_10, double %sel_tmp156
  %tmp_77_9_2 = fmul double %p_ay_load_9_2_phi, 1.000000e-02
  %tmp_78_9_2 = fmul double %tmp_77_9_2, 1.000000e+16
  %tmp_79_9_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_78_9_2) nounwind
  %p_int_vy_load_9_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vy_8_10, i64 %p_int_vy_8_10, i64 %p_int_8_vy_80, i64 %p_int_vy_8_10, i64 %p_int_vy_8_10, i64 %p_int_vy_5_10, i64 %p_int_vy_8_10, i64 %p_int_vy_8_10, i64 %p_int_vy_8_10, i64 %p_int_vy_8_10, i64 %p_int_vy_8_10, i64 %p_int_vy_8_10, i64 %p_int_vy_8_10, i64 %p_int_vy_8_10, i64 %p_int_vy_8_10, i64 %p_int_vy_8_10, i4 %i_4_9_1_t)
  %p_int_2_vy_10 = add nsw i64 %tmp_79_9_2, %p_int_vy_load_9_2_ph
  %p_int_8_vy_42 = select i1 %sel_tmp149, i64 %p_int_vy_8_10, i64 %p_int_2_vy_10
  %p_int_8_vy_43 = select i1 %sel_tmp147, i64 %p_int_vy_8_10, i64 %p_int_8_vy_42
  %p_int_8_vy_44 = select i1 %sel_tmp149, i64 %p_int_2_vy_10, i64 %p_int_vy_5_10
  %p_int_8_vy_45 = select i1 %sel_tmp147, i64 %p_int_vy_5_10, i64 %p_int_8_vy_44
  %p_int_8_vy_81 = select i1 %sel_tmp147, i64 %p_int_2_vy_10, i64 %p_int_8_vy_80
  %p_az_8_load_9 = load double* @p_az_8, align 16
  %p_az_2_load_10 = load double* @p_az_2, align 16
  %p_az_5_load_10 = load double* @p_az_5, align 16
  %sel_tmp157 = select i1 %sel_tmp147, double %p_az_2_load_10, double %p_az_8_load_9
  %p_az_load_9_2_phi = select i1 %sel_tmp149, double %p_az_5_load_10, double %sel_tmp157
  %tmp_81_9_2 = fmul double %p_az_load_9_2_phi, 1.000000e-02
  %tmp_82_9_2 = fmul double %tmp_81_9_2, 1.000000e+16
  %tmp_83_9_2 = call fastcc i64 @__hls_fptosi_double_(double %tmp_82_9_2) nounwind
  %p_int_vz_load_9_2_ph = call i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64 %p_int_vz_8_10, i64 %p_int_vz_8_10, i64 %p_int_8_vz_80, i64 %p_int_vz_8_10, i64 %p_int_vz_8_10, i64 %p_int_vz_5_10, i64 %p_int_vz_8_10, i64 %p_int_vz_8_10, i64 %p_int_vz_8_10, i64 %p_int_vz_8_10, i64 %p_int_vz_8_10, i64 %p_int_vz_8_10, i64 %p_int_vz_8_10, i64 %p_int_vz_8_10, i64 %p_int_vz_8_10, i64 %p_int_vz_8_10, i4 %i_4_9_1_t)
  %p_int_2_vz_10 = add nsw i64 %tmp_83_9_2, %p_int_vz_load_9_2_ph
  %p_int_8_vz_42 = select i1 %sel_tmp149, i64 %p_int_vz_8_10, i64 %p_int_2_vz_10
  %p_int_8_vz_43 = select i1 %sel_tmp147, i64 %p_int_vz_8_10, i64 %p_int_8_vz_42
  %p_int_8_vz_44 = select i1 %sel_tmp149, i64 %p_int_2_vz_10, i64 %p_int_vz_5_10
  %p_int_8_vz_45 = select i1 %sel_tmp147, i64 %p_int_vz_5_10, i64 %p_int_8_vz_44
  %p_int_8_vz_81 = select i1 %sel_tmp147, i64 %p_int_2_vz_10, i64 %p_int_8_vz_80
  %i_4_9_2 = add i4 %i_0_i_i_9, 3
  br label %12

janus_step.exit.9:                                ; preds = %12
  %drift_ret19 = call fastcc { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } @drift(i64 %p_int_0_x_19, i64 %p_int_1_x_19, i64 %p_int_2_x_19, i64 %p_int_3_x_19, i64 %p_int_4_x_19, i64 %p_int_5_x_19, i64 %p_int_6_x_37, i64 %p_int_7_x_36, i64 %p_int_8_x_36, i64 %p_int_0_y_19, i64 %p_int_1_y_19, i64 %p_int_2_y_19, i64 %p_int_3_y_19, i64 %p_int_4_y_19, i64 %p_int_5_y_19, i64 %p_int_6_y_37, i64 %p_int_7_y_36, i64 %p_int_8_y_36, i64 %p_int_0_z_19, i64 %p_int_1_z_19, i64 %p_int_2_z_19, i64 %p_int_3_z_19, i64 %p_int_4_z_19, i64 %p_int_5_z_19, i64 %p_int_6_z_36, i64 %p_int_7_z_36, i64 %p_int_8_z_36, i64 %p_int_6_vx_80, i64 %p_int_7_vx_80, i64 %p_int_8_vx_80, i64 %p_int_vx_3_10, i64 %p_int_vx_4_10, i64 %p_int_vx_5_10, i64 %p_int_vx_6_10, i64 %p_int_vx_7_10, i64 %p_int_vx_8_10, i64 %p_int_6_vy_80, i64 %p_int_7_vy_80, i64 %p_int_8_vy_80, i64 %p_int_vy_3_10, i64 %p_int_vy_4_10, i64 %p_int_vy_5_10, i64 %p_int_vy_6_10, i64 %p_int_vy_7_10, i64 %p_int_vy_8_10, i64 %p_int_6_vz_80, i64 %p_int_7_vz_80, i64 %p_int_8_vz_80, i64 %p_int_vz_3_10, i64 %p_int_vz_4_10, i64 %p_int_vz_5_10, i64 %p_int_vz_6_10, i64 %p_int_vz_7_10, i64 %p_int_vz_8_10)
  %p_int_0_x_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 0
  %p_int_1_x_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 1
  %p_int_2_x_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 2
  %p_int_3_x_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 3
  %p_int_4_x_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 4
  %p_int_5_x_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 5
  %p_int_6_x_38 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 6
  %p_int_7_x_37 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 7
  %p_int_8_x_37 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 8
  %p_int_0_y_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 9
  %p_int_1_y_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 10
  %p_int_2_y_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 11
  %p_int_3_y_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 12
  %p_int_4_y_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 13
  %p_int_5_y_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 14
  %p_int_6_y_38 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 15
  %p_int_7_y_37 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 16
  %p_int_8_y_37 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 17
  %p_int_0_z_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 18
  %p_int_1_z_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 19
  %p_int_2_z_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 20
  %p_int_3_z_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 21
  %p_int_4_z_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 22
  %p_int_5_z_20 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 23
  %p_int_6_z_37 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 24
  %p_int_7_z_37 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 25
  %p_int_8_z_37 = extractvalue { i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64 } %drift_ret19, 26
  call fastcc void @to_double(i64 %p_int_0_x_20, i64 %p_int_1_x_20, i64 %p_int_2_x_20, i64 %p_int_3_x_20, i64 %p_int_4_x_20, i64 %p_int_5_x_20, i64 %p_int_6_x_38, i64 %p_int_7_x_37, i64 %p_int_8_x_37, i64 %p_int_0_y_20, i64 %p_int_1_y_20, i64 %p_int_2_y_20, i64 %p_int_3_y_20, i64 %p_int_4_y_20, i64 %p_int_5_y_20, i64 %p_int_6_y_38, i64 %p_int_7_y_37, i64 %p_int_8_y_37, i64 %p_int_0_z_20, i64 %p_int_1_z_20, i64 %p_int_2_z_20, i64 %p_int_3_z_20, i64 %p_int_4_z_20, i64 %p_int_5_z_20, i64 %p_int_6_z_37, i64 %p_int_7_z_37, i64 %p_int_8_z_37, i64 %p_int_6_vx_80, i64 %p_int_7_vx_80, i64 %p_int_8_vx_80, i64 %p_int_vx_3_10, i64 %p_int_vx_4_10, i64 %p_int_vx_5_10, i64 %p_int_vx_6_10, i64 %p_int_vx_7_10, i64 %p_int_vx_8_10, i64 %p_int_6_vy_80, i64 %p_int_7_vy_80, i64 %p_int_8_vy_80, i64 %p_int_vy_3_10, i64 %p_int_vy_4_10, i64 %p_int_vy_5_10, i64 %p_int_vy_6_10, i64 %p_int_vy_7_10, i64 %p_int_vy_8_10, i64 %p_int_6_vz_80, i64 %p_int_7_vz_80, i64 %p_int_8_vz_80, i64 %p_int_vz_3_10, i64 %p_int_vz_4_10, i64 %p_int_vz_5_10, i64 %p_int_vz_6_10, i64 %p_int_vz_7_10, i64 %p_int_vz_8_10)
  %empty_40 = call i32 (...)* @_ssdm_op_SpecRegionEnd([7 x i8]* @p_str5, i32 %tmp_36)
  %t_1_9 = add nsw i32 %t, 10
  br label %to_int.exit.0

burst.wr.header:                                  ; preds = %burst.wr.header.preheader, %burst.wr.body_ifconv
  %indvar = phi i3 [ %indvar_next, %burst.wr.body_ifconv ], [ 0, %burst.wr.header.preheader ]
  %exitcond1 = icmp eq i3 %indvar, -2
  %indvar_next = add i3 %indvar, 1
  br i1 %exitcond1, label %burst.wr.end, label %burst.wr.body_ifconv

burst.wr.body_ifconv:                             ; preds = %burst.wr.header
  %empty_41 = call i32 (...)* @_ssdm_op_SpecLoopTripCount(i64 6, i64 6, i64 6)
  %burstwrite_rbegin = call i32 (...)* @_ssdm_op_SpecRegionBegin([18 x i8]* @burstwrite_OC_region)
  call void (...)* @_ssdm_op_SpecPipeline(i32 1, i32 1, i32 1, i32 0, [1 x i8]* @p_str)
  call void (...)* @_ssdm_op_SpecLoopName([17 x i8]* @memcpy_OC_result_OC_s)
  %p_x_5_load = load double* @p_x_5, align 8
  %p_x_0_load_1 = load double* @p_x_0, align 8
  %p_x_1_load = load double* @p_x_1, align 8
  %p_x_2_load = load double* @p_x_2, align 8
  %p_x_3_load_1 = load double* @p_x_3, align 8
  %p_x_4_load = load double* @p_x_4, align 8
  %sel_tmp47 = icmp eq i3 %indvar, 0
  %sel_tmp48 = select i1 %sel_tmp47, double %p_x_0_load_1, double %p_x_5_load
  %sel_tmp49 = icmp eq i3 %indvar, 1
  %sel_tmp50 = select i1 %sel_tmp49, double %p_x_1_load, double %sel_tmp48
  %sel_tmp51 = icmp eq i3 %indvar, 2
  %sel_tmp52 = select i1 %sel_tmp51, double %p_x_2_load, double %sel_tmp50
  %sel_tmp53 = icmp eq i3 %indvar, 3
  %sel_tmp54 = select i1 %sel_tmp53, double %p_x_3_load_1, double %sel_tmp52
  %sel_tmp55 = icmp eq i3 %indvar, -4
  %p_x_gep3_phi = select i1 %sel_tmp55, double %p_x_4_load, double %sel_tmp54
  call void @_ssdm_op_Write.m_axi.doubleP(double* %result_x, double %p_x_gep3_phi, i8 -1)
  %p_y_5_load = load double* @p_y_5, align 8
  %p_y_0_load_1 = load double* @p_y_0, align 8
  %p_y_1_load = load double* @p_y_1, align 8
  %p_y_2_load = load double* @p_y_2, align 8
  %p_y_3_load_1 = load double* @p_y_3, align 8
  %p_y_4_load = load double* @p_y_4, align 8
  %sel_tmp56 = select i1 %sel_tmp47, double %p_y_0_load_1, double %p_y_5_load
  %sel_tmp57 = select i1 %sel_tmp49, double %p_y_1_load, double %sel_tmp56
  %sel_tmp58 = select i1 %sel_tmp51, double %p_y_2_load, double %sel_tmp57
  %sel_tmp59 = select i1 %sel_tmp53, double %p_y_3_load_1, double %sel_tmp58
  %p_y_gep6_phi = select i1 %sel_tmp55, double %p_y_4_load, double %sel_tmp59
  call void @_ssdm_op_Write.m_axi.doubleP(double* %result_y, double %p_y_gep6_phi, i8 -1)
  %p_z_5_load = load double* @p_z_5, align 8
  %p_z_0_load_1 = load double* @p_z_0, align 8
  %p_z_1_load = load double* @p_z_1, align 8
  %p_z_2_load = load double* @p_z_2, align 8
  %p_z_3_load_1 = load double* @p_z_3, align 8
  %p_z_4_load = load double* @p_z_4, align 8
  %sel_tmp60 = select i1 %sel_tmp47, double %p_z_0_load_1, double %p_z_5_load
  %sel_tmp61 = select i1 %sel_tmp49, double %p_z_1_load, double %sel_tmp60
  %sel_tmp62 = select i1 %sel_tmp51, double %p_z_2_load, double %sel_tmp61
  %sel_tmp63 = select i1 %sel_tmp53, double %p_z_3_load_1, double %sel_tmp62
  %p_z_gep9_phi = select i1 %sel_tmp55, double %p_z_4_load, double %sel_tmp63
  call void @_ssdm_op_Write.m_axi.doubleP(double* %result_z, double %p_z_gep9_phi, i8 -1)
  %p_vx_5_load = load double* @p_vx_5, align 8
  %p_vx_0_load_1 = load double* @p_vx_0, align 8
  %p_vx_1_load = load double* @p_vx_1, align 8
  %p_vx_2_load = load double* @p_vx_2, align 8
  %p_vx_3_load_1 = load double* @p_vx_3, align 8
  %p_vx_4_load = load double* @p_vx_4, align 8
  %sel_tmp64 = select i1 %sel_tmp47, double %p_vx_0_load_1, double %p_vx_5_load
  %sel_tmp65 = select i1 %sel_tmp49, double %p_vx_1_load, double %sel_tmp64
  %sel_tmp66 = select i1 %sel_tmp51, double %p_vx_2_load, double %sel_tmp65
  %sel_tmp67 = select i1 %sel_tmp53, double %p_vx_3_load_1, double %sel_tmp66
  %p_vx_gep12_phi = select i1 %sel_tmp55, double %p_vx_4_load, double %sel_tmp67
  call void @_ssdm_op_Write.m_axi.doubleP(double* %result_vx, double %p_vx_gep12_phi, i8 -1)
  %p_vy_5_load = load double* @p_vy_5, align 8
  %p_vy_0_load_1 = load double* @p_vy_0, align 8
  %p_vy_1_load = load double* @p_vy_1, align 8
  %p_vy_2_load = load double* @p_vy_2, align 8
  %p_vy_3_load_1 = load double* @p_vy_3, align 8
  %p_vy_4_load = load double* @p_vy_4, align 8
  %sel_tmp68 = select i1 %sel_tmp47, double %p_vy_0_load_1, double %p_vy_5_load
  %sel_tmp69 = select i1 %sel_tmp49, double %p_vy_1_load, double %sel_tmp68
  %sel_tmp70 = select i1 %sel_tmp51, double %p_vy_2_load, double %sel_tmp69
  %sel_tmp71 = select i1 %sel_tmp53, double %p_vy_3_load_1, double %sel_tmp70
  %p_vy_gep15_phi = select i1 %sel_tmp55, double %p_vy_4_load, double %sel_tmp71
  call void @_ssdm_op_Write.m_axi.doubleP(double* %result_vy, double %p_vy_gep15_phi, i8 -1)
  %p_vz_5_load = load double* @p_vz_5, align 8
  %p_vz_0_load = load double* @p_vz_0, align 8
  %p_vz_1_load = load double* @p_vz_1, align 8
  %p_vz_2_load = load double* @p_vz_2, align 8
  %p_vz_3_load = load double* @p_vz_3, align 8
  %p_vz_4_load = load double* @p_vz_4, align 8
  %sel_tmp72 = select i1 %sel_tmp47, double %p_vz_0_load, double %p_vz_5_load
  %sel_tmp73 = select i1 %sel_tmp49, double %p_vz_1_load, double %sel_tmp72
  %sel_tmp74 = select i1 %sel_tmp51, double %p_vz_2_load, double %sel_tmp73
  %sel_tmp75 = select i1 %sel_tmp53, double %p_vz_3_load, double %sel_tmp74
  %p_vz_gep18_phi = select i1 %sel_tmp55, double %p_vz_4_load, double %sel_tmp75
  call void @_ssdm_op_Write.m_axi.doubleP(double* %result_vz, double %p_vz_gep18_phi, i8 -1)
  %p_ax_5_load = load double* @p_ax_5, align 8
  %p_ax_0_load_10 = load double* @p_ax_0, align 8
  %p_ax_1_load_1 = load double* @p_ax_1, align 8
  %p_ax_2_load = load double* @p_ax_2, align 8
  %p_ax_3_load_10 = load double* @p_ax_3, align 8
  %p_ax_4_load_1 = load double* @p_ax_4, align 8
  %sel_tmp76 = select i1 %sel_tmp47, double %p_ax_0_load_10, double %p_ax_5_load
  %sel_tmp77 = select i1 %sel_tmp49, double %p_ax_1_load_1, double %sel_tmp76
  %sel_tmp78 = select i1 %sel_tmp51, double %p_ax_2_load, double %sel_tmp77
  %sel_tmp79 = select i1 %sel_tmp53, double %p_ax_3_load_10, double %sel_tmp78
  %p_ax_gep21_phi = select i1 %sel_tmp55, double %p_ax_4_load_1, double %sel_tmp79
  call void @_ssdm_op_Write.m_axi.doubleP(double* %result_ax, double %p_ax_gep21_phi, i8 -1)
  %p_ay_5_load = load double* @p_ay_5, align 8
  %p_ay_0_load_8 = load double* @p_ay_0, align 8
  %p_ay_1_load = load double* @p_ay_1, align 8
  %p_ay_2_load = load double* @p_ay_2, align 8
  %p_ay_3_load_8 = load double* @p_ay_3, align 8
  %p_ay_4_load = load double* @p_ay_4, align 8
  %sel_tmp80 = select i1 %sel_tmp47, double %p_ay_0_load_8, double %p_ay_5_load
  %sel_tmp81 = select i1 %sel_tmp49, double %p_ay_1_load, double %sel_tmp80
  %sel_tmp82 = select i1 %sel_tmp51, double %p_ay_2_load, double %sel_tmp81
  %sel_tmp83 = select i1 %sel_tmp53, double %p_ay_3_load_8, double %sel_tmp82
  %p_ay_gep24_phi = select i1 %sel_tmp55, double %p_ay_4_load, double %sel_tmp83
  call void @_ssdm_op_Write.m_axi.doubleP(double* %result_ay, double %p_ay_gep24_phi, i8 -1)
  %p_az_5_load = load double* @p_az_5, align 8
  %p_az_0_load_6 = load double* @p_az_0, align 8
  %p_az_1_load = load double* @p_az_1, align 8
  %p_az_2_load = load double* @p_az_2, align 8
  %p_az_3_load_6 = load double* @p_az_3, align 8
  %p_az_4_load = load double* @p_az_4, align 8
  %sel_tmp84 = select i1 %sel_tmp47, double %p_az_0_load_6, double %p_az_5_load
  %sel_tmp85 = select i1 %sel_tmp49, double %p_az_1_load, double %sel_tmp84
  %sel_tmp86 = select i1 %sel_tmp51, double %p_az_2_load, double %sel_tmp85
  %sel_tmp87 = select i1 %sel_tmp53, double %p_az_3_load_6, double %sel_tmp86
  %p_az_gep27_phi = select i1 %sel_tmp55, double %p_az_4_load, double %sel_tmp87
  call void @_ssdm_op_Write.m_axi.doubleP(double* %result_az, double %p_az_gep27_phi, i8 -1)
  %p_m_5_load = load double* @p_m_5, align 8
  %p_m_0_load = load double* @p_m_0, align 8
  %p_m_1_load = load double* @p_m_1, align 8
  %p_m_2_load = load double* @p_m_2, align 8
  %p_m_3_load = load double* @p_m_3, align 8
  %p_m_4_load = load double* @p_m_4, align 8
  %sel_tmp88 = select i1 %sel_tmp47, double %p_m_0_load, double %p_m_5_load
  %sel_tmp89 = select i1 %sel_tmp49, double %p_m_1_load, double %sel_tmp88
  %sel_tmp90 = select i1 %sel_tmp51, double %p_m_2_load, double %sel_tmp89
  %sel_tmp91 = select i1 %sel_tmp53, double %p_m_3_load, double %sel_tmp90
  %p_m_gep30_phi = select i1 %sel_tmp55, double %p_m_4_load, double %sel_tmp91
  call void @_ssdm_op_Write.m_axi.doubleP(double* %result_m, double %p_m_gep30_phi, i8 -1)
  %burstwrite_rend = call i32 (...)* @_ssdm_op_SpecRegionEnd([18 x i8]* @burstwrite_OC_region, i32 %burstwrite_rbegin)
  br label %burst.wr.header

burst.wr.end:                                     ; preds = %burst.wr.header
  %result_m_wr_resp = call i1 @_ssdm_op_WriteResp.m_axi.doubleP(double* %result_m)
  %result_az_wr_resp = call i1 @_ssdm_op_WriteResp.m_axi.doubleP(double* %result_az)
  %result_ay_wr_resp = call i1 @_ssdm_op_WriteResp.m_axi.doubleP(double* %result_ay)
  %result_ax_wr_resp = call i1 @_ssdm_op_WriteResp.m_axi.doubleP(double* %result_ax)
  %result_vz_wr_resp = call i1 @_ssdm_op_WriteResp.m_axi.doubleP(double* %result_vz)
  %result_vy_wr_resp = call i1 @_ssdm_op_WriteResp.m_axi.doubleP(double* %result_vy)
  %result_vx_wr_resp = call i1 @_ssdm_op_WriteResp.m_axi.doubleP(double* %result_vx)
  %result_z_wr_resp = call i1 @_ssdm_op_WriteResp.m_axi.doubleP(double* %result_z)
  %result_y_wr_resp = call i1 @_ssdm_op_WriteResp.m_axi.doubleP(double* %result_y)
  %result_x_wr_resp = call i1 @_ssdm_op_WriteResp.m_axi.doubleP(double* %result_x)
  ret void
}

define weak i1 @_ssdm_op_WriteResp.m_axi.doubleP(double*) {
entry:
  ret i1 true
}

define weak i1 @_ssdm_op_WriteReq.m_axi.doubleP(double*, i32) {
entry:
  ret i1 true
}

define weak void @_ssdm_op_Write.m_axi.doubleP(double*, double, i8) {
entry:
  ret void
}

define weak void @_ssdm_op_SpecTopModule(...) {
entry:
  ret void
}

define weak i32 @_ssdm_op_SpecRegionEnd(...) {
entry:
  ret i32 0
}

define weak i32 @_ssdm_op_SpecRegionBegin(...) {
entry:
  ret i32 0
}

define weak void @_ssdm_op_SpecPipeline(...) nounwind {
entry:
  ret void
}

define weak i32 @_ssdm_op_SpecLoopTripCount(...) {
entry:
  ret i32 0
}

define weak void @_ssdm_op_SpecLoopName(...) nounwind {
entry:
  ret void
}

define weak void @_ssdm_op_SpecInterface(...) nounwind {
entry:
  ret void
}

define weak void @_ssdm_op_SpecBitsMap(...) {
entry:
  ret void
}

define weak i64 @_ssdm_op_Read.ap_auto.i64(i64) {
entry:
  ret i64 %0
}

define weak double @_ssdm_op_Read.ap_auto.double(double) {
entry:
  ret double %0
}

define weak i63 @_ssdm_op_PartSelect.i63.i169.i32.i32(i169, i32, i32) nounwind readnone {
entry:
  %empty = call i169 @llvm.part.select.i169(i169 %0, i32 %1, i32 %2)
  %empty_42 = trunc i169 %empty to i63
  ret i63 %empty_42
}

declare i52 @_ssdm_op_PartSelect.i52.i64.i32.i32(i64, i32, i32) nounwind readnone

define weak i11 @_ssdm_op_PartSelect.i11.i64.i32.i32(i64, i32, i32) nounwind readnone {
entry:
  %empty = call i64 @llvm.part.select.i64(i64 %0, i32 %1, i32 %2)
  %empty_43 = trunc i64 %empty to i11
  ret i11 %empty_43
}

define weak i64 @_ssdm_op_Mux.ap_auto.16i64.i4(i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i4) {
entry:
  switch i4 %16, label %case15 [
    i4 0, label %case0
    i4 1, label %case1
    i4 2, label %case2
    i4 3, label %case3
    i4 4, label %case4
    i4 5, label %case5
    i4 6, label %case6
    i4 7, label %case7
    i4 -8, label %case8
    i4 -7, label %case9
    i4 -6, label %case10
    i4 -5, label %case11
    i4 -4, label %case12
    i4 -3, label %case13
    i4 -2, label %case14
  ]

case0:                                            ; preds = %case15, %case14, %case13, %case12, %case11, %case10, %case9, %case8, %case7, %case6, %case5, %case4, %case3, %case2, %case1, %entry
  %merge = phi i64 [ %0, %entry ], [ %1, %case1 ], [ %2, %case2 ], [ %3, %case3 ], [ %4, %case4 ], [ %5, %case5 ], [ %6, %case6 ], [ %7, %case7 ], [ %8, %case8 ], [ %9, %case9 ], [ %10, %case10 ], [ %11, %case11 ], [ %12, %case12 ], [ %13, %case13 ], [ %14, %case14 ], [ %15, %case15 ]
  ret i64 %merge

case1:                                            ; preds = %entry
  br label %case0

case2:                                            ; preds = %entry
  br label %case0

case3:                                            ; preds = %entry
  br label %case0

case4:                                            ; preds = %entry
  br label %case0

case5:                                            ; preds = %entry
  br label %case0

case6:                                            ; preds = %entry
  br label %case0

case7:                                            ; preds = %entry
  br label %case0

case8:                                            ; preds = %entry
  br label %case0

case9:                                            ; preds = %entry
  br label %case0

case10:                                           ; preds = %entry
  br label %case0

case11:                                           ; preds = %entry
  br label %case0

case12:                                           ; preds = %entry
  br label %case0

case13:                                           ; preds = %entry
  br label %case0

case14:                                           ; preds = %entry
  br label %case0

case15:                                           ; preds = %entry
  br label %case0
}

define weak i1 @_ssdm_op_BitSelect.i1.i64.i32(i64, i32) nounwind readnone {
entry:
  %empty = zext i32 %1 to i64
  %empty_44 = shl i64 1, %empty
  %empty_45 = and i64 %0, %empty_44
  %empty_46 = icmp ne i64 %empty_45, 0
  ret i1 %empty_46
}

define weak i1 @_ssdm_op_BitSelect.i1.i54.i32(i54, i32) nounwind readnone {
entry:
  %empty = zext i32 %1 to i54
  %empty_47 = shl i54 1, %empty
  %empty_48 = and i54 %0, %empty_47
  %empty_49 = icmp ne i54 %empty_48, 0
  ret i1 %empty_49
}

define weak i1 @_ssdm_op_BitSelect.i1.i12.i32(i12, i32) nounwind readnone {
entry:
  %empty = trunc i32 %1 to i12
  %empty_50 = shl i12 1, %empty
  %empty_51 = and i12 %0, %empty_50
  %empty_52 = icmp ne i12 %empty_51, 0
  ret i1 %empty_52
}

define weak i54 @_ssdm_op_BitConcatenate.i54.i1.i52.i1(i1, i52, i1) nounwind readnone {
entry:
  %empty = zext i52 %1 to i53
  %empty_53 = zext i1 %2 to i53
  %empty_54 = shl i53 %empty, 1
  %empty_55 = or i53 %empty_54, %empty_53
  %empty_56 = zext i1 %0 to i54
  %empty_57 = zext i53 %empty_55 to i54
  %empty_58 = shl i54 %empty_56, 53
  %empty_59 = or i54 %empty_58, %empty_57
  ret i54 %empty_59
}

define internal fastcc i64 @__hls_fptosi_double_(double %x) nounwind uwtable readnone {
  %x_read = call double @_ssdm_op_Read.ap_auto.double(double %x) nounwind
  %p_Val2_s = bitcast double %x_read to i64
  %p_Result_s = call i1 @_ssdm_op_BitSelect.i1.i64.i32(i64 %p_Val2_s, i32 63)
  %loc_V = call i11 @_ssdm_op_PartSelect.i11.i64.i32.i32(i64 %p_Val2_s, i32 52, i32 62) nounwind
  %loc_V_1 = trunc i64 %p_Val2_s to i52
  %tmp_i_i = call i54 @_ssdm_op_BitConcatenate.i54.i1.i52.i1(i1 true, i52 %loc_V_1, i1 false)
  %tmp_i_i_cast = zext i54 %tmp_i_i to i169
  %tmp_i_i_i_cast1 = zext i11 %loc_V to i12
  %sh_assign = add i12 -1023, %tmp_i_i_i_cast1
  %isNeg = call i1 @_ssdm_op_BitSelect.i1.i12.i32(i12 %sh_assign, i32 11)
  %tmp_1_i_i = sub i11 1023, %loc_V
  %tmp_1_i_i_cast = sext i11 %tmp_1_i_i to i12
  %sh_assign_1 = select i1 %isNeg, i12 %tmp_1_i_i_cast, i12 %sh_assign
  %sh_assign_1_cast = sext i12 %sh_assign_1 to i32
  %tmp_2_i_i = zext i32 %sh_assign_1_cast to i169
  %tmp_2_i_i_cast = zext i32 %sh_assign_1_cast to i54
  %tmp_3_i_i = lshr i54 %tmp_i_i, %tmp_2_i_i_cast
  %tmp_4_i_i = shl i169 %tmp_i_i_cast, %tmp_2_i_i
  %tmp = call i1 @_ssdm_op_BitSelect.i1.i54.i32(i54 %tmp_3_i_i, i32 53)
  %tmp_1 = zext i1 %tmp to i63
  %tmp_2 = call i63 @_ssdm_op_PartSelect.i63.i169.i32.i32(i169 %tmp_4_i_i, i32 53, i32 115)
  %p_Val2_2 = select i1 %isNeg, i63 %tmp_1, i63 %tmp_2
  %tmp_6_i_i = zext i63 %p_Val2_2 to i64
  %tmp_9_i_i = sub nsw i64 0, %tmp_6_i_i
  %p_Val2_4 = select i1 %p_Result_s, i64 %tmp_9_i_i, i64 %tmp_6_i_i
  ret i64 %p_Val2_4
}

declare void @_GLOBAL__I_a() nounwind section ".text.startup"

!opencl.kernels = !{!0, !7, !13, !0, !16, !13, !0, !22, !22, !22, !22, !26, !26, !26, !26, !28, !28, !28, !30, !22, !22, !22, !22, !26, !26, !26, !26, !28, !28, !28, !28, !31, !35, !41, !41, !41, !42, !45, !45, !41, !48, !48, !50, !41, !41, !41, !52, !52, !41, !41, !54, !57, !57, !41, !59, !62, !62, !41, !64, !64, !66, !64, !64, !66, !68, !45, !45, !74, !41, !41, !41, !77, !45, !45, !41, !41, !41, !79, !45, !45, !81, !41, !41, !41, !83, !83, !85, !85, !87, !41, !41, !66, !66, !41, !89, !91, !94, !94, !97, !97, !100, !100, !104, !106, !106, !41, !41, !41, !41, !108, !110, !110, !41, !41, !97, !111, !111, !113, !113, !115, !117, !117, !118, !120, !120, !118, !122, !122, !124, !126, !126, !41, !41, !127, !129, !129, !97, !97, !130, !130, !124, !127, !129, !129, !41, !97, !132, !132, !134, !135, !135, !137, !41, !89, !134, !139, !139, !141, !141, !41, !41, !41, !41, !41, !41, !41, !41, !31, !143, !41, !41, !41, !42, !145, !145, !147, !41, !52, !52, !41, !41, !149, !59, !151, !151, !41, !153, !153, !155, !153, !153, !155, !68, !157, !41, !41, !41, !159, !45, !45, !87, !41, !41, !155, !155, !120, !120, !118, !31, !161, !41, !41, !41, !42, !45, !45, !41, !163, !163, !165, !41, !52, !52, !41, !41, !167, !59, !169, !169, !41, !171, !171, !173, !171, !171, !173, !68, !175, !41, !41, !41, !177, !45, !45, !87, !41, !41, !173, !173, !120, !120, !118, !31, !179, !41, !41, !41, !42, !45, !45, !41, !181, !181, !183, !41, !52, !52, !41, !41, !185, !59, !187, !187, !41, !189, !189, !191, !189, !189, !191, !68, !193, !41, !41, !41, !195, !45, !45, !87, !41, !41, !191, !191, !120, !120, !118, !197, !199, !41, !201, !201, !203, !201, !201, !203, !205, !41, !41, !41, !207, !45, !45, !41, !209, !211, !213, !213, !87, !41, !41, !203, !203, !41, !89, !91, !215, !215, !97, !97, !217, !217, !219, !221, !221, !41, !41, !41, !41, !222, !224, !224, !41, !41, !97, !225, !225, !113, !113, !115, !117, !117, !227, !229, !229, !227, !231, !231, !232, !234, !234, !41, !41, !235, !237, !237, !97, !97, !238, !238, !232, !235, !237, !237, !97, !240, !240, !134, !242, !242, !244, !41, !246, !246, !41, !41, !41, !41, !197, !247, !249, !249, !251, !249, !249, !251, !253, !41, !41, !41, !255, !45, !45, !87, !41, !41, !251, !251, !229, !229, !227, !197, !257, !259, !259, !261, !259, !259, !261, !263, !41, !41, !41, !265, !45, !45, !87, !41, !41, !261, !261, !229, !229, !227, !197, !267, !269, !269, !271, !269, !269, !271, !273, !41, !41, !41, !275, !45, !45, !87, !41, !41, !271, !271, !229, !229, !227, !277, !279, !41, !281, !283, !284, !284, !286, !284, !284, !286, !288, !41, !41, !41, !290, !45, !45, !41, !292, !293, !295, !295, !87, !41, !41, !286, !286, !41, !89, !91, !297, !297, !97, !97, !299, !299, !301, !303, !303, !41, !41, !41, !304, !306, !306, !41, !97, !307, !307, !113, !113, !115, !117, !117, !309, !311, !311, !309, !313, !313, !314, !316, !316, !41, !41, !317, !319, !319, !97, !97, !320, !320, !314, !317, !319, !319, !41, !97, !322, !322, !134, !324, !324, !326, !41, !328, !328, !41, !41, !41, !41, !41, !277, !330, !332, !332, !334, !332, !332, !334, !336, !41, !41, !338, !45, !45, !87, !41, !41, !334, !334, !311, !311, !309, !277, !340, !342, !342, !344, !342, !342, !344, !346, !41, !41, !41, !348, !45, !45, !87, !41, !41, !344, !344, !311, !311, !309, !277, !350, !352, !352, !354, !352, !352, !354, !356, !41, !41, !41, !358, !45, !45, !87, !41, !41, !354, !354, !311, !311, !309, !31, !360, !41, !41, !41, !41, !362, !362, !364, !364, !366, !368, !368, !41, !89, !134, !370, !370, !52, !52, !41, !372, !59, !374, !374, !41, !64, !64, !66, !64, !64, !66, !68, !31, !376, !41, !41, !41, !41, !378, !378, !117, !117, !380, !382, !382, !41, !89, !134, !384, !384, !52, !52, !41, !386, !59, !388, !388, !41, !153, !153, !155, !41, !153, !153, !155, !68, !31, !390, !41, !41, !41, !41, !392, !392, !394, !394, !396, !398, !398, !41, !89, !134, !400, !400, !52, !52, !41, !402, !59, !404, !404, !41, !171, !171, !173, !41, !171, !171, !173, !68, !31, !406, !41, !41, !41, !41, !408, !408, !410, !410, !412, !414, !414, !41, !89, !134, !416, !416, !52, !52, !41, !418, !59, !420, !420, !41, !189, !189, !191, !41, !189, !189, !191, !68, !197, !422, !201, !201, !203, !201, !201, !203, !197, !424, !249, !249, !251, !249, !249, !251, !197, !426, !259, !259, !261, !259, !259, !261, !197, !428, !269, !269, !271, !269, !269, !271, !277, !430, !284, !284, !286, !284, !284, !286, !277, !432, !332, !332, !334, !332, !332, !334, !277, !434, !342, !342, !344, !342, !342, !344, !277, !436, !352, !352, !354, !352, !352, !354, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !438, !438, !438, !438, !438, !438, !438, !438, !438, !442, !442, !443, !41, !445, !41, !41, !41, !447, !447, !449, !449, !451, !41, !41, !41, !453, !41, !41, !41, !41, !455, !41, !113, !113, !115, !117, !117, !457, !442, !442, !443, !455, !113, !113, !115, !117, !117, !459, !442, !442, !443, !455, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !438, !438, !438, !438, !438, !438, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !438, !438, !438, !438, !438, !438, !438, !438, !438, !41, !438, !438, !438, !438, !438, !438, !461, !461, !461, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !461, !461, !461, !41, !461, !461, !461, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438, !41, !438, !438, !438}
!hls.encrypted.func = !{}
!llvm.map.gv = !{!465, !472, !477, !482, !487, !492, !497, !502, !507, !512, !517, !524, !531, !538, !545, !552, !559, !566, !573, !580, !587, !592, !597, !602, !607, !612, !617, !622, !627, !632, !637, !642, !647, !652, !657, !662, !667, !672, !677, !682, !687, !692, !697, !702, !707, !712, !717, !722, !727, !732, !737, !742, !747, !752, !757, !762, !767, !772, !777, !782, !787, !792, !797, !802, !807, !812, !817, !822, !827, !832, !837, !842, !847, !852, !857, !862, !867, !872, !877, !882, !887, !892, !897, !902, !907, !912, !917, !922, !927, !932, !937, !942, !947, !952, !957, !962, !967, !972, !977, !982, !987}

!0 = metadata !{null, metadata !1, metadata !2, metadata !3, metadata !4, metadata !5, metadata !6}
!1 = metadata !{metadata !"kernel_arg_addr_space", i32 1, i32 0}
!2 = metadata !{metadata !"kernel_arg_access_qual", metadata !"none", metadata !"none"}
!3 = metadata !{metadata !"kernel_arg_type", metadata !"struct reb_particle_int*", metadata !"double"}
!4 = metadata !{metadata !"kernel_arg_type_qual", metadata !"", metadata !""}
!5 = metadata !{metadata !"kernel_arg_name", metadata !"p_int", metadata !"dt"}
!6 = metadata !{metadata !"reqd_work_group_size", i32 1, i32 1, i32 1}
!7 = metadata !{null, metadata !8, metadata !9, metadata !10, metadata !11, metadata !12, metadata !6}
!8 = metadata !{metadata !"kernel_arg_addr_space", i32 1}
!9 = metadata !{metadata !"kernel_arg_access_qual", metadata !"none"}
!10 = metadata !{metadata !"kernel_arg_type", metadata !"struct reb_particle*"}
!11 = metadata !{metadata !"kernel_arg_type_qual", metadata !""}
!12 = metadata !{metadata !"kernel_arg_name", metadata !"result"}
!13 = metadata !{null, metadata !8, metadata !9, metadata !14, metadata !11, metadata !15, metadata !6}
!14 = metadata !{metadata !"kernel_arg_type", metadata !"struct reb_particle_int*"}
!15 = metadata !{metadata !"kernel_arg_name", metadata !"p_int"}
!16 = metadata !{void ()* @gravity, metadata !17, metadata !18, metadata !19, metadata !20, metadata !21, metadata !6}
!17 = metadata !{metadata !"kernel_arg_addr_space"}
!18 = metadata !{metadata !"kernel_arg_access_qual"}
!19 = metadata !{metadata !"kernel_arg_type"}
!20 = metadata !{metadata !"kernel_arg_type_qual"}
!21 = metadata !{metadata !"kernel_arg_name"}
!22 = metadata !{null, metadata !23, metadata !9, metadata !24, metadata !11, metadata !25, metadata !6}
!23 = metadata !{metadata !"kernel_arg_addr_space", i32 0}
!24 = metadata !{metadata !"kernel_arg_type", metadata !"half"}
!25 = metadata !{metadata !"kernel_arg_name", metadata !"x"}
!26 = metadata !{null, metadata !23, metadata !9, metadata !27, metadata !11, metadata !25, metadata !6}
!27 = metadata !{metadata !"kernel_arg_type", metadata !"float"}
!28 = metadata !{null, metadata !23, metadata !9, metadata !29, metadata !11, metadata !25, metadata !6}
!29 = metadata !{metadata !"kernel_arg_type", metadata !"double"}
!30 = metadata !{i64 (double)* @__hls_fptosi_double_, metadata !23, metadata !9, metadata !29, metadata !11, metadata !25, metadata !6}
!31 = metadata !{null, metadata !32, metadata !2, metadata !33, metadata !4, metadata !34, metadata !6}
!32 = metadata !{metadata !"kernel_arg_addr_space", i32 0, i32 0}
!33 = metadata !{metadata !"kernel_arg_type", metadata !"double", metadata !"_Bool"}
!34 = metadata !{metadata !"kernel_arg_name", metadata !"x", metadata !"detect_overflow"}
!35 = metadata !{null, metadata !36, metadata !37, metadata !38, metadata !39, metadata !40, metadata !6}
!36 = metadata !{metadata !"kernel_arg_addr_space", i32 0, i32 0, i32 0}
!37 = metadata !{metadata !"kernel_arg_access_qual", metadata !"none", metadata !"none", metadata !"none"}
!38 = metadata !{metadata !"kernel_arg_type", metadata !"double", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<ulong>::is_signed, _Bool>::type"}
!39 = metadata !{metadata !"kernel_arg_type_qual", metadata !"", metadata !"", metadata !""}
!40 = metadata !{metadata !"kernel_arg_name", metadata !"x", metadata !"detect_overflow", metadata !""}
!41 = metadata !{null, metadata !17, metadata !18, metadata !19, metadata !20, metadata !21, metadata !6}
!42 = metadata !{null, metadata !23, metadata !9, metadata !43, metadata !11, metadata !44, metadata !6}
!43 = metadata !{metadata !"kernel_arg_type", metadata !"_Bool"}
!44 = metadata !{metadata !"kernel_arg_name", metadata !"Cnative"}
!45 = metadata !{null, metadata !23, metadata !9, metadata !46, metadata !11, metadata !47, metadata !6}
!46 = metadata !{metadata !"kernel_arg_type", metadata !"int"}
!47 = metadata !{metadata !"kernel_arg_name", metadata !"op"}
!48 = metadata !{null, metadata !23, metadata !9, metadata !49, metadata !11, metadata !47, metadata !6}
!49 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<64, 64, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!50 = metadata !{null, metadata !23, metadata !9, metadata !51, metadata !11, metadata !47, metadata !6}
!51 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<64, 64, false, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!52 = metadata !{null, metadata !23, metadata !9, metadata !46, metadata !11, metadata !53, metadata !6}
!53 = metadata !{metadata !"kernel_arg_name", metadata !"val"}
!54 = metadata !{null, metadata !32, metadata !2, metadata !55, metadata !4, metadata !56, metadata !6}
!55 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 65, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &", metadata !"int"}
!56 = metadata !{metadata !"kernel_arg_name", metadata !"op", metadata !"i_op"}
!57 = metadata !{null, metadata !23, metadata !9, metadata !46, metadata !11, metadata !58, metadata !6}
!58 = metadata !{metadata !"kernel_arg_name", metadata !"i_op"}
!59 = metadata !{null, metadata !23, metadata !9, metadata !60, metadata !11, metadata !61, metadata !6}
!60 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<32, 32, true, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!61 = metadata !{metadata !"kernel_arg_name", metadata !"op2"}
!62 = metadata !{null, metadata !23, metadata !9, metadata !63, metadata !11, metadata !47, metadata !6}
!63 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 65, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &"}
!64 = metadata !{null, metadata !23, metadata !9, metadata !65, metadata !11, metadata !47, metadata !6}
!65 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<169, 116, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!66 = metadata !{null, metadata !23, metadata !9, metadata !67, metadata !11, metadata !47, metadata !6}
!67 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<169, 116, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!68 = metadata !{null, metadata !69, metadata !70, metadata !71, metadata !72, metadata !73, metadata !6}
!69 = metadata !{metadata !"kernel_arg_addr_space", i32 0, i32 0, i32 0, i32 0}
!70 = metadata !{metadata !"kernel_arg_access_qual", metadata !"none", metadata !"none", metadata !"none", metadata !"none"}
!71 = metadata !{metadata !"kernel_arg_type", metadata !"_Bool", metadata !"_Bool", metadata !"_Bool", metadata !"_Bool"}
!72 = metadata !{metadata !"kernel_arg_type_qual", metadata !"", metadata !"", metadata !"", metadata !""}
!73 = metadata !{metadata !"kernel_arg_name", metadata !"underflow", metadata !"overflow", metadata !"lD", metadata !"sign"}
!74 = metadata !{null, metadata !32, metadata !2, metadata !75, metadata !4, metadata !76, metadata !6}
!75 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<169, false> &", metadata !"int"}
!76 = metadata !{metadata !"kernel_arg_name", metadata !"op", metadata !"op2"}
!77 = metadata !{null, metadata !23, metadata !9, metadata !78, metadata !11, metadata !61, metadata !6}
!78 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<169, false> &"}
!79 = metadata !{null, metadata !32, metadata !2, metadata !80, metadata !4, metadata !56, metadata !6}
!80 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<11, false> &", metadata !"int"}
!81 = metadata !{null, metadata !32, metadata !2, metadata !82, metadata !4, metadata !76, metadata !6}
!82 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<11, false> &", metadata !"const ap_int_base<32, true> &"}
!83 = metadata !{null, metadata !23, metadata !9, metadata !84, metadata !11, metadata !47, metadata !6}
!84 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<32, true> &"}
!85 = metadata !{null, metadata !23, metadata !9, metadata !86, metadata !11, metadata !47, metadata !6}
!86 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<11, false> &"}
!87 = metadata !{null, metadata !23, metadata !9, metadata !46, metadata !11, metadata !88, metadata !6}
!88 = metadata !{metadata !"kernel_arg_name", metadata !"sh"}
!89 = metadata !{null, metadata !23, metadata !9, metadata !90, metadata !11, metadata !53, metadata !6}
!90 = metadata !{metadata !"kernel_arg_type", metadata !"ulong long"}
!91 = metadata !{null, metadata !23, metadata !9, metadata !92, metadata !11, metadata !93, metadata !6}
!92 = metadata !{metadata !"kernel_arg_type", metadata !"uint"}
!93 = metadata !{metadata !"kernel_arg_name", metadata !"index"}
!94 = metadata !{null, metadata !1, metadata !2, metadata !95, metadata !4, metadata !96, metadata !6}
!95 = metadata !{metadata !"kernel_arg_type", metadata !"ap_fixed_base<53, 1, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0>*", metadata !"int"}
!96 = metadata !{metadata !"kernel_arg_name", metadata !"bv", metadata !"index"}
!97 = metadata !{null, metadata !32, metadata !2, metadata !98, metadata !4, metadata !99, metadata !6}
!98 = metadata !{metadata !"kernel_arg_type", metadata !"int", metadata !"int"}
!99 = metadata !{metadata !"kernel_arg_name", metadata !"Hi", metadata !"Lo"}
!100 = metadata !{null, metadata !101, metadata !37, metadata !102, metadata !39, metadata !103, metadata !6}
!101 = metadata !{metadata !"kernel_arg_addr_space", i32 1, i32 0, i32 0}
!102 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<52, false>*", metadata !"int", metadata !"int"}
!103 = metadata !{metadata !"kernel_arg_name", metadata !"bv", metadata !"h", metadata !"l"}
!104 = metadata !{null, metadata !23, metadata !9, metadata !105, metadata !11, metadata !53, metadata !6}
!105 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_range_ref<52, false> &"}
!106 = metadata !{null, metadata !23, metadata !9, metadata !105, metadata !11, metadata !107, metadata !6}
!107 = metadata !{metadata !"kernel_arg_name", metadata !"ref"}
!108 = metadata !{null, metadata !23, metadata !9, metadata !109, metadata !11, metadata !53, metadata !6}
!109 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<52, false> &"}
!110 = metadata !{null, metadata !23, metadata !9, metadata !109, metadata !11, metadata !47, metadata !6}
!111 = metadata !{null, metadata !101, metadata !37, metadata !112, metadata !39, metadata !103, metadata !6}
!112 = metadata !{metadata !"kernel_arg_type", metadata !"ap_fixed_base<53, 1, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0>*", metadata !"int", metadata !"int"}
!113 = metadata !{null, metadata !23, metadata !9, metadata !46, metadata !11, metadata !114, metadata !6}
!114 = metadata !{metadata !"kernel_arg_name", metadata !"v"}
!115 = metadata !{null, metadata !23, metadata !9, metadata !46, metadata !11, metadata !116, metadata !6}
!116 = metadata !{metadata !"kernel_arg_name", metadata !"b"}
!117 = metadata !{null, metadata !23, metadata !9, metadata !60, metadata !11, metadata !47, metadata !6}
!118 = metadata !{null, metadata !23, metadata !9, metadata !119, metadata !11, metadata !47, metadata !6}
!119 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<53, 1, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!120 = metadata !{null, metadata !23, metadata !9, metadata !121, metadata !11, metadata !47, metadata !6}
!121 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<53, 1, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!122 = metadata !{null, metadata !23, metadata !9, metadata !29, metadata !11, metadata !123, metadata !6}
!123 = metadata !{metadata !"kernel_arg_name", metadata !"f"}
!124 = metadata !{null, metadata !23, metadata !9, metadata !125, metadata !11, metadata !53, metadata !6}
!125 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_range_ref<64, false> &"}
!126 = metadata !{null, metadata !23, metadata !9, metadata !125, metadata !11, metadata !107, metadata !6}
!127 = metadata !{null, metadata !23, metadata !9, metadata !128, metadata !11, metadata !53, metadata !6}
!128 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<64, false> &"}
!129 = metadata !{null, metadata !23, metadata !9, metadata !128, metadata !11, metadata !47, metadata !6}
!130 = metadata !{null, metadata !101, metadata !37, metadata !131, metadata !39, metadata !103, metadata !6}
!131 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<64, false>*", metadata !"int", metadata !"int"}
!132 = metadata !{null, metadata !101, metadata !37, metadata !133, metadata !39, metadata !103, metadata !6}
!133 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<11, false>*", metadata !"int", metadata !"int"}
!134 = metadata !{null, metadata !23, metadata !9, metadata !46, metadata !11, metadata !93, metadata !6}
!135 = metadata !{null, metadata !1, metadata !2, metadata !136, metadata !4, metadata !96, metadata !6}
!136 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<64, false>*", metadata !"int"}
!137 = metadata !{null, metadata !23, metadata !9, metadata !138, metadata !11, metadata !53, metadata !6}
!138 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_bit_ref<64, false> &"}
!139 = metadata !{null, metadata !1, metadata !2, metadata !140, metadata !4, metadata !96, metadata !6}
!140 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<1, false>*", metadata !"int"}
!141 = metadata !{null, metadata !23, metadata !9, metadata !142, metadata !11, metadata !53, metadata !6}
!142 = metadata !{metadata !"kernel_arg_type", metadata !"ulong"}
!143 = metadata !{null, metadata !36, metadata !37, metadata !144, metadata !39, metadata !40, metadata !6}
!144 = metadata !{metadata !"kernel_arg_type", metadata !"double", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<uint>::is_signed, _Bool>::type"}
!145 = metadata !{null, metadata !23, metadata !9, metadata !146, metadata !11, metadata !47, metadata !6}
!146 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<32, 32, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!147 = metadata !{null, metadata !23, metadata !9, metadata !148, metadata !11, metadata !47, metadata !6}
!148 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<32, 32, false, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!149 = metadata !{null, metadata !32, metadata !2, metadata !150, metadata !4, metadata !56, metadata !6}
!150 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 33, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &", metadata !"int"}
!151 = metadata !{null, metadata !23, metadata !9, metadata !152, metadata !11, metadata !47, metadata !6}
!152 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 33, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &"}
!153 = metadata !{null, metadata !23, metadata !9, metadata !154, metadata !11, metadata !47, metadata !6}
!154 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<137, 84, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!155 = metadata !{null, metadata !23, metadata !9, metadata !156, metadata !11, metadata !47, metadata !6}
!156 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<137, 84, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!157 = metadata !{null, metadata !32, metadata !2, metadata !158, metadata !4, metadata !76, metadata !6}
!158 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<137, false> &", metadata !"int"}
!159 = metadata !{null, metadata !23, metadata !9, metadata !160, metadata !11, metadata !61, metadata !6}
!160 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<137, false> &"}
!161 = metadata !{null, metadata !36, metadata !37, metadata !162, metadata !39, metadata !40, metadata !6}
!162 = metadata !{metadata !"kernel_arg_type", metadata !"double", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<ushort>::is_signed, _Bool>::type"}
!163 = metadata !{null, metadata !23, metadata !9, metadata !164, metadata !11, metadata !47, metadata !6}
!164 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<16, 16, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!165 = metadata !{null, metadata !23, metadata !9, metadata !166, metadata !11, metadata !47, metadata !6}
!166 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<16, 16, false, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!167 = metadata !{null, metadata !32, metadata !2, metadata !168, metadata !4, metadata !56, metadata !6}
!168 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 17, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &", metadata !"int"}
!169 = metadata !{null, metadata !23, metadata !9, metadata !170, metadata !11, metadata !47, metadata !6}
!170 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 17, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &"}
!171 = metadata !{null, metadata !23, metadata !9, metadata !172, metadata !11, metadata !47, metadata !6}
!172 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<121, 68, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!173 = metadata !{null, metadata !23, metadata !9, metadata !174, metadata !11, metadata !47, metadata !6}
!174 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<121, 68, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!175 = metadata !{null, metadata !32, metadata !2, metadata !176, metadata !4, metadata !76, metadata !6}
!176 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<121, false> &", metadata !"int"}
!177 = metadata !{null, metadata !23, metadata !9, metadata !178, metadata !11, metadata !61, metadata !6}
!178 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<121, false> &"}
!179 = metadata !{null, metadata !36, metadata !37, metadata !180, metadata !39, metadata !40, metadata !6}
!180 = metadata !{metadata !"kernel_arg_type", metadata !"double", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<uchar>::is_signed, _Bool>::type"}
!181 = metadata !{null, metadata !23, metadata !9, metadata !182, metadata !11, metadata !47, metadata !6}
!182 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<8, 8, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!183 = metadata !{null, metadata !23, metadata !9, metadata !184, metadata !11, metadata !47, metadata !6}
!184 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<8, 8, false, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!185 = metadata !{null, metadata !32, metadata !2, metadata !186, metadata !4, metadata !56, metadata !6}
!186 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 9, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &", metadata !"int"}
!187 = metadata !{null, metadata !23, metadata !9, metadata !188, metadata !11, metadata !47, metadata !6}
!188 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 9, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &"}
!189 = metadata !{null, metadata !23, metadata !9, metadata !190, metadata !11, metadata !47, metadata !6}
!190 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<113, 60, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!191 = metadata !{null, metadata !23, metadata !9, metadata !192, metadata !11, metadata !47, metadata !6}
!192 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<113, 60, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!193 = metadata !{null, metadata !32, metadata !2, metadata !194, metadata !4, metadata !76, metadata !6}
!194 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<113, false> &", metadata !"int"}
!195 = metadata !{null, metadata !23, metadata !9, metadata !196, metadata !11, metadata !61, metadata !6}
!196 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<113, false> &"}
!197 = metadata !{null, metadata !32, metadata !2, metadata !198, metadata !4, metadata !34, metadata !6}
!198 = metadata !{metadata !"kernel_arg_type", metadata !"float", metadata !"_Bool"}
!199 = metadata !{null, metadata !36, metadata !37, metadata !200, metadata !39, metadata !40, metadata !6}
!200 = metadata !{metadata !"kernel_arg_type", metadata !"float", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<ulong>::is_signed, _Bool>::type"}
!201 = metadata !{null, metadata !23, metadata !9, metadata !202, metadata !11, metadata !47, metadata !6}
!202 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<111, 87, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!203 = metadata !{null, metadata !23, metadata !9, metadata !204, metadata !11, metadata !47, metadata !6}
!204 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<111, 87, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!205 = metadata !{null, metadata !32, metadata !2, metadata !206, metadata !4, metadata !76, metadata !6}
!206 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<111, false> &", metadata !"int"}
!207 = metadata !{null, metadata !23, metadata !9, metadata !208, metadata !11, metadata !61, metadata !6}
!208 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<111, false> &"}
!209 = metadata !{null, metadata !32, metadata !2, metadata !210, metadata !4, metadata !56, metadata !6}
!210 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<8, false> &", metadata !"int"}
!211 = metadata !{null, metadata !32, metadata !2, metadata !212, metadata !4, metadata !76, metadata !6}
!212 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<8, false> &", metadata !"const ap_int_base<32, true> &"}
!213 = metadata !{null, metadata !23, metadata !9, metadata !214, metadata !11, metadata !47, metadata !6}
!214 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<8, false> &"}
!215 = metadata !{null, metadata !1, metadata !2, metadata !216, metadata !4, metadata !96, metadata !6}
!216 = metadata !{metadata !"kernel_arg_type", metadata !"ap_fixed_base<24, 1, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0>*", metadata !"int"}
!217 = metadata !{null, metadata !101, metadata !37, metadata !218, metadata !39, metadata !103, metadata !6}
!218 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<23, false>*", metadata !"int", metadata !"int"}
!219 = metadata !{null, metadata !23, metadata !9, metadata !220, metadata !11, metadata !53, metadata !6}
!220 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_range_ref<23, false> &"}
!221 = metadata !{null, metadata !23, metadata !9, metadata !220, metadata !11, metadata !107, metadata !6}
!222 = metadata !{null, metadata !23, metadata !9, metadata !223, metadata !11, metadata !53, metadata !6}
!223 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<23, false> &"}
!224 = metadata !{null, metadata !23, metadata !9, metadata !223, metadata !11, metadata !47, metadata !6}
!225 = metadata !{null, metadata !101, metadata !37, metadata !226, metadata !39, metadata !103, metadata !6}
!226 = metadata !{metadata !"kernel_arg_type", metadata !"ap_fixed_base<24, 1, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0>*", metadata !"int", metadata !"int"}
!227 = metadata !{null, metadata !23, metadata !9, metadata !228, metadata !11, metadata !47, metadata !6}
!228 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<24, 1, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!229 = metadata !{null, metadata !23, metadata !9, metadata !230, metadata !11, metadata !47, metadata !6}
!230 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<24, 1, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!231 = metadata !{null, metadata !23, metadata !9, metadata !27, metadata !11, metadata !123, metadata !6}
!232 = metadata !{null, metadata !23, metadata !9, metadata !233, metadata !11, metadata !53, metadata !6}
!233 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_range_ref<32, false> &"}
!234 = metadata !{null, metadata !23, metadata !9, metadata !233, metadata !11, metadata !107, metadata !6}
!235 = metadata !{null, metadata !23, metadata !9, metadata !236, metadata !11, metadata !53, metadata !6}
!236 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<32, false> &"}
!237 = metadata !{null, metadata !23, metadata !9, metadata !236, metadata !11, metadata !47, metadata !6}
!238 = metadata !{null, metadata !101, metadata !37, metadata !239, metadata !39, metadata !103, metadata !6}
!239 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<32, false>*", metadata !"int", metadata !"int"}
!240 = metadata !{null, metadata !101, metadata !37, metadata !241, metadata !39, metadata !103, metadata !6}
!241 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<8, false>*", metadata !"int", metadata !"int"}
!242 = metadata !{null, metadata !1, metadata !2, metadata !243, metadata !4, metadata !96, metadata !6}
!243 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<32, false>*", metadata !"int"}
!244 = metadata !{null, metadata !23, metadata !9, metadata !245, metadata !11, metadata !53, metadata !6}
!245 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_bit_ref<32, false> &"}
!246 = metadata !{null, metadata !23, metadata !9, metadata !92, metadata !11, metadata !53, metadata !6}
!247 = metadata !{null, metadata !36, metadata !37, metadata !248, metadata !39, metadata !40, metadata !6}
!248 = metadata !{metadata !"kernel_arg_type", metadata !"float", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<uint>::is_signed, _Bool>::type"}
!249 = metadata !{null, metadata !23, metadata !9, metadata !250, metadata !11, metadata !47, metadata !6}
!250 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<79, 55, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!251 = metadata !{null, metadata !23, metadata !9, metadata !252, metadata !11, metadata !47, metadata !6}
!252 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<79, 55, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!253 = metadata !{null, metadata !32, metadata !2, metadata !254, metadata !4, metadata !76, metadata !6}
!254 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<79, false> &", metadata !"int"}
!255 = metadata !{null, metadata !23, metadata !9, metadata !256, metadata !11, metadata !61, metadata !6}
!256 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<79, false> &"}
!257 = metadata !{null, metadata !36, metadata !37, metadata !258, metadata !39, metadata !40, metadata !6}
!258 = metadata !{metadata !"kernel_arg_type", metadata !"float", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<ushort>::is_signed, _Bool>::type"}
!259 = metadata !{null, metadata !23, metadata !9, metadata !260, metadata !11, metadata !47, metadata !6}
!260 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<63, 39, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!261 = metadata !{null, metadata !23, metadata !9, metadata !262, metadata !11, metadata !47, metadata !6}
!262 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<63, 39, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!263 = metadata !{null, metadata !32, metadata !2, metadata !264, metadata !4, metadata !76, metadata !6}
!264 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<63, false> &", metadata !"int"}
!265 = metadata !{null, metadata !23, metadata !9, metadata !266, metadata !11, metadata !61, metadata !6}
!266 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<63, false> &"}
!267 = metadata !{null, metadata !36, metadata !37, metadata !268, metadata !39, metadata !40, metadata !6}
!268 = metadata !{metadata !"kernel_arg_type", metadata !"float", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<uchar>::is_signed, _Bool>::type"}
!269 = metadata !{null, metadata !23, metadata !9, metadata !270, metadata !11, metadata !47, metadata !6}
!270 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<55, 31, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!271 = metadata !{null, metadata !23, metadata !9, metadata !272, metadata !11, metadata !47, metadata !6}
!272 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<55, 31, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!273 = metadata !{null, metadata !32, metadata !2, metadata !274, metadata !4, metadata !76, metadata !6}
!274 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<55, false> &", metadata !"int"}
!275 = metadata !{null, metadata !23, metadata !9, metadata !276, metadata !11, metadata !61, metadata !6}
!276 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<55, false> &"}
!277 = metadata !{null, metadata !32, metadata !2, metadata !278, metadata !4, metadata !34, metadata !6}
!278 = metadata !{metadata !"kernel_arg_type", metadata !"half", metadata !"_Bool"}
!279 = metadata !{null, metadata !36, metadata !37, metadata !280, metadata !39, metadata !40, metadata !6}
!280 = metadata !{metadata !"kernel_arg_type", metadata !"half", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<ulong>::is_signed, _Bool>::type"}
!281 = metadata !{null, metadata !32, metadata !2, metadata !282, metadata !4, metadata !76, metadata !6}
!282 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<5, false> &", metadata !"int"}
!283 = metadata !{null, metadata !23, metadata !9, metadata !84, metadata !11, metadata !61, metadata !6}
!284 = metadata !{null, metadata !23, metadata !9, metadata !285, metadata !11, metadata !47, metadata !6}
!285 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<85, 74, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!286 = metadata !{null, metadata !23, metadata !9, metadata !287, metadata !11, metadata !47, metadata !6}
!287 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<85, 74, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!288 = metadata !{null, metadata !32, metadata !2, metadata !289, metadata !4, metadata !76, metadata !6}
!289 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<85, false> &", metadata !"int"}
!290 = metadata !{null, metadata !23, metadata !9, metadata !291, metadata !11, metadata !61, metadata !6}
!291 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<85, false> &"}
!292 = metadata !{null, metadata !32, metadata !2, metadata !282, metadata !4, metadata !56, metadata !6}
!293 = metadata !{null, metadata !32, metadata !2, metadata !294, metadata !4, metadata !76, metadata !6}
!294 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<5, false> &", metadata !"const ap_int_base<32, true> &"}
!295 = metadata !{null, metadata !23, metadata !9, metadata !296, metadata !11, metadata !47, metadata !6}
!296 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<5, false> &"}
!297 = metadata !{null, metadata !1, metadata !2, metadata !298, metadata !4, metadata !96, metadata !6}
!298 = metadata !{metadata !"kernel_arg_type", metadata !"ap_fixed_base<11, 1, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0>*", metadata !"int"}
!299 = metadata !{null, metadata !101, metadata !37, metadata !300, metadata !39, metadata !103, metadata !6}
!300 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<10, false>*", metadata !"int", metadata !"int"}
!301 = metadata !{null, metadata !23, metadata !9, metadata !302, metadata !11, metadata !53, metadata !6}
!302 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_range_ref<10, false> &"}
!303 = metadata !{null, metadata !23, metadata !9, metadata !302, metadata !11, metadata !107, metadata !6}
!304 = metadata !{null, metadata !23, metadata !9, metadata !305, metadata !11, metadata !53, metadata !6}
!305 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<10, false> &"}
!306 = metadata !{null, metadata !23, metadata !9, metadata !305, metadata !11, metadata !47, metadata !6}
!307 = metadata !{null, metadata !101, metadata !37, metadata !308, metadata !39, metadata !103, metadata !6}
!308 = metadata !{metadata !"kernel_arg_type", metadata !"ap_fixed_base<11, 1, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0>*", metadata !"int", metadata !"int"}
!309 = metadata !{null, metadata !23, metadata !9, metadata !310, metadata !11, metadata !47, metadata !6}
!310 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<11, 1, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!311 = metadata !{null, metadata !23, metadata !9, metadata !312, metadata !11, metadata !47, metadata !6}
!312 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<11, 1, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!313 = metadata !{null, metadata !23, metadata !9, metadata !24, metadata !11, metadata !123, metadata !6}
!314 = metadata !{null, metadata !23, metadata !9, metadata !315, metadata !11, metadata !53, metadata !6}
!315 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_range_ref<16, false> &"}
!316 = metadata !{null, metadata !23, metadata !9, metadata !315, metadata !11, metadata !107, metadata !6}
!317 = metadata !{null, metadata !23, metadata !9, metadata !318, metadata !11, metadata !53, metadata !6}
!318 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<16, false> &"}
!319 = metadata !{null, metadata !23, metadata !9, metadata !318, metadata !11, metadata !47, metadata !6}
!320 = metadata !{null, metadata !101, metadata !37, metadata !321, metadata !39, metadata !103, metadata !6}
!321 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<16, false>*", metadata !"int", metadata !"int"}
!322 = metadata !{null, metadata !101, metadata !37, metadata !323, metadata !39, metadata !103, metadata !6}
!323 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<5, false>*", metadata !"int", metadata !"int"}
!324 = metadata !{null, metadata !1, metadata !2, metadata !325, metadata !4, metadata !96, metadata !6}
!325 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<16, false>*", metadata !"int"}
!326 = metadata !{null, metadata !23, metadata !9, metadata !327, metadata !11, metadata !53, metadata !6}
!327 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_bit_ref<16, false> &"}
!328 = metadata !{null, metadata !23, metadata !9, metadata !329, metadata !11, metadata !53, metadata !6}
!329 = metadata !{metadata !"kernel_arg_type", metadata !"ushort"}
!330 = metadata !{null, metadata !36, metadata !37, metadata !331, metadata !39, metadata !40, metadata !6}
!331 = metadata !{metadata !"kernel_arg_type", metadata !"half", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<uint>::is_signed, _Bool>::type"}
!332 = metadata !{null, metadata !23, metadata !9, metadata !333, metadata !11, metadata !47, metadata !6}
!333 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<53, 42, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!334 = metadata !{null, metadata !23, metadata !9, metadata !335, metadata !11, metadata !47, metadata !6}
!335 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<53, 42, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!336 = metadata !{null, metadata !32, metadata !2, metadata !337, metadata !4, metadata !76, metadata !6}
!337 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<53, false> &", metadata !"int"}
!338 = metadata !{null, metadata !23, metadata !9, metadata !339, metadata !11, metadata !61, metadata !6}
!339 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<53, false> &"}
!340 = metadata !{null, metadata !36, metadata !37, metadata !341, metadata !39, metadata !40, metadata !6}
!341 = metadata !{metadata !"kernel_arg_type", metadata !"half", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<ushort>::is_signed, _Bool>::type"}
!342 = metadata !{null, metadata !23, metadata !9, metadata !343, metadata !11, metadata !47, metadata !6}
!343 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<37, 26, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!344 = metadata !{null, metadata !23, metadata !9, metadata !345, metadata !11, metadata !47, metadata !6}
!345 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<37, 26, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!346 = metadata !{null, metadata !32, metadata !2, metadata !347, metadata !4, metadata !76, metadata !6}
!347 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<37, false> &", metadata !"int"}
!348 = metadata !{null, metadata !23, metadata !9, metadata !349, metadata !11, metadata !61, metadata !6}
!349 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<37, false> &"}
!350 = metadata !{null, metadata !36, metadata !37, metadata !351, metadata !39, metadata !40, metadata !6}
!351 = metadata !{metadata !"kernel_arg_type", metadata !"half", metadata !"_Bool", metadata !"typename enable_if<!std::numeric_limits<uchar>::is_signed, _Bool>::type"}
!352 = metadata !{null, metadata !23, metadata !9, metadata !353, metadata !11, metadata !47, metadata !6}
!353 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<29, 18, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!354 = metadata !{null, metadata !23, metadata !9, metadata !355, metadata !11, metadata !47, metadata !6}
!355 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<29, 18, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!356 = metadata !{null, metadata !32, metadata !2, metadata !357, metadata !4, metadata !76, metadata !6}
!357 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<29, false> &", metadata !"int"}
!358 = metadata !{null, metadata !23, metadata !9, metadata !359, metadata !11, metadata !61, metadata !6}
!359 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<29, false> &"}
!360 = metadata !{null, metadata !36, metadata !37, metadata !361, metadata !39, metadata !40, metadata !6}
!361 = metadata !{metadata !"kernel_arg_type", metadata !"double", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<long>::is_signed, _Bool>::type"}
!362 = metadata !{null, metadata !23, metadata !9, metadata !363, metadata !11, metadata !47, metadata !6}
!363 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<63, 63, false, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!364 = metadata !{null, metadata !23, metadata !9, metadata !365, metadata !11, metadata !47, metadata !6}
!365 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<64, 64, true, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!366 = metadata !{null, metadata !23, metadata !9, metadata !367, metadata !11, metadata !47, metadata !6}
!367 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed<64, 64, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!368 = metadata !{null, metadata !23, metadata !9, metadata !369, metadata !11, metadata !47, metadata !6}
!369 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<63, 63, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!370 = metadata !{null, metadata !1, metadata !2, metadata !371, metadata !4, metadata !96, metadata !6}
!371 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<64, true>*", metadata !"int"}
!372 = metadata !{null, metadata !32, metadata !2, metadata !373, metadata !4, metadata !56, metadata !6}
!373 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 64, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &", metadata !"int"}
!374 = metadata !{null, metadata !23, metadata !9, metadata !375, metadata !11, metadata !47, metadata !6}
!375 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 64, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &"}
!376 = metadata !{null, metadata !36, metadata !37, metadata !377, metadata !39, metadata !40, metadata !6}
!377 = metadata !{metadata !"kernel_arg_type", metadata !"double", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<int>::is_signed, _Bool>::type"}
!378 = metadata !{null, metadata !23, metadata !9, metadata !379, metadata !11, metadata !47, metadata !6}
!379 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<31, 31, false, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!380 = metadata !{null, metadata !23, metadata !9, metadata !381, metadata !11, metadata !47, metadata !6}
!381 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed<32, 32, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!382 = metadata !{null, metadata !23, metadata !9, metadata !383, metadata !11, metadata !47, metadata !6}
!383 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<31, 31, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!384 = metadata !{null, metadata !1, metadata !2, metadata !385, metadata !4, metadata !96, metadata !6}
!385 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<32, true>*", metadata !"int"}
!386 = metadata !{null, metadata !32, metadata !2, metadata !387, metadata !4, metadata !56, metadata !6}
!387 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 32, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &", metadata !"int"}
!388 = metadata !{null, metadata !23, metadata !9, metadata !389, metadata !11, metadata !47, metadata !6}
!389 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 32, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &"}
!390 = metadata !{null, metadata !36, metadata !37, metadata !391, metadata !39, metadata !40, metadata !6}
!391 = metadata !{metadata !"kernel_arg_type", metadata !"double", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<short>::is_signed, _Bool>::type"}
!392 = metadata !{null, metadata !23, metadata !9, metadata !393, metadata !11, metadata !47, metadata !6}
!393 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<15, 15, false, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!394 = metadata !{null, metadata !23, metadata !9, metadata !395, metadata !11, metadata !47, metadata !6}
!395 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<16, 16, true, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!396 = metadata !{null, metadata !23, metadata !9, metadata !397, metadata !11, metadata !47, metadata !6}
!397 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed<16, 16, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!398 = metadata !{null, metadata !23, metadata !9, metadata !399, metadata !11, metadata !47, metadata !6}
!399 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<15, 15, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!400 = metadata !{null, metadata !1, metadata !2, metadata !401, metadata !4, metadata !96, metadata !6}
!401 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<16, true>*", metadata !"int"}
!402 = metadata !{null, metadata !32, metadata !2, metadata !403, metadata !4, metadata !56, metadata !6}
!403 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 16, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &", metadata !"int"}
!404 = metadata !{null, metadata !23, metadata !9, metadata !405, metadata !11, metadata !47, metadata !6}
!405 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 16, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &"}
!406 = metadata !{null, metadata !36, metadata !37, metadata !407, metadata !39, metadata !40, metadata !6}
!407 = metadata !{metadata !"kernel_arg_type", metadata !"double", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<signed char>::is_signed, _Bool>::type"}
!408 = metadata !{null, metadata !23, metadata !9, metadata !409, metadata !11, metadata !47, metadata !6}
!409 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<7, 7, false, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!410 = metadata !{null, metadata !23, metadata !9, metadata !411, metadata !11, metadata !47, metadata !6}
!411 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<8, 8, true, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!412 = metadata !{null, metadata !23, metadata !9, metadata !413, metadata !11, metadata !47, metadata !6}
!413 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed<8, 8, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!414 = metadata !{null, metadata !23, metadata !9, metadata !415, metadata !11, metadata !47, metadata !6}
!415 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_ufixed<7, 7, (enum ap_q_mode)6, (enum ap_o_mode)3, 0> &"}
!416 = metadata !{null, metadata !1, metadata !2, metadata !417, metadata !4, metadata !96, metadata !6}
!417 = metadata !{metadata !"kernel_arg_type", metadata !"ap_int_base<8, true>*", metadata !"int"}
!418 = metadata !{null, metadata !32, metadata !2, metadata !419, metadata !4, metadata !56, metadata !6}
!419 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 8, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &", metadata !"int"}
!420 = metadata !{null, metadata !23, metadata !9, metadata !421, metadata !11, metadata !47, metadata !6}
!421 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<1, 8, false, (enum ap_q_mode)5, (enum ap_o_mode)0, 0> &"}
!422 = metadata !{null, metadata !36, metadata !37, metadata !423, metadata !39, metadata !40, metadata !6}
!423 = metadata !{metadata !"kernel_arg_type", metadata !"float", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<long>::is_signed, _Bool>::type"}
!424 = metadata !{null, metadata !36, metadata !37, metadata !425, metadata !39, metadata !40, metadata !6}
!425 = metadata !{metadata !"kernel_arg_type", metadata !"float", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<int>::is_signed, _Bool>::type"}
!426 = metadata !{null, metadata !36, metadata !37, metadata !427, metadata !39, metadata !40, metadata !6}
!427 = metadata !{metadata !"kernel_arg_type", metadata !"float", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<short>::is_signed, _Bool>::type"}
!428 = metadata !{null, metadata !36, metadata !37, metadata !429, metadata !39, metadata !40, metadata !6}
!429 = metadata !{metadata !"kernel_arg_type", metadata !"float", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<signed char>::is_signed, _Bool>::type"}
!430 = metadata !{null, metadata !36, metadata !37, metadata !431, metadata !39, metadata !40, metadata !6}
!431 = metadata !{metadata !"kernel_arg_type", metadata !"half", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<long>::is_signed, _Bool>::type"}
!432 = metadata !{null, metadata !36, metadata !37, metadata !433, metadata !39, metadata !40, metadata !6}
!433 = metadata !{metadata !"kernel_arg_type", metadata !"half", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<int>::is_signed, _Bool>::type"}
!434 = metadata !{null, metadata !36, metadata !37, metadata !435, metadata !39, metadata !40, metadata !6}
!435 = metadata !{metadata !"kernel_arg_type", metadata !"half", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<short>::is_signed, _Bool>::type"}
!436 = metadata !{null, metadata !36, metadata !37, metadata !437, metadata !39, metadata !40, metadata !6}
!437 = metadata !{metadata !"kernel_arg_type", metadata !"half", metadata !"_Bool", metadata !"typename enable_if<std::numeric_limits<signed char>::is_signed, _Bool>::type"}
!438 = metadata !{null, metadata !8, metadata !9, metadata !439, metadata !440, metadata !441, metadata !6}
!439 = metadata !{metadata !"kernel_arg_type", metadata !"char*"}
!440 = metadata !{metadata !"kernel_arg_type_qual", metadata !"const"}
!441 = metadata !{metadata !"kernel_arg_name", metadata !"str"}
!442 = metadata !{null, metadata !23, metadata !9, metadata !29, metadata !11, metadata !114, metadata !6}
!443 = metadata !{null, metadata !23, metadata !9, metadata !29, metadata !11, metadata !444, metadata !6}
!444 = metadata !{metadata !"kernel_arg_name", metadata !"d"}
!445 = metadata !{null, metadata !32, metadata !2, metadata !446, metadata !4, metadata !76, metadata !6}
!446 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<1, false> &", metadata !"const ap_int_base<54, true> &"}
!447 = metadata !{null, metadata !23, metadata !9, metadata !448, metadata !11, metadata !47, metadata !6}
!448 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<54, true> &"}
!449 = metadata !{null, metadata !23, metadata !9, metadata !450, metadata !11, metadata !47, metadata !6}
!450 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<1, false> &"}
!451 = metadata !{null, metadata !23, metadata !9, metadata !452, metadata !11, metadata !61, metadata !6}
!452 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<55, true> &"}
!453 = metadata !{null, metadata !23, metadata !9, metadata !454, metadata !11, metadata !61, metadata !6}
!454 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_int_base<33, true> &"}
!455 = metadata !{null, metadata !23, metadata !9, metadata !29, metadata !11, metadata !456, metadata !6}
!456 = metadata !{metadata !"kernel_arg_name", metadata !"pf"}
!457 = metadata !{null, metadata !23, metadata !9, metadata !458, metadata !11, metadata !47, metadata !6}
!458 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<25, 1, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!459 = metadata !{null, metadata !23, metadata !9, metadata !460, metadata !11, metadata !47, metadata !6}
!460 = metadata !{metadata !"kernel_arg_type", metadata !"const ap_fixed_base<7, 0, false, (enum ap_q_mode)5, (enum ap_o_mode)3, 0> &"}
!461 = metadata !{null, metadata !1, metadata !2, metadata !462, metadata !463, metadata !464, metadata !6}
!462 = metadata !{metadata !"kernel_arg_type", metadata !"char*", metadata !"signed char"}
!463 = metadata !{metadata !"kernel_arg_type_qual", metadata !"const", metadata !""}
!464 = metadata !{metadata !"kernel_arg_name", metadata !"str", metadata !"radix"}
!465 = metadata !{metadata !466, [9 x double]* @p_z}
!466 = metadata !{metadata !467}
!467 = metadata !{i32 0, i32 63, metadata !468}
!468 = metadata !{metadata !469}
!469 = metadata !{metadata !"p.z", metadata !470, metadata !"double", i32 0, i32 63}
!470 = metadata !{metadata !471}
!471 = metadata !{i32 0, i32 8, i32 1}
!472 = metadata !{metadata !473, [9 x double]* @p_y}
!473 = metadata !{metadata !474}
!474 = metadata !{i32 0, i32 63, metadata !475}
!475 = metadata !{metadata !476}
!476 = metadata !{metadata !"p.y", metadata !470, metadata !"double", i32 0, i32 63}
!477 = metadata !{metadata !478, [9 x double]* @p_x}
!478 = metadata !{metadata !479}
!479 = metadata !{i32 0, i32 63, metadata !480}
!480 = metadata !{metadata !481}
!481 = metadata !{metadata !"p.x", metadata !470, metadata !"double", i32 0, i32 63}
!482 = metadata !{metadata !483, [9 x double]* @p_vz}
!483 = metadata !{metadata !484}
!484 = metadata !{i32 0, i32 63, metadata !485}
!485 = metadata !{metadata !486}
!486 = metadata !{metadata !"p.vz", metadata !470, metadata !"double", i32 0, i32 63}
!487 = metadata !{metadata !488, [9 x double]* @p_vy}
!488 = metadata !{metadata !489}
!489 = metadata !{i32 0, i32 63, metadata !490}
!490 = metadata !{metadata !491}
!491 = metadata !{metadata !"p.vy", metadata !470, metadata !"double", i32 0, i32 63}
!492 = metadata !{metadata !493, [9 x double]* @p_vx}
!493 = metadata !{metadata !494}
!494 = metadata !{i32 0, i32 63, metadata !495}
!495 = metadata !{metadata !496}
!496 = metadata !{metadata !"p.vx", metadata !470, metadata !"double", i32 0, i32 63}
!497 = metadata !{metadata !498, [9 x double]* @p_m}
!498 = metadata !{metadata !499}
!499 = metadata !{i32 0, i32 63, metadata !500}
!500 = metadata !{metadata !501}
!501 = metadata !{metadata !"p.m", metadata !470, metadata !"double", i32 0, i32 63}
!502 = metadata !{metadata !503, [9 x double]* @p_az}
!503 = metadata !{metadata !504}
!504 = metadata !{i32 0, i32 63, metadata !505}
!505 = metadata !{metadata !506}
!506 = metadata !{metadata !"p.az", metadata !470, metadata !"double", i32 0, i32 63}
!507 = metadata !{metadata !508, [9 x double]* @p_ay}
!508 = metadata !{metadata !509}
!509 = metadata !{i32 0, i32 63, metadata !510}
!510 = metadata !{metadata !511}
!511 = metadata !{metadata !"p.ay", metadata !470, metadata !"double", i32 0, i32 63}
!512 = metadata !{metadata !513, [9 x double]* @p_ax}
!513 = metadata !{metadata !514}
!514 = metadata !{i32 0, i32 63, metadata !515}
!515 = metadata !{metadata !516}
!516 = metadata !{metadata !"p.ax", metadata !470, metadata !"double", i32 0, i32 63}
!517 = metadata !{metadata !518, [1 x i32]* @llvm_global_ctors_0}
!518 = metadata !{metadata !519}
!519 = metadata !{i32 0, i32 31, metadata !520}
!520 = metadata !{metadata !521}
!521 = metadata !{metadata !"llvm.global_ctors.0", metadata !522, metadata !"", i32 0, i32 31}
!522 = metadata !{metadata !523}
!523 = metadata !{i32 0, i32 0, i32 1}
!524 = metadata !{metadata !525, double* @p_x_0}
!525 = metadata !{metadata !526}
!526 = metadata !{i32 0, i32 63, metadata !527}
!527 = metadata !{metadata !528}
!528 = metadata !{metadata !"p.x", metadata !529, metadata !"double", i32 0, i32 63}
!529 = metadata !{metadata !530}
!530 = metadata !{i32 0, i32 0, i32 2}
!531 = metadata !{metadata !532, double* @p_x_1}
!532 = metadata !{metadata !533}
!533 = metadata !{i32 0, i32 63, metadata !534}
!534 = metadata !{metadata !535}
!535 = metadata !{metadata !"p.x", metadata !536, metadata !"double", i32 0, i32 63}
!536 = metadata !{metadata !537}
!537 = metadata !{i32 1, i32 1, i32 2}
!538 = metadata !{metadata !539, double* @p_x_2}
!539 = metadata !{metadata !540}
!540 = metadata !{i32 0, i32 63, metadata !541}
!541 = metadata !{metadata !542}
!542 = metadata !{metadata !"p.x", metadata !543, metadata !"double", i32 0, i32 63}
!543 = metadata !{metadata !544}
!544 = metadata !{i32 2, i32 2, i32 2}
!545 = metadata !{metadata !546, double* @p_x_3}
!546 = metadata !{metadata !547}
!547 = metadata !{i32 0, i32 63, metadata !548}
!548 = metadata !{metadata !549}
!549 = metadata !{metadata !"p.x", metadata !550, metadata !"double", i32 0, i32 63}
!550 = metadata !{metadata !551}
!551 = metadata !{i32 3, i32 3, i32 2}
!552 = metadata !{metadata !553, double* @p_x_4}
!553 = metadata !{metadata !554}
!554 = metadata !{i32 0, i32 63, metadata !555}
!555 = metadata !{metadata !556}
!556 = metadata !{metadata !"p.x", metadata !557, metadata !"double", i32 0, i32 63}
!557 = metadata !{metadata !558}
!558 = metadata !{i32 4, i32 4, i32 2}
!559 = metadata !{metadata !560, double* @p_x_5}
!560 = metadata !{metadata !561}
!561 = metadata !{i32 0, i32 63, metadata !562}
!562 = metadata !{metadata !563}
!563 = metadata !{metadata !"p.x", metadata !564, metadata !"double", i32 0, i32 63}
!564 = metadata !{metadata !565}
!565 = metadata !{i32 5, i32 5, i32 2}
!566 = metadata !{metadata !567, double* @p_x_6}
!567 = metadata !{metadata !568}
!568 = metadata !{i32 0, i32 63, metadata !569}
!569 = metadata !{metadata !570}
!570 = metadata !{metadata !"p.x", metadata !571, metadata !"double", i32 0, i32 63}
!571 = metadata !{metadata !572}
!572 = metadata !{i32 6, i32 6, i32 2}
!573 = metadata !{metadata !574, double* @p_x_7}
!574 = metadata !{metadata !575}
!575 = metadata !{i32 0, i32 63, metadata !576}
!576 = metadata !{metadata !577}
!577 = metadata !{metadata !"p.x", metadata !578, metadata !"double", i32 0, i32 63}
!578 = metadata !{metadata !579}
!579 = metadata !{i32 7, i32 7, i32 2}
!580 = metadata !{metadata !581, double* @p_x_8}
!581 = metadata !{metadata !582}
!582 = metadata !{i32 0, i32 63, metadata !583}
!583 = metadata !{metadata !584}
!584 = metadata !{metadata !"p.x", metadata !585, metadata !"double", i32 0, i32 63}
!585 = metadata !{metadata !586}
!586 = metadata !{i32 8, i32 8, i32 2}
!587 = metadata !{metadata !588, double* @p_y_0}
!588 = metadata !{metadata !589}
!589 = metadata !{i32 0, i32 63, metadata !590}
!590 = metadata !{metadata !591}
!591 = metadata !{metadata !"p.y", metadata !529, metadata !"double", i32 0, i32 63}
!592 = metadata !{metadata !593, double* @p_y_1}
!593 = metadata !{metadata !594}
!594 = metadata !{i32 0, i32 63, metadata !595}
!595 = metadata !{metadata !596}
!596 = metadata !{metadata !"p.y", metadata !536, metadata !"double", i32 0, i32 63}
!597 = metadata !{metadata !598, double* @p_y_2}
!598 = metadata !{metadata !599}
!599 = metadata !{i32 0, i32 63, metadata !600}
!600 = metadata !{metadata !601}
!601 = metadata !{metadata !"p.y", metadata !543, metadata !"double", i32 0, i32 63}
!602 = metadata !{metadata !603, double* @p_y_3}
!603 = metadata !{metadata !604}
!604 = metadata !{i32 0, i32 63, metadata !605}
!605 = metadata !{metadata !606}
!606 = metadata !{metadata !"p.y", metadata !550, metadata !"double", i32 0, i32 63}
!607 = metadata !{metadata !608, double* @p_y_4}
!608 = metadata !{metadata !609}
!609 = metadata !{i32 0, i32 63, metadata !610}
!610 = metadata !{metadata !611}
!611 = metadata !{metadata !"p.y", metadata !557, metadata !"double", i32 0, i32 63}
!612 = metadata !{metadata !613, double* @p_y_5}
!613 = metadata !{metadata !614}
!614 = metadata !{i32 0, i32 63, metadata !615}
!615 = metadata !{metadata !616}
!616 = metadata !{metadata !"p.y", metadata !564, metadata !"double", i32 0, i32 63}
!617 = metadata !{metadata !618, double* @p_y_6}
!618 = metadata !{metadata !619}
!619 = metadata !{i32 0, i32 63, metadata !620}
!620 = metadata !{metadata !621}
!621 = metadata !{metadata !"p.y", metadata !571, metadata !"double", i32 0, i32 63}
!622 = metadata !{metadata !623, double* @p_y_7}
!623 = metadata !{metadata !624}
!624 = metadata !{i32 0, i32 63, metadata !625}
!625 = metadata !{metadata !626}
!626 = metadata !{metadata !"p.y", metadata !578, metadata !"double", i32 0, i32 63}
!627 = metadata !{metadata !628, double* @p_y_8}
!628 = metadata !{metadata !629}
!629 = metadata !{i32 0, i32 63, metadata !630}
!630 = metadata !{metadata !631}
!631 = metadata !{metadata !"p.y", metadata !585, metadata !"double", i32 0, i32 63}
!632 = metadata !{metadata !633, double* @p_z_0}
!633 = metadata !{metadata !634}
!634 = metadata !{i32 0, i32 63, metadata !635}
!635 = metadata !{metadata !636}
!636 = metadata !{metadata !"p.z", metadata !529, metadata !"double", i32 0, i32 63}
!637 = metadata !{metadata !638, double* @p_z_1}
!638 = metadata !{metadata !639}
!639 = metadata !{i32 0, i32 63, metadata !640}
!640 = metadata !{metadata !641}
!641 = metadata !{metadata !"p.z", metadata !536, metadata !"double", i32 0, i32 63}
!642 = metadata !{metadata !643, double* @p_z_2}
!643 = metadata !{metadata !644}
!644 = metadata !{i32 0, i32 63, metadata !645}
!645 = metadata !{metadata !646}
!646 = metadata !{metadata !"p.z", metadata !543, metadata !"double", i32 0, i32 63}
!647 = metadata !{metadata !648, double* @p_z_3}
!648 = metadata !{metadata !649}
!649 = metadata !{i32 0, i32 63, metadata !650}
!650 = metadata !{metadata !651}
!651 = metadata !{metadata !"p.z", metadata !550, metadata !"double", i32 0, i32 63}
!652 = metadata !{metadata !653, double* @p_z_4}
!653 = metadata !{metadata !654}
!654 = metadata !{i32 0, i32 63, metadata !655}
!655 = metadata !{metadata !656}
!656 = metadata !{metadata !"p.z", metadata !557, metadata !"double", i32 0, i32 63}
!657 = metadata !{metadata !658, double* @p_z_5}
!658 = metadata !{metadata !659}
!659 = metadata !{i32 0, i32 63, metadata !660}
!660 = metadata !{metadata !661}
!661 = metadata !{metadata !"p.z", metadata !564, metadata !"double", i32 0, i32 63}
!662 = metadata !{metadata !663, double* @p_z_6}
!663 = metadata !{metadata !664}
!664 = metadata !{i32 0, i32 63, metadata !665}
!665 = metadata !{metadata !666}
!666 = metadata !{metadata !"p.z", metadata !571, metadata !"double", i32 0, i32 63}
!667 = metadata !{metadata !668, double* @p_z_7}
!668 = metadata !{metadata !669}
!669 = metadata !{i32 0, i32 63, metadata !670}
!670 = metadata !{metadata !671}
!671 = metadata !{metadata !"p.z", metadata !578, metadata !"double", i32 0, i32 63}
!672 = metadata !{metadata !673, double* @p_z_8}
!673 = metadata !{metadata !674}
!674 = metadata !{i32 0, i32 63, metadata !675}
!675 = metadata !{metadata !676}
!676 = metadata !{metadata !"p.z", metadata !585, metadata !"double", i32 0, i32 63}
!677 = metadata !{metadata !678, double* @p_vx_0}
!678 = metadata !{metadata !679}
!679 = metadata !{i32 0, i32 63, metadata !680}
!680 = metadata !{metadata !681}
!681 = metadata !{metadata !"p.vx", metadata !529, metadata !"double", i32 0, i32 63}
!682 = metadata !{metadata !683, double* @p_vx_1}
!683 = metadata !{metadata !684}
!684 = metadata !{i32 0, i32 63, metadata !685}
!685 = metadata !{metadata !686}
!686 = metadata !{metadata !"p.vx", metadata !536, metadata !"double", i32 0, i32 63}
!687 = metadata !{metadata !688, double* @p_vx_2}
!688 = metadata !{metadata !689}
!689 = metadata !{i32 0, i32 63, metadata !690}
!690 = metadata !{metadata !691}
!691 = metadata !{metadata !"p.vx", metadata !543, metadata !"double", i32 0, i32 63}
!692 = metadata !{metadata !693, double* @p_vx_3}
!693 = metadata !{metadata !694}
!694 = metadata !{i32 0, i32 63, metadata !695}
!695 = metadata !{metadata !696}
!696 = metadata !{metadata !"p.vx", metadata !550, metadata !"double", i32 0, i32 63}
!697 = metadata !{metadata !698, double* @p_vx_4}
!698 = metadata !{metadata !699}
!699 = metadata !{i32 0, i32 63, metadata !700}
!700 = metadata !{metadata !701}
!701 = metadata !{metadata !"p.vx", metadata !557, metadata !"double", i32 0, i32 63}
!702 = metadata !{metadata !703, double* @p_vx_5}
!703 = metadata !{metadata !704}
!704 = metadata !{i32 0, i32 63, metadata !705}
!705 = metadata !{metadata !706}
!706 = metadata !{metadata !"p.vx", metadata !564, metadata !"double", i32 0, i32 63}
!707 = metadata !{metadata !708, double* @p_vx_6}
!708 = metadata !{metadata !709}
!709 = metadata !{i32 0, i32 63, metadata !710}
!710 = metadata !{metadata !711}
!711 = metadata !{metadata !"p.vx", metadata !571, metadata !"double", i32 0, i32 63}
!712 = metadata !{metadata !713, double* @p_vx_7}
!713 = metadata !{metadata !714}
!714 = metadata !{i32 0, i32 63, metadata !715}
!715 = metadata !{metadata !716}
!716 = metadata !{metadata !"p.vx", metadata !578, metadata !"double", i32 0, i32 63}
!717 = metadata !{metadata !718, double* @p_vx_8}
!718 = metadata !{metadata !719}
!719 = metadata !{i32 0, i32 63, metadata !720}
!720 = metadata !{metadata !721}
!721 = metadata !{metadata !"p.vx", metadata !585, metadata !"double", i32 0, i32 63}
!722 = metadata !{metadata !723, double* @p_vy_0}
!723 = metadata !{metadata !724}
!724 = metadata !{i32 0, i32 63, metadata !725}
!725 = metadata !{metadata !726}
!726 = metadata !{metadata !"p.vy", metadata !529, metadata !"double", i32 0, i32 63}
!727 = metadata !{metadata !728, double* @p_vy_1}
!728 = metadata !{metadata !729}
!729 = metadata !{i32 0, i32 63, metadata !730}
!730 = metadata !{metadata !731}
!731 = metadata !{metadata !"p.vy", metadata !536, metadata !"double", i32 0, i32 63}
!732 = metadata !{metadata !733, double* @p_vy_2}
!733 = metadata !{metadata !734}
!734 = metadata !{i32 0, i32 63, metadata !735}
!735 = metadata !{metadata !736}
!736 = metadata !{metadata !"p.vy", metadata !543, metadata !"double", i32 0, i32 63}
!737 = metadata !{metadata !738, double* @p_vy_3}
!738 = metadata !{metadata !739}
!739 = metadata !{i32 0, i32 63, metadata !740}
!740 = metadata !{metadata !741}
!741 = metadata !{metadata !"p.vy", metadata !550, metadata !"double", i32 0, i32 63}
!742 = metadata !{metadata !743, double* @p_vy_4}
!743 = metadata !{metadata !744}
!744 = metadata !{i32 0, i32 63, metadata !745}
!745 = metadata !{metadata !746}
!746 = metadata !{metadata !"p.vy", metadata !557, metadata !"double", i32 0, i32 63}
!747 = metadata !{metadata !748, double* @p_vy_5}
!748 = metadata !{metadata !749}
!749 = metadata !{i32 0, i32 63, metadata !750}
!750 = metadata !{metadata !751}
!751 = metadata !{metadata !"p.vy", metadata !564, metadata !"double", i32 0, i32 63}
!752 = metadata !{metadata !753, double* @p_vy_6}
!753 = metadata !{metadata !754}
!754 = metadata !{i32 0, i32 63, metadata !755}
!755 = metadata !{metadata !756}
!756 = metadata !{metadata !"p.vy", metadata !571, metadata !"double", i32 0, i32 63}
!757 = metadata !{metadata !758, double* @p_vy_7}
!758 = metadata !{metadata !759}
!759 = metadata !{i32 0, i32 63, metadata !760}
!760 = metadata !{metadata !761}
!761 = metadata !{metadata !"p.vy", metadata !578, metadata !"double", i32 0, i32 63}
!762 = metadata !{metadata !763, double* @p_vy_8}
!763 = metadata !{metadata !764}
!764 = metadata !{i32 0, i32 63, metadata !765}
!765 = metadata !{metadata !766}
!766 = metadata !{metadata !"p.vy", metadata !585, metadata !"double", i32 0, i32 63}
!767 = metadata !{metadata !768, double* @p_vz_0}
!768 = metadata !{metadata !769}
!769 = metadata !{i32 0, i32 63, metadata !770}
!770 = metadata !{metadata !771}
!771 = metadata !{metadata !"p.vz", metadata !529, metadata !"double", i32 0, i32 63}
!772 = metadata !{metadata !773, double* @p_vz_1}
!773 = metadata !{metadata !774}
!774 = metadata !{i32 0, i32 63, metadata !775}
!775 = metadata !{metadata !776}
!776 = metadata !{metadata !"p.vz", metadata !536, metadata !"double", i32 0, i32 63}
!777 = metadata !{metadata !778, double* @p_vz_2}
!778 = metadata !{metadata !779}
!779 = metadata !{i32 0, i32 63, metadata !780}
!780 = metadata !{metadata !781}
!781 = metadata !{metadata !"p.vz", metadata !543, metadata !"double", i32 0, i32 63}
!782 = metadata !{metadata !783, double* @p_vz_3}
!783 = metadata !{metadata !784}
!784 = metadata !{i32 0, i32 63, metadata !785}
!785 = metadata !{metadata !786}
!786 = metadata !{metadata !"p.vz", metadata !550, metadata !"double", i32 0, i32 63}
!787 = metadata !{metadata !788, double* @p_vz_4}
!788 = metadata !{metadata !789}
!789 = metadata !{i32 0, i32 63, metadata !790}
!790 = metadata !{metadata !791}
!791 = metadata !{metadata !"p.vz", metadata !557, metadata !"double", i32 0, i32 63}
!792 = metadata !{metadata !793, double* @p_vz_5}
!793 = metadata !{metadata !794}
!794 = metadata !{i32 0, i32 63, metadata !795}
!795 = metadata !{metadata !796}
!796 = metadata !{metadata !"p.vz", metadata !564, metadata !"double", i32 0, i32 63}
!797 = metadata !{metadata !798, double* @p_vz_6}
!798 = metadata !{metadata !799}
!799 = metadata !{i32 0, i32 63, metadata !800}
!800 = metadata !{metadata !801}
!801 = metadata !{metadata !"p.vz", metadata !571, metadata !"double", i32 0, i32 63}
!802 = metadata !{metadata !803, double* @p_vz_7}
!803 = metadata !{metadata !804}
!804 = metadata !{i32 0, i32 63, metadata !805}
!805 = metadata !{metadata !806}
!806 = metadata !{metadata !"p.vz", metadata !578, metadata !"double", i32 0, i32 63}
!807 = metadata !{metadata !808, double* @p_vz_8}
!808 = metadata !{metadata !809}
!809 = metadata !{i32 0, i32 63, metadata !810}
!810 = metadata !{metadata !811}
!811 = metadata !{metadata !"p.vz", metadata !585, metadata !"double", i32 0, i32 63}
!812 = metadata !{metadata !813, double* @p_ax_0}
!813 = metadata !{metadata !814}
!814 = metadata !{i32 0, i32 63, metadata !815}
!815 = metadata !{metadata !816}
!816 = metadata !{metadata !"p.ax", metadata !529, metadata !"double", i32 0, i32 63}
!817 = metadata !{metadata !818, double* @p_ax_1}
!818 = metadata !{metadata !819}
!819 = metadata !{i32 0, i32 63, metadata !820}
!820 = metadata !{metadata !821}
!821 = metadata !{metadata !"p.ax", metadata !536, metadata !"double", i32 0, i32 63}
!822 = metadata !{metadata !823, double* @p_ax_2}
!823 = metadata !{metadata !824}
!824 = metadata !{i32 0, i32 63, metadata !825}
!825 = metadata !{metadata !826}
!826 = metadata !{metadata !"p.ax", metadata !543, metadata !"double", i32 0, i32 63}
!827 = metadata !{metadata !828, double* @p_ax_3}
!828 = metadata !{metadata !829}
!829 = metadata !{i32 0, i32 63, metadata !830}
!830 = metadata !{metadata !831}
!831 = metadata !{metadata !"p.ax", metadata !550, metadata !"double", i32 0, i32 63}
!832 = metadata !{metadata !833, double* @p_ax_4}
!833 = metadata !{metadata !834}
!834 = metadata !{i32 0, i32 63, metadata !835}
!835 = metadata !{metadata !836}
!836 = metadata !{metadata !"p.ax", metadata !557, metadata !"double", i32 0, i32 63}
!837 = metadata !{metadata !838, double* @p_ax_5}
!838 = metadata !{metadata !839}
!839 = metadata !{i32 0, i32 63, metadata !840}
!840 = metadata !{metadata !841}
!841 = metadata !{metadata !"p.ax", metadata !564, metadata !"double", i32 0, i32 63}
!842 = metadata !{metadata !843, double* @p_ax_6}
!843 = metadata !{metadata !844}
!844 = metadata !{i32 0, i32 63, metadata !845}
!845 = metadata !{metadata !846}
!846 = metadata !{metadata !"p.ax", metadata !571, metadata !"double", i32 0, i32 63}
!847 = metadata !{metadata !848, double* @p_ax_7}
!848 = metadata !{metadata !849}
!849 = metadata !{i32 0, i32 63, metadata !850}
!850 = metadata !{metadata !851}
!851 = metadata !{metadata !"p.ax", metadata !578, metadata !"double", i32 0, i32 63}
!852 = metadata !{metadata !853, double* @p_ax_8}
!853 = metadata !{metadata !854}
!854 = metadata !{i32 0, i32 63, metadata !855}
!855 = metadata !{metadata !856}
!856 = metadata !{metadata !"p.ax", metadata !585, metadata !"double", i32 0, i32 63}
!857 = metadata !{metadata !858, double* @p_ay_0}
!858 = metadata !{metadata !859}
!859 = metadata !{i32 0, i32 63, metadata !860}
!860 = metadata !{metadata !861}
!861 = metadata !{metadata !"p.ay", metadata !529, metadata !"double", i32 0, i32 63}
!862 = metadata !{metadata !863, double* @p_ay_1}
!863 = metadata !{metadata !864}
!864 = metadata !{i32 0, i32 63, metadata !865}
!865 = metadata !{metadata !866}
!866 = metadata !{metadata !"p.ay", metadata !536, metadata !"double", i32 0, i32 63}
!867 = metadata !{metadata !868, double* @p_ay_2}
!868 = metadata !{metadata !869}
!869 = metadata !{i32 0, i32 63, metadata !870}
!870 = metadata !{metadata !871}
!871 = metadata !{metadata !"p.ay", metadata !543, metadata !"double", i32 0, i32 63}
!872 = metadata !{metadata !873, double* @p_ay_3}
!873 = metadata !{metadata !874}
!874 = metadata !{i32 0, i32 63, metadata !875}
!875 = metadata !{metadata !876}
!876 = metadata !{metadata !"p.ay", metadata !550, metadata !"double", i32 0, i32 63}
!877 = metadata !{metadata !878, double* @p_ay_4}
!878 = metadata !{metadata !879}
!879 = metadata !{i32 0, i32 63, metadata !880}
!880 = metadata !{metadata !881}
!881 = metadata !{metadata !"p.ay", metadata !557, metadata !"double", i32 0, i32 63}
!882 = metadata !{metadata !883, double* @p_ay_5}
!883 = metadata !{metadata !884}
!884 = metadata !{i32 0, i32 63, metadata !885}
!885 = metadata !{metadata !886}
!886 = metadata !{metadata !"p.ay", metadata !564, metadata !"double", i32 0, i32 63}
!887 = metadata !{metadata !888, double* @p_ay_6}
!888 = metadata !{metadata !889}
!889 = metadata !{i32 0, i32 63, metadata !890}
!890 = metadata !{metadata !891}
!891 = metadata !{metadata !"p.ay", metadata !571, metadata !"double", i32 0, i32 63}
!892 = metadata !{metadata !893, double* @p_ay_7}
!893 = metadata !{metadata !894}
!894 = metadata !{i32 0, i32 63, metadata !895}
!895 = metadata !{metadata !896}
!896 = metadata !{metadata !"p.ay", metadata !578, metadata !"double", i32 0, i32 63}
!897 = metadata !{metadata !898, double* @p_ay_8}
!898 = metadata !{metadata !899}
!899 = metadata !{i32 0, i32 63, metadata !900}
!900 = metadata !{metadata !901}
!901 = metadata !{metadata !"p.ay", metadata !585, metadata !"double", i32 0, i32 63}
!902 = metadata !{metadata !903, double* @p_az_0}
!903 = metadata !{metadata !904}
!904 = metadata !{i32 0, i32 63, metadata !905}
!905 = metadata !{metadata !906}
!906 = metadata !{metadata !"p.az", metadata !529, metadata !"double", i32 0, i32 63}
!907 = metadata !{metadata !908, double* @p_az_1}
!908 = metadata !{metadata !909}
!909 = metadata !{i32 0, i32 63, metadata !910}
!910 = metadata !{metadata !911}
!911 = metadata !{metadata !"p.az", metadata !536, metadata !"double", i32 0, i32 63}
!912 = metadata !{metadata !913, double* @p_az_2}
!913 = metadata !{metadata !914}
!914 = metadata !{i32 0, i32 63, metadata !915}
!915 = metadata !{metadata !916}
!916 = metadata !{metadata !"p.az", metadata !543, metadata !"double", i32 0, i32 63}
!917 = metadata !{metadata !918, double* @p_az_3}
!918 = metadata !{metadata !919}
!919 = metadata !{i32 0, i32 63, metadata !920}
!920 = metadata !{metadata !921}
!921 = metadata !{metadata !"p.az", metadata !550, metadata !"double", i32 0, i32 63}
!922 = metadata !{metadata !923, double* @p_az_4}
!923 = metadata !{metadata !924}
!924 = metadata !{i32 0, i32 63, metadata !925}
!925 = metadata !{metadata !926}
!926 = metadata !{metadata !"p.az", metadata !557, metadata !"double", i32 0, i32 63}
!927 = metadata !{metadata !928, double* @p_az_5}
!928 = metadata !{metadata !929}
!929 = metadata !{i32 0, i32 63, metadata !930}
!930 = metadata !{metadata !931}
!931 = metadata !{metadata !"p.az", metadata !564, metadata !"double", i32 0, i32 63}
!932 = metadata !{metadata !933, double* @p_az_6}
!933 = metadata !{metadata !934}
!934 = metadata !{i32 0, i32 63, metadata !935}
!935 = metadata !{metadata !936}
!936 = metadata !{metadata !"p.az", metadata !571, metadata !"double", i32 0, i32 63}
!937 = metadata !{metadata !938, double* @p_az_7}
!938 = metadata !{metadata !939}
!939 = metadata !{i32 0, i32 63, metadata !940}
!940 = metadata !{metadata !941}
!941 = metadata !{metadata !"p.az", metadata !578, metadata !"double", i32 0, i32 63}
!942 = metadata !{metadata !943, double* @p_az_8}
!943 = metadata !{metadata !944}
!944 = metadata !{i32 0, i32 63, metadata !945}
!945 = metadata !{metadata !946}
!946 = metadata !{metadata !"p.az", metadata !585, metadata !"double", i32 0, i32 63}
!947 = metadata !{metadata !948, double* @p_m_0}
!948 = metadata !{metadata !949}
!949 = metadata !{i32 0, i32 63, metadata !950}
!950 = metadata !{metadata !951}
!951 = metadata !{metadata !"p.m", metadata !529, metadata !"double", i32 0, i32 63}
!952 = metadata !{metadata !953, double* @p_m_1}
!953 = metadata !{metadata !954}
!954 = metadata !{i32 0, i32 63, metadata !955}
!955 = metadata !{metadata !956}
!956 = metadata !{metadata !"p.m", metadata !536, metadata !"double", i32 0, i32 63}
!957 = metadata !{metadata !958, double* @p_m_2}
!958 = metadata !{metadata !959}
!959 = metadata !{i32 0, i32 63, metadata !960}
!960 = metadata !{metadata !961}
!961 = metadata !{metadata !"p.m", metadata !543, metadata !"double", i32 0, i32 63}
!962 = metadata !{metadata !963, double* @p_m_3}
!963 = metadata !{metadata !964}
!964 = metadata !{i32 0, i32 63, metadata !965}
!965 = metadata !{metadata !966}
!966 = metadata !{metadata !"p.m", metadata !550, metadata !"double", i32 0, i32 63}
!967 = metadata !{metadata !968, double* @p_m_4}
!968 = metadata !{metadata !969}
!969 = metadata !{i32 0, i32 63, metadata !970}
!970 = metadata !{metadata !971}
!971 = metadata !{metadata !"p.m", metadata !557, metadata !"double", i32 0, i32 63}
!972 = metadata !{metadata !973, double* @p_m_5}
!973 = metadata !{metadata !974}
!974 = metadata !{i32 0, i32 63, metadata !975}
!975 = metadata !{metadata !976}
!976 = metadata !{metadata !"p.m", metadata !564, metadata !"double", i32 0, i32 63}
!977 = metadata !{metadata !978, double* @p_m_6}
!978 = metadata !{metadata !979}
!979 = metadata !{i32 0, i32 63, metadata !980}
!980 = metadata !{metadata !981}
!981 = metadata !{metadata !"p.m", metadata !571, metadata !"double", i32 0, i32 63}
!982 = metadata !{metadata !983, double* @p_m_7}
!983 = metadata !{metadata !984}
!984 = metadata !{i32 0, i32 63, metadata !985}
!985 = metadata !{metadata !986}
!986 = metadata !{metadata !"p.m", metadata !578, metadata !"double", i32 0, i32 63}
!987 = metadata !{metadata !988, double* @p_m_8}
!988 = metadata !{metadata !989}
!989 = metadata !{i32 0, i32 63, metadata !990}
!990 = metadata !{metadata !991}
!991 = metadata !{metadata !"p.m", metadata !585, metadata !"double", i32 0, i32 63}
!992 = metadata !{metadata !993}
!993 = metadata !{i32 0, i32 63, metadata !994}
!994 = metadata !{metadata !995}
!995 = metadata !{metadata !"result.x", metadata !470, metadata !"double", i32 0, i32 63}
!996 = metadata !{metadata !997}
!997 = metadata !{i32 0, i32 63, metadata !998}
!998 = metadata !{metadata !999}
!999 = metadata !{metadata !"result.y", metadata !470, metadata !"double", i32 0, i32 63}
!1000 = metadata !{metadata !1001}
!1001 = metadata !{i32 0, i32 63, metadata !1002}
!1002 = metadata !{metadata !1003}
!1003 = metadata !{metadata !"result.z", metadata !470, metadata !"double", i32 0, i32 63}
!1004 = metadata !{metadata !1005}
!1005 = metadata !{i32 0, i32 63, metadata !1006}
!1006 = metadata !{metadata !1007}
!1007 = metadata !{metadata !"result.vx", metadata !470, metadata !"double", i32 0, i32 63}
!1008 = metadata !{metadata !1009}
!1009 = metadata !{i32 0, i32 63, metadata !1010}
!1010 = metadata !{metadata !1011}
!1011 = metadata !{metadata !"result.vy", metadata !470, metadata !"double", i32 0, i32 63}
!1012 = metadata !{metadata !1013}
!1013 = metadata !{i32 0, i32 63, metadata !1014}
!1014 = metadata !{metadata !1015}
!1015 = metadata !{metadata !"result.vz", metadata !470, metadata !"double", i32 0, i32 63}
!1016 = metadata !{metadata !1017}
!1017 = metadata !{i32 0, i32 63, metadata !1018}
!1018 = metadata !{metadata !1019}
!1019 = metadata !{metadata !"result.ax", metadata !470, metadata !"double", i32 0, i32 63}
!1020 = metadata !{metadata !1021}
!1021 = metadata !{i32 0, i32 63, metadata !1022}
!1022 = metadata !{metadata !1023}
!1023 = metadata !{metadata !"result.ay", metadata !470, metadata !"double", i32 0, i32 63}
!1024 = metadata !{metadata !1025}
!1025 = metadata !{i32 0, i32 63, metadata !1026}
!1026 = metadata !{metadata !1027}
!1027 = metadata !{metadata !"result.az", metadata !470, metadata !"double", i32 0, i32 63}
!1028 = metadata !{metadata !1029}
!1029 = metadata !{i32 0, i32 63, metadata !1030}
!1030 = metadata !{metadata !1031}
!1031 = metadata !{metadata !"result.m", metadata !470, metadata !"double", i32 0, i32 63}
